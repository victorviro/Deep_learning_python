{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Introduction to Machine Learning pipelines.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMCybV0CHQFDQ44dWSqMQ4D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victorviro/Deep_learning_python/blob/master/Introduction_to_Machine_Learning_pipelines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2v_zOYt9SNY"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bG6Zgm_x9UZC"
      },
      "source": [
        "In this notebook, we will introduce machine learning pipelines and outline all the steps that go into building them. We will explain what needs to happen to move our machine learning model from an experiment to a robust production system."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rN61RVKy-C4O"
      },
      "source": [
        "## Why Machine Learning Pipelines?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GpTMf7f-DGW"
      },
      "source": [
        "The key benefit of machine learning pipelines lies in the automation of the model life cycle steps. When new training data becomes available, a workflow which includes data validation, preprocessing, model training, analysis, and deployment should be triggered. Manually going through these steps is costly and also a source of errors. Let’s cover some details of the benefits of machine learning pipelines:\n",
        "\n",
        "- *Ability to focus on new models, not maintaining existing models*: Automated machine learning pipelines will free up data scientists from maintaining existing models. We want to avoid spending our days on keeping previously developed models up to date, running scripts manually to preprocess our training data, or writing one-off deployment scripts, or manually tune our models. Automated pipelines allow us to develop new models, the fun part of our job. Ultimately, this will lead to higher job satisfaction and retention in a competitive job market.\n",
        "\n",
        "- *Prevention of bugs*: Automated pipelines can prevent bugs. As we will see in the following notebooks, newly created models will be tied to a set of versioned data, and preprocessing steps will be tied to the developed model. This means that if new data is collected, a new model will be generated. If the preprocessing steps are updated, the training data will become invalid and a new model will be generated. In manual machine learning workflows, a common source of bugs is a change in the preprocessing step after a model was trained. In this case, we would deploy a model with different processing instructions than what we trained the model with. These bugs might be really difficult to debug since an inference of the model is still possible, but simply incorrect. With automated workflows, these errors can be prevented.\n",
        "\n",
        "- *Useful paper trail*: The experiment tracking and the model release management generate a paper trail of the model changes. The experiment will record changes to the model’s hyperparameters, the used datasets, and the resulting model metrics (e.g., loss or accuracy). The model release management will keep track of which model was ultimately selected and deployed. This paper trail is especially valuable if the data science team needs to re-create a model or track the model’s performance.\n",
        "\n",
        "- *Standardization*: Standardized machine learning pipelines improve the experience of a data science team. Due to the standardized setups, data scientists can be onboarded quickly or move across teams and find the same development environments. This improves efficiency and reduces the time spent getting set up on a new project. The time investment of setting up machine learning pipelines can also lead to an improved retention rate.\n",
        "\n",
        "- *The business case for pipelines*\n",
        "The implementation of automated machine learning pipelines will lead to three key impacts for a data science team:\n",
        "\n",
        " - More development time for novel models\n",
        "\n",
        " - Simpler processes to update existing models\n",
        "\n",
        " - Less time spent to reproduce models\n",
        "\n",
        "All of these aspects will reduce the costs of data science projects. But furthermore, automated machine learning pipelines will:\n",
        "\n",
        "- Help detect potential biases in the datasets or in the trained models. Spotting biases can prevent harm to people who interact with the model. For example, Amazon’s machine learning-powered resume screener was found to be biased against women.\n",
        "\n",
        "- Create a paper trail (via experiment tracking and model release management) that will assist if questions arise around data protection laws, such as Europe’s General Data Protection Regulation (GDPR).\n",
        "\n",
        "- Free up development time for data scientists and increase their job satisfaction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvLZUhU__euY"
      },
      "source": [
        "## When Machine Learning Pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dn6Qpc5X_iQi"
      },
      "source": [
        "Machine learning pipelines provide a variety of advantages, but not every data science project needs a pipeline. Sometimes data scientists simply want to experiment with a new model, investigate a new model architecture, or reproduce a recent publication. Pipelines wouldn’t be useful in these cases. However, as soon as a model has users (e.g., it is being used in an app), it will require continuous updates and fine-tuning. In these situations, we are back in the scenarios we discussed earlier about continuously updating models and reducing the burden of these tasks for data scientists.\n",
        "\n",
        "Pipelines also become more important as a machine learning project grows. If the dataset or resource requirements are large, the approaches we discuss allow for easy infrastructure scaling. If repeatability is important, this is provided through the automation and the audit trail of machine learning pipelines."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3TUNY54_tS2"
      },
      "source": [
        "## Steps in a Machine Learning Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyyGu-lZ_uoT"
      },
      "source": [
        "A machine learning pipeline starts with the ingestion of new training data and ends with receiving some kind of feedback on how our newly trained model is performing. This feedback can be a production performance metric or feedback from users of our product. The pipeline includes a variety of steps, including data preprocessing, model training, and model analysis, as well as the deployment of the model. We can imagine that going through these steps manually is cumbersome and very error-prone. In the course of these notebooks, we will introduce tools and solutions to automate our machine learning pipeline.\n",
        "\n",
        "![](https://i.ibb.co/YL3s7T8/ml-model-lifecycle.png)\n",
        "\n",
        "As we can see in Figure 1-1, the pipeline is actually a recurring cycle. Data can be continuously collected and, therefore, machine learning models can be updated. More data generally means improved models. And because of this constant influx of data, automation is key. In real-world applications, we want to retrain our models frequently. If we don’t, in many cases accuracy will decrease because the training data is different from the new data that the model is making predictions on. If retraining is a manual process, where it is necessary to manually validate the new training data or analyze the updated models, a data scientist or machine learning engineer would have no time to develop new models for entirely different business problems.\n",
        "\n",
        "A machine learning pipeline commonly includes the next steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "js8AbKd5CIMw"
      },
      "source": [
        "#### Data Ingestion and Data Versioning\n",
        "\n",
        "Data ingestion is the beginning of every machine learning pipeline. In this pipeline step, we process the data into a format that the following components can digest. The data ingestion step does not perform any feature engineering (this happens after the data validation step). It is also a good moment to version the incoming data to connect a data snapshot with the trained model at the end of the pipeline.\n",
        "\n",
        "#### Data Validation\n",
        "Before training a new model version, we need to validate the new data. Data validation focuses on checking that the statistics of the new data are as expected (e.g., the range, number of categories, and distribution of categories). It also alerts the data scientist if any anomalies are detected. For example, if we are training a binary classification model, our training data could contain 50% of Class X samples and 50% of Class Y samples. Data validation tools provide alerts if the split between these classes changes, where perhaps the newly collected data is split 70/30 between the two classes. If a model is being trained with such an imbalanced training set and the data scientist hasn’t adjusted the model’s loss function, or over/under sampled category X or Y, the model predictions could be biased toward the dominant category.\n",
        "\n",
        "Common data validation tools will also allow us to compare different datasets. If we have a dataset with a dominant label and we split the dataset into a training and validation set, we need to make sure that the label split is roughly the same between the two datasets. Data validation tools will allow us to compare datasets and highlight anomalies.\n",
        "\n",
        "If the validation highlights anything out of the ordinary, the pipeline can be stopped here and the data scientist can be alerted. If a shift in the data is detected, the data scientist or the machine learning engineer can either change the sampling of the individual classes (e.g., only pick the same number of examples from each class), or change the model’s loss function, kick off a new model build pipeline, and restart the life cycle."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkgBjDkvCkYb"
      },
      "source": [
        "#### Data Preprocessing\n",
        "\n",
        "It is highly likely that we cannot use our freshly collected data and train our machine learning model directly. In almost all cases, we will need to preprocess the data to use it for our training runs. Labels often need to be converted to one or multi-hot vectors. The same applies to the model inputs. If we train a model from text data, we want to convert the characters of the text to indices or the text tokens to word vectors. Since preprocessing is only required before model training and not with every training epoch, it makes the most sense to run the preprocessing in its own life cycle step before training the model.\n",
        "\n",
        "Data preprocessing tools can range from a simple Python script to elaborate graph models. While most data scientists focus on the processing capabilities of their preferred tools, it is also important that modifications of preprocessing steps can be linked to the processed data and vice versa. This means if someone modifies a processing step (e.g., allowing an additional label in a one-hot vector conversion), the previous training data should become invalid and force an update of the entire pipeline. \n",
        "\n",
        "#### Model Training and Tuning\n",
        "\n",
        "The model training step is the core of the machine learning pipeline. In this step, we train a model to take inputs and predict an output with the lowest error possible. With larger models, and especially with large training sets, this step can quickly become difficult to manage. Since memory is generally a finite resource for our computations, the efficient distribution of the model training is crucial.\n",
        "\n",
        "Model tuning has seen a great deal of attention lately because it can yield significant performance improvements and provide a competitive edge. Depending on our machine learning project, we may choose to tune our model before starting to think about machine learning pipelines or we may want to tune it as part of our pipeline. Because our pipelines are scalable, thanks to their underlying architecture, we can spin up a large number of models in parallel or in sequence. This lets us pick out the optimal model hyperparameters for our final production model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVuMeQCIDJFG"
      },
      "source": [
        "#### Model Analysis\n",
        "\n",
        "Generally, we would use accuracy or loss to determine the optimal set of model parameters. But once we have settled on the final version of the model, it’s extremely useful to carry out a more in-depth analysis of the model’s performance. This may include calculating other metrics such as precision, recall, and AUC (area under the curve), or calculating performance on a larger dataset than the validation set used in training.\n",
        "\n",
        "Another reason for an in-depth model analysis is to check that the model’s predictions are fair. It’s impossible to tell how the model will perform for different groups of users unless the dataset is sliced and the performance is calculated for each slice. We can also investigate the model’s dependence on features used in training and explore how the model’s predictions would change if we altered the features of a single training example.\n",
        "\n",
        "Similar to the model-tuning step and the final selection of the best performing model, this workflow step requires a review by a data scientist. However, we will demonstrate how the entire analysis can be automated with only the final review done by a human. The automation will keep the analysis of the models consistent and comparable against other analyses.\n",
        "\n",
        "#### Model Versioning\n",
        "\n",
        "The purpose of the model versioning and validation step is to keep track of which model, set of hyperparameters, and datasets have been selected as the next version to be deployed.\n",
        "\n",
        "Semantic versioning in software engineering requires us to increase the major version number when we make an incompatible change in our API or when we add major features. Otherwise, we increase the minor version number. Model release management has another degree of freedom: the dataset. There are situations in which we can achieve a significant difference of model performance without changing a single model parameter or architecture description by providing significantly more and/or better data for the training process. Does that performance increase warrant a major version upgrade?\n",
        "\n",
        "While the answer to this question might be different for every data science team, it is essential to document all inputs into a new model version (hyperparameters, datasets, architecture) and track them as part of this release step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcS1UeCCDNhI"
      },
      "source": [
        "#### Model Deployment\n",
        "\n",
        "Once we have trained, tuned, and analyzed our model, it is ready for prime time. Unfortunately, too many models are deployed with one-off implementations, which makes updating models a brittle process.\n",
        "\n",
        "Modern model servers allow us to deploy our models without writing web app code. Often, they provide multiple API interfaces like representational state transfer (REST) or remote procedure call (RPC) protocols and allow us to host multiple versions of the same model simultaneously. Hosting multiple versions at the same time will allow us to run A/B tests on our models and provide valuable feedback about our model improvements.\n",
        "\n",
        "Model servers also allow us to update a model version without redeploying our application, which will reduce our application’s downtime and reduce the communication between the application development and the machine learning teams. \n",
        "\n",
        "#### Feedback Loops\n",
        "\n",
        "The last step of the machine learning pipeline is often forgotten, but it is crucial to the success of data science projects. We need to close the loop. We can then measure the effectiveness and performance of the newly deployed model. During this step, we can capture valuable information about the performance of the model. In some situations, we can also capture new training data to increase our datasets and update our model. This may involve a human in the loop, or it may be automatic.\n",
        "\n",
        "Except for the two manual review steps (the model analysis step and the feedback step), we can automate the entire pipeline. Data scientists should be able to focus on the development of new models, not on updating and maintaining existing models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8njYvS84DPb_"
      },
      "source": [
        "#### Data Privacy\n",
        "\n",
        "At the time of writing, data privacy considerations sit outside the standard machine learning pipeline. We expect this to change in the future as consumer concerns grow over the use of their data and new laws are brought in to restrict the usage of personal data. This will lead to privacy-preserving methods being integrated into tools for building machine learning pipelines.\n",
        "\n",
        "We'll discuss several current options for increasing privacy in machine learning models:\n",
        "\n",
        "- Differential privacy, where math guarantees that model predictions do not expose a user’s data.\n",
        "\n",
        "- Federated learning, where the raw data does not leave a user’s device.\n",
        "\n",
        "- Encrypted machine learning, where either the entire training process can run in the encrypted space or a model trained on raw data can be encrypted."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oB8_4hsMliE"
      },
      "source": [
        "## Pipeline Orchestration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jas3PUL4MmUM"
      },
      "source": [
        "All the components of a machine learning pipeline described in the previous section need to be executed or, as we say, orchestrated, so that the components are being executed in the correct order. Inputs to a component must be computed before a component is executed. The orchestration of these steps is performed by tools such as Apache Airflow, or Kubeflow Pipelines for Kubernetes infrastructure.\n",
        "\n",
        "While data pipeline tools coordinate the machine learning pipeline steps, pipeline artifact stores like the TensorFlow ML MetadataStore capture the outputs of the individual processes. We will provide an overview of TFX’s MetadataStore and look behind the scenes of TFX and its pipeline components."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtEvmBRmM4qR"
      },
      "source": [
        "### Why Pipeline Orchestration?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ud83v_fcM7tm"
      },
      "source": [
        "In 2015, a group of machine learning engineers at Google concluded that one of the reasons machine learning projects often fail is that most projects come with custom code to bridge the gap between machine learning pipeline steps. However, this custom code doesn’t transfer easily from one project to the next. The researchers summarized their findings in the paper [“Hidden Technical Debt in Machine Learning Systems”](https://papers.nips.cc/paper/2015/file/86df7dcfd896fcaf2674f757a2463eba-Paper.pdf). The authors argue in this paper that the glue code between the pipeline steps is often brittle and that custom scripts don’t scale beyond specific cases. Over time, tools like  Apache Airflow, or Kubeflow Pipelines have been developed. These tools can be used to manage the machine learning pipeline tasks; they allow a standardized orchestration and an abstraction of the glue code between tasks.\n",
        "\n",
        "While it might seem cumbersome at first to learn a new tool (e.g., Airflow) or a new framework (e.g., Kubeflow) and set up an additional machine learning infrastructure (e.g., Kubernetes), the time investment will pay off very soon. By not adopting standardized machine learning pipelines, data science teams will face unique project setups, arbitrary log file locations, unique debugging steps, etc. The list of complications can be endless."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfQ09vIRNfTj"
      },
      "source": [
        "### Directed Acyclic Graphs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHBYchyLNiw2"
      },
      "source": [
        "Pipeline tools like Apache Airflow, and Kubeflow Pipelines manage the flow of tasks through a graph representation of the task dependencies.\n",
        "\n",
        "![](https://i.ibb.co/w4XpLr7/DAG-example.png)\n",
        "\n",
        "As the example graph in Figure 1-2 shows, the pipeline steps are directed. This means that a pipeline starts with Task A and ends with Task E, which guarantees that the path of execution is clearly defined by the task's dependencies. Directed graphs avoid situations where some tasks start without all dependencies fully computed. Since we know that we must preprocess our training data before training a model, the representation as a directed graph prevents the training task from being executed before the preprocessing step is completed.\n",
        "\n",
        "Pipeline graphs must also be acyclic, meaning that a graph isn’t linking to a previously completed task. This would mean that the pipeline could run endlessly and therefore wouldn’t finish the workflow.\n",
        "\n",
        "Because of the two conditions (being directed and acyclic), pipeline graphs are called directed acyclic graphs (DAGs). We will discover DAGs are a central concept behind most workflow tools. We will discuss more details about how these graphs are executed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bggeS2W7IV9r"
      },
      "source": [
        "## Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhwoZFScIXOp"
      },
      "source": [
        "In this notebook, we have introduced the concept of machine learning pipelines and explained the individual steps. We have also shown the benefits of automating this process. In addition, we have set the stage for the following notebooks. In the next notebook, we will start building our pipeline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWXfFGkqOSGu"
      },
      "source": [
        "# References\n",
        "\n",
        "- [Building Machine Learning Pipelines](https://learning.oreilly.com/library/view/building-machine-learning/9781492053187/)\n",
        "\n",
        "- [From Research to Production with TFX Pipelines and ML Metadata](https://blog.tensorflow.org/2019/05/research-to-production-with-tfx-ml.html)"
      ]
    }
  ]
}