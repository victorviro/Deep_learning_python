{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow Eager vs Graph execution.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "dUgSg-9WVMtd",
        "5eUAtuVlVM1s",
        "ZAEoOGLfHxH8",
        "IbGf9B1oIWyD",
        "5M-mC-wjIqLE",
        "daSJn_CVJ1B7",
        "FnA2b3HrTgD-",
        "1JtEsIn3UNKO",
        "2s43IovwV6-n",
        "w59NMNxCitLg"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOJpjRilr00wGd0QNdyrM2a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victorviro/Deep_learning_python/blob/master/TensorFlow_Eager_vs_Graph_execution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jrqNaZ3s4J8"
      },
      "source": [
        "# TensorFlow Eager vs Graph execution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUgSg-9WVMtd"
      },
      "source": [
        "# Table of contents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_erhQefI2df"
      },
      "source": [
        "1. [Introduction](#1)\n",
        "2. [Eager execution](#2)\n",
        "3. [Graph execution](#3)\n",
        "    1. [Graphs](#3.1)\n",
        "    2. [Benefits of graphs](#3.2)\n",
        "    3. [tf.function](#3.3)\n",
        "    4. [Polymorphism](#3.4)\n",
        "    5. [Graph vs. eager execution](#3.5)\n",
        "    6. [Speed-up](#3.6)\n",
        "4. [References and further reading](#4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eUAtuVlVM1s"
      },
      "source": [
        "# Introduction <a name=\"1\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22oYRUT2GGfC"
      },
      "source": [
        "In this notebook, we will talk about the two modes in TensorFlow: the eager execution mode and the graph mode, as well as its pros and cons."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_CkiRfptDe5"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAEoOGLfHxH8"
      },
      "source": [
        "# Eager execution <a name=\"2\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJp9ISUBGGh8"
      },
      "source": [
        "TensorFlow's eager execution is an imperative programming environment that evaluates operations immediately, without building graphs: **operations return concrete values instead of constructing a computational graph to run later**. This makes it **easy to get started with TensorFlow and debug models**, but it is **not necessarily suggested for real training or production**. \n",
        "\n",
        "Eager execution supports most TensorFlow operations and GPU acceleration. In Tensorflow 2.0, eager execution is enabled by default:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QI73Ar3Gg6Z",
        "outputId": "b9169207-cece-433c-b231-247b8eec2a98"
      },
      "source": [
        "tf.executing_eagerly()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dR24i-wQGl7R"
      },
      "source": [
        "We can run TensorFlow operations and the results will return immediately. This is what we usually expect in running Python codes. Codes are executed line by line with computation results returned immediately."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZ0-Vpe5GoTR",
        "outputId": "68d3f699-8e2f-4ea3-97a0-9dab4a69b367"
      },
      "source": [
        "x = [[2.]]\n",
        "m = tf.matmul(x, x)\n",
        "print(m)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([[4.]], shape=(1, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K19keanrHUWZ"
      },
      "source": [
        "With eager execution TensorFlow operations immediately evaluate and return their values to Python. `tf.Tensor` objects reference concrete values instead of symbolic handles to nodes in a computational graph. Since there isn't a computational graph to build and run later in a session, it's easy to inspect results using `print` statements or a debugger."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbGf9B1oIWyD"
      },
      "source": [
        "# Graph execution <a name=\"3\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pN5CKVlYIYp-"
      },
      "source": [
        "While eager execution has several unique advantages, graph execution enables portability outside Python and tends to offer better performance. Graph execution means that tensor computations are executed as a **TensorFlow graph**, sometimes referred to as a [`tf.Graph`](https://www.tensorflow.org/api_docs/python/tf/Graph) or simply a \"graph.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5M-mC-wjIqLE"
      },
      "source": [
        "## Graphs <a name=\"3.1\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJCmBo74Irml"
      },
      "source": [
        "Graphs are data structures that contain a set of [`tf.Operation`](https://www.tensorflow.org/api_docs/python/tf/Operation) objects, which represent units of computation or nodes in the graph; and [`tf.Tensor`](https://www.tensorflow.org/api_docs/python/tf/Tensor) objects, which represent the units of data that flow between operations. They are defined in a `tf.Graph` context. Since these graphs are data structures, they can be saved, run, and restored all without the original Python code.\n",
        "\n",
        "This is what a TensorFlow graph representing a two-layer neural network looks like when visualized in TensorBoard.\n",
        "\n",
        "![](https://i.ibb.co/7pZ6qmc/tf-graph.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daSJn_CVJ1B7"
      },
      "source": [
        "## The benefits of graphs <a name=\"3.2\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KHdBftsJ3st"
      },
      "source": [
        "- **Speed**: Graphs are easily [optimized](https://www.tensorflow.org/guide/graph_optimization) to improve execution performance.\n",
        "\n",
        "- **Portability/Deployability**: Models can run efficiently on multiple devices that don't have a Python interpreter (like mobile applications, embedded devices, and backend servers). In fact, TensorFlow uses graphs as the format for saved models when it exports them from Python. This portability has a great advantage in production deployment. By export a `SavedModel` including data preprocessing, we eliminate possible mistakes in re-creating the data preprocessing logic in production.\n",
        "\n",
        "However, we still want to define our machine learning models (or other computations) in Python for convenience, and then automatically construct graphs when we need them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnA2b3HrTgD-"
      },
      "source": [
        "## `tf.function` <a name=\"3.3\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iaIWd0WJ1HU"
      },
      "source": [
        "We create and run a graph in TensorFlow by using [`tf.function`](https://www.tensorflow.org/api_docs/python/tf/function), either as a direct call or as a decorator. `tf.function` takes a regular function as input and returns a TensorFlow `Function`, which is a Python callable that builds TensorFlow graphs from the Python function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEbDA0S-QT5k",
        "outputId": "3c072ff9-a0b6-4916-a545-30c19694e208"
      },
      "source": [
        "# Define a Python function\n",
        "def a_regular_function(x, y):\n",
        "  x = tf.matmul(x, y)\n",
        "  return x\n",
        "# Create a TensorFlow `Function`\n",
        "a_function_that_uses_a_graph = tf.function(a_regular_function)\n",
        "\n",
        "x = tf.constant([[1.0, 2.0]])\n",
        "y = tf.constant([[2.0], [3.0]])\n",
        "\n",
        "print(a_regular_function(x, y).numpy())\n",
        "print(a_function_that_uses_a_graph(x, y).numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[8.]]\n",
            "[[8.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OzmpguxRgdA"
      },
      "source": [
        "On the outside, a `Function` looks like a regular function we write using TensorFlow operations. Underneath, however, it's different. A `Function` encapsulates several `tf.Graphs` behind one API. \n",
        "\n",
        "**Note**: `tf.function` applies to a function and all other functions it calls.\n",
        "\n",
        "Any function we write will contain a mixture of built-in TF operations and Python logic, such as `if-then` clauses, loops, `return`, etc. While TensorFlow operations are easily captured by a `tf.Graph`, Python-specific logic needs to undergo an extra step in order to become part of the graph. `tf.function` uses a library, [`tf.autograph`](https://www.tensorflow.org/api_docs/python/tf/autograph), to convert Python code into graph-generating code. Though it is unlikely that we'll need to view graphs directly, we can inspect the outputs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlO9iUXqTcfu"
      },
      "source": [
        "# Graph-generating output of AutoGraph\n",
        "print(tf.autograph.to_code(a_regular_function))\n",
        "# The graph itself\n",
        "print(a_function_that_uses_a_graph.get_concrete_function(x,y).graph.as_graph_def())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_1SsJxdsLpo"
      },
      "source": [
        "It's recommendable to **include as much computation as possible under a `tf.function` to maximize the performance gain**. For example, decorate a whole **training step** or the entire training loop."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JtEsIn3UNKO"
      },
      "source": [
        "## Polymorphism <a name=\"3.4\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScOPmCv0UN--"
      },
      "source": [
        "A `tf.Graph` is specialized to a specific type of inputs (for example, tensors with a specific `dtype`). Each time we invoke a `Function` with new `dtypes` and shapes in its arguments, `Function` creates a new `tf.Graph` for the new arguments. The `dtypes` and shapes of a `tf.Graph`'s inputs are known as an **input signature** or just a signature.\n",
        "\n",
        "The `Function` stores the `tf.Graph` corresponding to that signature in a `ConcreteFunction`, which is a wrapper around a `tf.Graph`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMnS9HVCVDFN",
        "outputId": "a04b21f0-b39c-4f60-8e00-8606d7292ea1"
      },
      "source": [
        "@tf.function\n",
        "def my_relu(x):\n",
        "  return tf.maximum(0., x)\n",
        "\n",
        "# `my_relu` creates new graphs as it observes more signatures\n",
        "print(my_relu(tf.constant(5.5)))\n",
        "print(my_relu([1, -1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(5.5, shape=(), dtype=float32)\n",
            "tf.Tensor([1. 0.], shape=(2,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKDNqGLrVYHR",
        "outputId": "312b3fd9-7cad-49b5-acdd-bd834e2039c2"
      },
      "source": [
        "# There are two `ConcreteFunction`s (one for each graph) in `my_relu`\n",
        "# The `ConcreteFunction` also knows the return type and shape!\n",
        "print(my_relu.pretty_printed_concrete_signatures())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "my_relu(x)\n",
            "  Args:\n",
            "    x: float32 Tensor, shape=()\n",
            "  Returns:\n",
            "    float32 Tensor, shape=()\n",
            "\n",
            "my_relu(x=[1, -1])\n",
            "  Returns:\n",
            "    float32 Tensor, shape=(2,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "621oqeYuVIbv"
      },
      "source": [
        "If the `Function` has already been called with that signature, `Function` does not create a new `tf.Graph`.\n",
        "\n",
        "Because it's backed by **multiple graphs**, a `Function` is **polymorphic**. That enables it to support more input types than a single `tf.Graph` could represent, as well as to optimize each `tf.Graph` for better performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2s43IovwV6-n"
      },
      "source": [
        "## Graph execution vs. eager execution <a name=\"3.5\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxC_BlUrV92G"
      },
      "source": [
        "The code in a `Function` can be executed both eagerly and as a graph. By default, `Function` executes its code as a graph. To verify that our Function's graph is doing the same computation as its equivalent Python function, we can make it execute eagerly with `tf.config.run_functions_eagerly(True)`. This is a switch that turns off `Function`'s ability to create and run graphs, and instead executing the code eagerly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCqxYCCxWIDW",
        "outputId": "3fbd9602-5c72-49da-993e-3e439ca79146"
      },
      "source": [
        "tf.config.run_functions_eagerly(True)\n",
        "print(my_relu([1, -1]))\n",
        "tf.config.run_functions_eagerly(False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([1. 0.], shape=(2,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqRR--cWV98N"
      },
      "source": [
        "**`Function` can behave differently under graph and eager execution**. The Python `print` function is one example . Let's check out what happens when we insert a `print` statement to our function and call it repeatedly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MikeYQRoWhuQ",
        "outputId": "d2e48558-9533-454d-ea89-e5285b277565"
      },
      "source": [
        "@tf.function\n",
        "def my_relu(x):\n",
        "    print(\"Applying relu!\")\n",
        "    return tf.maximum(0., x)\n",
        "\n",
        "activation = my_relu([1, -1])\n",
        "activation = my_relu([1, -1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Applying relu!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvyPjX6HX_um"
      },
      "source": [
        "`my_relu` only printed once even though it was called two times. This is caused by that the `print` statement is executed when `Function` runs the original code to create the graph in a process known as [\"tracing\"](https://www.tensorflow.org/guide/function#tracing). Tracing captures the TensorFlow operations into a graph, and `print` is not captured in the graph. That graph is then executed for all two calls without ever running the Python code again.\n",
        "\n",
        "As a sanity check, let's turn off graph execution to compare:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8izArF3dV89Q",
        "outputId": "5e0ef6a0-9b61-46e8-bc93-770599e658b2"
      },
      "source": [
        "tf.config.run_functions_eagerly(True)\n",
        "activation = my_relu([1, -1])\n",
        "activation = my_relu([1, -1])\n",
        "tf.config.run_functions_eagerly(False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Applying relu!\n",
            "Applying relu!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzSWgTYYYbqG"
      },
      "source": [
        "`print` is a *Python side effect*, and there are [other differences](https://www.tensorflow.org/guide/function#executing_python_side_effects) to be aware of when converting a function into a `Function`.\n",
        "\n",
        "TensorFlow documentation suggests to first-time users to play around with decorating toy functions with `@tf.function` to get experience with going from eager to graph execution. [Here](https://www.tensorflow.org/guide/intro_to_graphs#tffunction_best_practices) are some tips."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w59NMNxCitLg"
      },
      "source": [
        "## Speed-up <a name=\"3.6\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwiT80meizNR"
      },
      "source": [
        "Graphs can speed up your code, but the process of creating them has some overhead. For some functions, the creation of the graph takes more time than the execution of the graph. This investment is usually quickly paid back with the performance boost of subsequent executions. The first few steps of any large model training can be slower due to tracing.\n",
        "\n",
        "No matter how large our model is, we want to avoid tracing frequently.  To figure out when our `Function` is tracing, we can add a `print` statement to its code. An illustration is available [here](https://www.tensorflow.org/guide/intro_to_graphs#when_is_a_function_tracing). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nLD11GNGQA8"
      },
      "source": [
        "# References and further reading <a name=\"4\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLrCY8WiGSJx"
      },
      "source": [
        "- [TensorFlow docs: Eager execution](https://www.tensorflow.org/guide/eager)\n",
        "\n",
        "- [Introduction to graphs and tf.function](https://www.tensorflow.org/guide/intro_to_graphs)\n",
        "\n",
        "- [Better performance with tf.function](https://www.tensorflow.org/guide/function)\n",
        "\n",
        "- [AutoGraph reference](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/index.md)\n",
        "\n",
        "- [When is a `Function` tracing?](https://www.tensorflow.org/guide/intro_to_graphs#when_is_a_function_tracing)"
      ]
    }
  ]
}