{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensorflow custom models and training.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "0_b-hp0qbtix",
        "PnpnaNhjdHYJ",
        "piQZq_OogSSf",
        "x2wtP1qeiQQJ",
        "D8RMLKUApHUt",
        "mZ1guxUopMVm",
        "XueA3eUVpPgl"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO2+2RmRagqzrTBlN8yZZlO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ab3b177aa6fe45f68c6b4831a731499f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_eeb870f05f2046e89e8078bbe2e0452a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b4efa3905c0a40ee9dac6a3e227b5d0d",
              "IPY_MODEL_2b359bd240c7437cb122956ef9d56ab6"
            ]
          }
        },
        "eeb870f05f2046e89e8078bbe2e0452a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b4efa3905c0a40ee9dac6a3e227b5d0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2e236e7dce8e4b0b83c7edebb2e88a45",
            "_dom_classes": [],
            "description": "All epochs: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bf63dfac41f64df3b9507c88d39d94a5"
          }
        },
        "2b359bd240c7437cb122956ef9d56ab6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3619bdccc5fb4f50a9d3138846a6b1ce",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [00:26&lt;00:00,  5.26s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_07ee55e6f6a247e2a7cf00cf80ccc957"
          }
        },
        "2e236e7dce8e4b0b83c7edebb2e88a45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bf63dfac41f64df3b9507c88d39d94a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3619bdccc5fb4f50a9d3138846a6b1ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "07ee55e6f6a247e2a7cf00cf80ccc957": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e8ed3f44549b43b1a92a6d65b8d5ad37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_984c522f1b5b48648befe1348bd31dcc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b0235005238f46bca04aa28e2d48cc61",
              "IPY_MODEL_f0edaf04900a4f9fa117ca223e5b067f"
            ]
          }
        },
        "984c522f1b5b48648befe1348bd31dcc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b0235005238f46bca04aa28e2d48cc61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_86a2ac2628dc4aa48d57abb366338487",
            "_dom_classes": [],
            "description": "Epoch 1/5: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 362,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 362,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d195eb4192c444dd9ae30ae2be37824d"
          }
        },
        "f0edaf04900a4f9fa117ca223e5b067f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7aec9dfab871432d9e7112c29405d7f1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 362/362 [00:05&lt;00:00, 68.51it/s, loss=0.65, mean_absolute_error=0.522]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_16482d0ada2d4668a40559af722bca06"
          }
        },
        "86a2ac2628dc4aa48d57abb366338487": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d195eb4192c444dd9ae30ae2be37824d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7aec9dfab871432d9e7112c29405d7f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "16482d0ada2d4668a40559af722bca06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d805b895500f40839351b4fe3a0f2e26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_19ed51b346064d32a860519f9eb9cf1c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9432aa2bb71f4581bcfdd7dd6556a5bd",
              "IPY_MODEL_18c8e2b629744a529dc26406efa17d9e"
            ]
          }
        },
        "19ed51b346064d32a860519f9eb9cf1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9432aa2bb71f4581bcfdd7dd6556a5bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6c8afa2989b54fe89c33db93b435d95c",
            "_dom_classes": [],
            "description": "Epoch 2/5: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 362,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 362,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_64ab43f3037b41edabb309361f3c13a1"
          }
        },
        "18c8e2b629744a529dc26406efa17d9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_866bdd5e17644aa0aa5f344ac02326e4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 362/362 [00:05&lt;00:00, 68.50it/s, loss=0.63, mean_absolute_error=0.512]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a4042aa2c2874ff4a2bf087fe192eb88"
          }
        },
        "6c8afa2989b54fe89c33db93b435d95c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "64ab43f3037b41edabb309361f3c13a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "866bdd5e17644aa0aa5f344ac02326e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a4042aa2c2874ff4a2bf087fe192eb88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "543de1f4bfd74eaca08b711f3b3c4550": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5ea70542f6074226b5cc14280d062e8b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_057a3f988d44488bb5fa2d9d5afaaaff",
              "IPY_MODEL_781def7aaeb745df9f60b546640b1eb9"
            ]
          }
        },
        "5ea70542f6074226b5cc14280d062e8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "057a3f988d44488bb5fa2d9d5afaaaff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a925ff622699485a9ad9fa742bb2c318",
            "_dom_classes": [],
            "description": "Epoch 3/5: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 362,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 362,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d5d30bddd4904d34b77375a5a9bedb8b"
          }
        },
        "781def7aaeb745df9f60b546640b1eb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9420a43c62214519986fd763c62bd083",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 362/362 [00:05&lt;00:00, 69.16it/s, loss=0.626, mean_absolute_error=0.51]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5c98cc8d0ec541a891b99c25a2b09bc9"
          }
        },
        "a925ff622699485a9ad9fa742bb2c318": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d5d30bddd4904d34b77375a5a9bedb8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9420a43c62214519986fd763c62bd083": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5c98cc8d0ec541a891b99c25a2b09bc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "85137b668110498080b26a54246c3fc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_62a1b189e09c4a7ebf83be46ad51705b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a8671a2bc2f54b0e9e832e07c351fb6f",
              "IPY_MODEL_4cb508f2cb114752881e4dadb6d661e9"
            ]
          }
        },
        "62a1b189e09c4a7ebf83be46ad51705b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a8671a2bc2f54b0e9e832e07c351fb6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fafbc0c5eac14798872212978de62b25",
            "_dom_classes": [],
            "description": "Epoch 4/5: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 362,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 362,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f46bb703a35a41b38189e450f0026adf"
          }
        },
        "4cb508f2cb114752881e4dadb6d661e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d5f74ce6ced24d278991517dd0095afb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 362/362 [00:05&lt;00:00, 69.08it/s, loss=0.612, mean_absolute_error=0.505]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d54b420c703e4809abdde79725b59c9f"
          }
        },
        "fafbc0c5eac14798872212978de62b25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f46bb703a35a41b38189e450f0026adf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d5f74ce6ced24d278991517dd0095afb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d54b420c703e4809abdde79725b59c9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8f5d9d259ef94d85b97077bf6acbe90d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_148ab3ab0f3e41dbb68efb61bfe70d04",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b2e61c4337144cb294cca7f2d86ad624",
              "IPY_MODEL_f38771ab4cda4fc0ba5a9aba60ef5267"
            ]
          }
        },
        "148ab3ab0f3e41dbb68efb61bfe70d04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b2e61c4337144cb294cca7f2d86ad624": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c1f92e171f2c4762a137328ff5b4639a",
            "_dom_classes": [],
            "description": "Epoch 5/5: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 362,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 362,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5701402239e24853ad4ac9b2b062a408"
          }
        },
        "f38771ab4cda4fc0ba5a9aba60ef5267": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_192f99213e6e4fa0b4577a86e2cd7781",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 362/362 [00:05&lt;00:00, 69.37it/s, loss=0.637, mean_absolute_error=0.513]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0c54473affb24bd9875d2e30096066f8"
          }
        },
        "c1f92e171f2c4762a137328ff5b4639a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5701402239e24853ad4ac9b2b062a408": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "192f99213e6e4fa0b4577a86e2cd7781": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0c54473affb24bd9875d2e30096066f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victorviro/Deep_learning_python/blob/master/Tensorflow_custom_models_and_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzEo8sQMdlBq"
      },
      "source": [
        "The 95% of the use cases we will encounter will not require anything else than TensorFlow’s high-level API, `tf.keras`. In previous notebooks we have built various neural network architectures, including regression and classification nets, deep nets, and self-normalizing nets, using all sorts of techniques, such as Batch Normalization, dropout, learning rate schedules, and more. But now it’s time to dive deeper into TensorFlow and take a look at its lower-level Python API. In a previous notebook, we took a quick tour of TensorFlow and we saw the basic operations around tensors and other data structures (see [notebook](https://github.com/victorviro/Deep_learning_python/blob/master/TensorFlow_operations_and_data_structures.ipynb)). This will be useful when we need extra control, to write custom loss functions, custom metrics, layers, models, initializers, regularizers, weight constraints and more. We may even need to fully control the training loop itself, for example, to apply special transformations or constraints to the gradients (beyond just clipping them), or to use multiple optimizers for different parts of the network. We will cover all these cases in this notebook, then in the next notebook, we will also look at how we can boost our custom models and training algorithms using TensorFlow’s automatic graph generation feature. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aj4rC8AqbarJ"
      },
      "source": [
        "## Customizing models and training algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_b-hp0qbtix"
      },
      "source": [
        "### Custom loss functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvmN77AIbut7"
      },
      "source": [
        "Suppose we want to train a regression model, but our training set is a bit noisy. Of course, we start by trying to clean up our dataset by removing or fixing the outliers, but it turns out to be insufficient, the dataset is still noisy. Which loss function should we use? The mean squared error might penalize large errors too much, so our model will end up being imprecise. The mean absolute error would not penalize outliers as much, but training might take a while to converge and the trained model might not be very precise. This is probably a good time to use the Huber loss (introduced in [here](https://github.com/victorviro/ML_algorithms_python/blob/master/Introduction_linear_regression_and_regularized_linear_models.ipynb)). The Huber loss is not currently part of the official Keras API, but it is available in tf.keras (we can just use an instance of the `keras.losses.Huber` class). But let’s pretend it’s not there. Let's create a function that takes the labels and predictions as arguments, and use TensorFlow operations to compute every instance’s loss:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oo8kb2kaioIV"
      },
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5EjAAVrvZI3",
        "outputId": "b6a3a435-3a2f-4730-9bb1-3964b89486d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Let's start by loading and preparing the California housing dataset\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
        "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X_train_full, y_train_full, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_valid_scaled = scaler.transform(X_valid)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to /root/scikit_learn_data\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyIbqFu7cL1N"
      },
      "source": [
        "def huber_fn(y_true, y_pred):\n",
        "    error = y_true - y_pred\n",
        "    is_small_error = tf.abs(error) < 1\n",
        "    squared_loss = tf.square(error) / 2\n",
        "    linear_loss = tf.abs(error) - 0.5\n",
        "    return tf.where(is_small_error, squared_loss, linear_loss)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOI7GB4Tvq9d",
        "cellView": "form",
        "outputId": "49697a07-649e-4376-bea5-1263d5a662e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "#@title\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "plt.figure(figsize=(9, 4))\n",
        "z = np.linspace(-4, 4, 200)\n",
        "plt.plot(z, huber_fn(0, z), \"b-\", linewidth=2, label=\"huber($z$)\")\n",
        "plt.plot(z, z**2 / 2, \"b:\", linewidth=1, label=r\"$\\frac{1}{2}z^2$\")\n",
        "plt.plot([-1, -1], [0, huber_fn(0., -1.)], \"r--\")\n",
        "plt.plot([1, 1], [0, huber_fn(0., 1.)], \"r--\")\n",
        "plt.gca().axhline(y=0, color='k')\n",
        "plt.gca().axvline(x=0, color='k')\n",
        "plt.axis([-4, 4, 0, 4])\n",
        "plt.grid(True)\n",
        "plt.xlabel(\"$z$\")\n",
        "plt.legend(fontsize=14)\n",
        "plt.title(\"Huber loss\", fontsize=14)\n",
        "plt.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh4AAAEXCAYAAADiJE0fAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3xU1RLA8d8AoXcJVRCkIwoKj66hiCIWQLErWBHFwhNUeCpKsWJBilIUFSw0C0WsdGkKCoggCiq9SQ89yXl/zCIBAtkku3u3zPfz2Q9bbu6dmw3J7Llz5ohzDmOMMcaYUMjmdQDGGGOMiR2WeBhjjDEmZCzxMMYYY0zIWOJhjDHGmJCxxMMYY4wxIWOJhzHGGGNCxhIPY8xpiUhTEXEiUixEx7tDRBJDcSxjjDcs8TAmyojIeyIyJY3n6/qSiPKhj8oYY5QlHsaYkBORnF7HYIzxhiUexsSotC6jiEh533N1T9q8gYgsEZFDIrJYROqctK9GIjJLRA6IyEYReUtECqZ6fabvuVdEZDswNwNx3iciq0XkiO/fe9N4/XdfbP+IyNciksP32vkiMk1E9opIoogsFZFmGfk+GWMCyxIPY4w/XgGeAOoCfwJTRCQv6B934BtgElALuBaoDYw8aR+3AQJcDHTw56Ai0g4YDAwAagJvAG+KyNW+1+sCQ4DeQFWgBfBVql18BGwG6vliehY45PdZG2MCLofXARhjgqJVGkWaWfmg0dc59zWAiNwJbABuAd4GHgPGOudePbaxiNwP/CwixZ1z23xP/+Wc65bB43YHRjvnBvse/+4bbXkCmAyUA/YDk5xz+4C1wNJUX38O8Ipz7jff49UZPL4xJsBsxMOY6DQb/YSf+nZLFvY3/9gd51wi8AtQw/dUHeA236WMRF/Cc+xSSsVU+1icieNW59TLMt+nOva3aLLxl4h8KCIdRaRAqm1fA94Wkeki8qSIVMtEDMaYALLEw5jodMA5tzr1DR2lSC3F96+kei4uE8fKho58pE5yagGVgSWpttufiX2fjgPwjXJcBNwArAN6Ar+JSGnf68+iScrnQCNgmYjcFcA4jDEZZImHMbFru+/fUqmeq32abRscuyMi+dB6i5W+p34Czjs50fHdDmYxxpVA45OeawKsOPbAOZfknJvunOsJXADkA65K9fofzrmBzrkrgXeAe7IYkzEmC6zGw5jYtRpYDzwrIj2A8sBTp9n2Kd9slE1AL+AIWrgJ8BKwQESGAsOAfUA14Grn3H1ZjLE/MF5EFqMFrK2AW9ECVkTkKvRyzmxgJ9AMKACsFJE8aFHseOBvoASatCzMYkzGmCywxMOYGOWcOyoiNwFvogWZS4D/Aac0HwN6AK+iM0d+Ba5yzu337WeZiFwC9ANmAdnRmS+fBSDGz0XkIbTIdABaz/GAc26yb5PdQFs0GcoLrAHucc7N8fUKKQK8h47q7PCdW/esxmWMyTxxznkdgzHGGGNihNV4GGOMMSZk/E48RCS7iPx8mjUgconIWF9XwYW2FoQxxhhj0pKREY9HOF7FfrK7gV3OuUrA62ixmTHGGGPMCfxKPETkbOBKdK5+WtoA7/vuTwBaiIicZltjjDHGxCh/Z7UMAB5Hp6mlpQw6LQ/nXJKI7AHOAv5JvZGIdAI6AeTOnbtOuXLlMhNzxEtJSSFbtvRzvsOHs5GcLOTNmxyCqELD33OPRrF47uvXr8c5h/1fjz3RdO7OQUY+SkfTuWfE77///o9zLj697dJNPHzz5Lc55xaLSNOsBOWcGw4MB6hatapbtWpVVnYXsWbOnEnTpk3T3W7WLNiyBW68MfgxhYq/5x6NYvHcmzZtyu7du1myZEn6G0ehWHzPj4mWc1+1Cu64A+bPT3fTf0XLuWeUiKz1Zzt/RjwaA9eISGsgN1BQRD5wzt2WapuNQFlgg2856kLonHmTBQkJ+u+RI5Azp7exGGNMLKpaFb76Kv3tjP/SHQtyzvV0zp3tnCsP3ARMPynpAF0Ou6PvfnvfNtYgJABGjoQePbyOwhhjYs+ePfDaa1CokNeRRJdMdy4VkT7AIufcJHT9g9EishptW3xTgOKLeTffDHGZWbbLGGNMlhw4APnyeR1F9MlQ4uGcmwnM9N3vler5Q8D1gQzMqDx5YOFC2LwZ2rb1OhpjjIkNzmnScV9WVxsyp4i9stsIFBdnNR7GGBNKv/0GV1zhdRTRyRaJiwAXXQQpKbBrFxQp4nU0xhgT/apXh5kzvY4iOtmIR4R47z144QWvozDGmOi3dSs8+aTV1wWLjXhEiI4dIQb70RhjTMhlywZ163odRfSyP2URInt2bSg2cqTXkRhjTPRKToaDB6FdO68jiV6WeESQ0qW1mY0xxpjgWLXKZrIEmyUeEaRKFS00/ftvryMxxpjoVKMGTJ3qdRTRzRKPCDN1Kgwf7nUUxhgTfVauhIcfztiCcCbjrLg0wlx3nd6MMcYEVpky2i3aBJeNeESgOXOgZ0+vozDGmOixZw/88Qc0bOh1JNHPRjwiUI0aULSo11EYY0z0+OMPGDMG6tTxOpLoZ4lHBDrrLL0GOX++ZefGGBMIdeta745QsUstEWrtWpg82esojDEm8k2dqkWlJjRsxCNCXXih3pyzCmxjjMmKSy+F887zOorYYSMeEWzxYmjTxusojDEmcq1ZA99/D+ec43UkscMSjwh2wQUwbJjXURhjTOTatg3++svrKGKLJR4RLC5OFzMaM8brSIwxJvIcPQoNGsDdd3sdSWyxxCPCZcsGv//udRTGGBN5Ro2Cxx7zOorYk25xqYjkBmYDuXzbT3DOPXPSNncA/YGNvqcGO+feDmyoJi3x8dCrl66mmCeP19EYY0zkuOsuSEz0OorY48+Ix2GguXOuFlAbaCUiDdLYbqxzrrbvZklHCP31FzRqpDNcjDHGpG/2bJ1GW6CA15HEnnRHPJxzDjiWE8b5bln+E/fPP7lISdFLBSZrKlSAefNsWq0xxvgrVy5ISvI6iuixfr3/2/r1Z19EsovIEmAb8K1zbmEam10nIstEZIKIlE1vnzt35uSWW+DQIf+DNae3fz/07u11FMYYE/527dI+SM2bex1JdPj5Z6hf3//txWVgfF5ECgOfAQ8555anev4sINE5d1hE7gNudM6d8paKSCegk96/sI5zP1Gz5h769VtOoUJH/Y86wiUmJpI/f/6A7jMpSZgypRTXXLMprEeRgnHukSIWz71r164kJyczaNAgr0PxRCy+58eE87lPmHA2hw9n49Zb1wVl/+F87oG2YEFRevc+j0OHsgOy2DmXbuP5DCUeACLSCzjgnHvlNK9nB3Y65wqdaT/ly1d3yckr2bABKlfWa22VKmUolIg1c+ZMmjZtGpR9r10b3o1wgnnu4S4Wz71p06bs3r2bJUuWeB2KJ2LxPT8m3M89mJf6w/3cA+XNN+Ghh/R7eeut8OGH/iUe6X7bRSTeN9KBiOQBWgK/nbRNqVQPrwFWprffXLlSWLgQatfWVQEbNNA6BZN5e/dC27Y6N90YY8yphg3TD7rhPDIc7lJSdBpyly56/+mnYfRo/7/en299KWCGiCwDfkRrPKaISB8Ruca3zcMi8quILAUeBu7w5+ClS2tlcevWsGOHXm8bN87/4M2JChaEn37SxmLGGGNO1bAhVK3qdRSR6+BBuOEGeOUVyJEDRo6EPn0yNrnBn1kty4AL03i+V6r7PYGe/h/2uAIFYOJEXRnwrbfgxht1eujjj9ssjcxIStIfig8+gHz5vI7GGGPCx/LlUK4cFC7sdSSRads2XR9swQL9oPvpp9CiRcb3ExaDTTlywJAhmkGJQI8ecN99dskgM+LioGtXnSpmjDHmuPHj4YcfvI4iMq1apSURCxZo8jZvXuaSDgiTxAM04ejWTX8wcueGESPg6qu1bsFkzCWXwPTpkJzsdSTGGBM+eveGyy7zOorIM3u2XqL66y+oU0eTj/POy/z+wibxOOa662DGDG0F/vXXcPHFsGGD11FFnjFjYMsWr6MwxpjwcPPNNtqRGR9+CC1bau+Tq6+GWbOgVKn0v+5Mwi7xgOPDOVWrwrJl2pgkRmfjZYqIFvyULu11JMYYEx5eegkuuMDrKCKHc9CvH9x2Gxw5otNmP/ssMLWDYZl4AJx7rl5DuuQS2LRJRz6mTvU6qshy1VWWsBljzLhxkDevXsY36Tt6FO6+W6fJisCAATBwIGTPHpj9h23iAVC0KHzzjTYmSUzUYZ633vI6qsgxYgTUquV1FMYY462lS72OIHLs2aMtLt59V1c8//RTeOSRwB4jrBMP0NkZo0dr5pWSAg88oI1LUlK8jiz8lS4NY8dqN1NjjIlFBw/Cc89BsWJeRxL+1q6Fxo3hu++geHGYOVObUgZa2CceoEM9ffpo3UKOHDrt9sYb9QfKnNnBg7qAnDHGxJqUFLjoIu0/Yc5s8WKtr/z1V6heXess69ULzrEiIvE45s474auvtHHJhAna6XT7dq+jCm933gkVK1qSZoyJPdmyaTfn4sW9jiS8TZ6s9ZRbtkDTpjB3LlSoELzjRVTiAdqwZN48bWCyYIFmaKtWeR1VePvvf2HSJK+jMMaY0ElJge7ddXaGOb3Bg/VyyoEDcPvt2saiSJHgHjPiEg/QxiULF0LduvDnn9rYZPZsr6MKX2+8oZemjDEmVhw9qpcM8uTxOpLwlJysH0qPrS777LPw/vuQM2fwjx2RiQdAyZJa+HLNNdrYpGVL+Ogjr6MKT3FxWmQ6caLXkRhjTGisX69TQm3Nr1MdOADt2+s02bg4TTieeSZ036uITTxAG5l8+qkuMHfkiE677dfPhtbSUqkSVK7sdRTGGBN827dDhw62bERatm6FZs3g88+hUCG9tNKhQ2hjiOjEA7ShyRtvaOYmotNu777bFpg7WZ06Or12zRqvIzHGmOCKj9dawEA1vIoWK1dqXeQPP0D58jB/viYhoRbxiccxjzyi7Vzz5NHGJ1dcAbt3ex1VeJkyRb9HxhgTrVavhltu8TqK8DNjBjRqBH//Df/5j07OqF7dm1iiJvEAaNNGF7ApUQKmTYMmTax5Vmq33aZV3sYYE63KlrXfcycbPRouv1w/jLdtq/WRJUp4F09UJR5wYib36686rLR4sddRhY85c+Cuu7yOwhhjAm/rVr3EctFFXkcSHpzT5psdOmj5Qdeu2gMrb15v44q6xAP02tW8edpgbMsWbYwyebLXUYWHiy6C3r29jsIYYwJv/XpYtMjrKMLDkSPaQPKZZ7SR2sCB8Prr4VH3EpWJB0DhwvDll9Cxo04datsWBg3yOirv5cundTAff+x1JMYYEzhHj2oR/WOPeR2J93bvhlatdJps3rxa2/fQQ15HdVy6iYeI5BaRH0RkqYj8KiKnfF4WkVwiMlZEVovIQhEpH4xgMypnTi007dNHG6Q8/LA2TIn1KVbZsullKGOMiRbvvANPPul1FN77+28tIp0xQ/tdzZ6t/a7CiT8jHoeB5s65WkBtoJWINDhpm7uBXc65SsDrwEuBDTPzjk2xHT1aG6UMGKCNUw4c8Doy7xQtqv1O9u3zOhJjjAmMTp2gRw+vo/DWjz9qXePKldrhe8ECHQUKN+kmHk4l+h7G+W4nt+hqA7zvuz8BaCESXv3ibrsNvvlGL8F8/rkuhLN1q9dReWfvXq33OHLE60iMMSZrPvtMP9kXLOh1JN6ZOBESEvTvWosW8P33cM45XkeVNnF+tPkUkezAYqASMMQ598RJry8HWjnnNvgerwHqO+f+OWm7TkAngPj4+Drjxo0LyElkxNq1eenZ83w2b85DyZIHeeGFXyhfPrTDH4mJieTPnz+kx0zLkSNCzpyhbfMaLufuhVg8965du5KcnMygGC2wisX3/JhQnvuSJYXImzeZKlUS0984BEL9vk+YUIY336yEc0KrVpt59NHfiYsLfQvvZs2aLXbO1U13Q+ec3zegMDADqHnS88uBs1M9XgMUO9O+qlSp4ryydatz9es7B84VKuTctGmhPf6MGTNCe8DTSE52rlMn5/btC90xw+XcvRCL556QkOBq1arldRieicX3/JhQnfvatc4dORKSQ/ktVOeelOTcww/r3zJwrm9f51JSQnLoNAGLnB+5RIZmtTjndvsSj1YnvbQRKAsgIjmAQsCOjOw7lIoXh+nToV072LNHq39HjfI6qtDLlk3PPbwuihljjP9efBG+/dbrKEJv/3649lqdJpszJ3zwATz1VGT8PvdnVku8iBT23c8DtAR+O2mzSUBH3/32wHRf9hO28uaF8ePh0Ud1GlbHjroscHhHHXjt2sEff8Dhw15HYowxGffmm7pERizZskXrFCdNgiJFtH7x1lu9jsp//ox4lAJmiMgy4EfgW+fcFBHpIyLHJum8A5wlIquBR4GIqC3Onh1efRUGD9ZP/717awISawWXAwZo8mGMMZHkhht04ctI+JQfKMc6ci9aBBUqaLPMhASvo8qYHOlt4JxbBlyYxvO9Ut0/BFwf2NBCp0sXrf696Saddrt+PXz6qWaSseC99/Rf52LrP7AxJrL16KGdqmPF9Ol6eWXPHqhfX0c8ihf3OqqMi9rOpRl11VU6HatUKV1Ap1Ej+Osvr6MKnUcf1elYxhgTCcaM0V4V4dACPBTef18XetuzR5OP6dMjM+kASzxOcNFFsHAh1KwJv/2mw1k//OB1VKHRtSu0bu11FMYYk75Dh/SDYrYY+AvmHPTqBXfcAUlJ0K2b1id6vdBbVsTA25YxZctq45WWLWHbNi3g+ewzr6MKvnLldBXfuXO9jsQYY87MOS0qjYvzOpLgOnxYV5bt21eTrCFD4JVXIj/hivDwg6NQIfjiC7jnHjh4EK67Tlf1i/YZL/v2WRt1Y0x4W7dOL4VH++/jXbv00soHH+jinhMnwgMPeB1VYFjicRpxcTB8ODz/vP6AP/qoru6XlOR1ZMFz2WX6g74jbDuwGGNiXblyOjIbzYXwf/4JDRvCrFladzh7ttYhRgtLPM5ABHr21CXkc+bUYa527SAxPLryBsUXX9iy0saY8LRiBbz8cmTXN6Rn4UKtL1y1SusNFy7U+sNoYomHH266Cb77Tld1nTJF50xv3ux1VMHRujW8/bbXURhjzKkKFYJatbyOIng+/VTrCrdv1zrD77/XusNoY4mHny6+GObPh4oV4aefdA71L794HVXgZcumfUzuu8/rSIwx5rgNG/T30+WXex1J4DmndYTt2+uMnXvu0dHnQoW8jiw4LPHIgCpVNPlo1Ej/ODdpEp1rBJQpA9dfH/3FW8aYyDF7tl72jjZJSVo/+Oij+jv3+ee1vjCaZ+xY4pFB8fEwbZq26t27Vy9NjBzpdVSBlSOHDvd99ZXXkRhjjP5BvuUW/eMcTRITtW5wyBCtI/zoI60rjObCWbDEI1Ny59bM+4knNFu9+25dFTCaRgic02lc+/d7HYkxJtbdfz9Mnep1FIG1aRNcconWDRYtqnWEN9/sdVShYYlHJmXLpssxDxumLXufe05XB4yWVV7j4uDDDzULN8YYLz33nP6Rjha//KIzV37+WesG58/XOsJYYYlHFnXqpBlr/vw6CtKyZXT1wWjRQldDNMYYLwwdCkeP6u/YaPDtt1ofuH699uqYP1/rB2OJJR4B0KqVTnsqUwbmzNEfptWrvY4qMCZO1IWYjDEm1JzTbsrR0rdj5EitC9y7Vwv4p03TusFYY4lHgNSqpY1eatWCP/44nslGuiJFYNQoW8PFGBN6GzdqQ8OCBb2OJGuc0zrAu+/WusDHH9fVdfPk8Toyb1jiEUDHRjxatYJ//oFmzXQVwUhXtiycdZbXURhjYkliIlx5pfa1iGSHD2v933PPaT3g0KHw0kuRv9BbVsTwqQdHgQIweTJ07qw/cDfcoC1+I3nGS7Nmul5AtFw+MsaEv/z5YckSnUUYqXbs0Lq/jz/W85k82ZozgiUeQZEjhy7Z/PLL+viJJ3Q6WCQvMPfllzBhgtdRGGNiwa+/QseOkd3PYs0abTY5Zw6ULq3/XnGF11GFh3QTDxEpKyIzRGSFiPwqIo+ksU1TEdkjIkt8t17BCTdyiOi1yfHjNWMfNgyuvjpyl52/6Sbo0SOyR26MMZGhUiX473+9jiLzfv21IA0awO+/wwUXaP1f7dpeRxU+/BnxSAK6OedqAA2ALiJSI43t5jjnavtufQIaZQRr3x6mT4dixbQT6MUXw/btubwOK1OWL9drrsYYEyzLl8OiRZH7h3rCBHj00Vr884+uKzNnDpx9ttdRhZd0Ew/n3Gbn3E+++/uAlUCZYAcWTRo2hAULdK720qXwwAMXsXSp11FlXI0aWhhljDHBsnWr9riINM5B//46TfbIkex06qQ1HZE+IycYxGVg7FxEygOzgZrOub2pnm8KfAJsADYB3Z1zp7SdEpFOQCeA+Pj4OuPGjctC6JFnz54c9OpVk2XLCpMnTxLPPLOC+vV3eh1Whhw+nI1PPjmbm25al6mq7MTERPJHSyegDIrFc+/atSvJyckMGjTI61A8EYvv+TGZOffExBzky5cUcbUdycnCwIGVmDRJP5PfccdKOnTYGnHnkVXNmjVb7Jyrm+6Gzjm/bkB+YDFwbRqvFQTy++63Bv5Ib39VqlRxsejQIedatNjiwLns2Z0bOtTriDImJcW5F1907sCBzH39jBkzAhpPJInFc09ISHC1atXyOgzPxOJ7fkxmzv2ee5z79NPAxxJMe/c617q1c+BcrlzOjRkTu+87sMj5kU/49ZlVROLQEY0PnXOfppG87HXOJfruTwXiRKSYP/uONblywZNPruSppyA5WafdPvEEpKR4HZl/RDTebdsie5aOMSb8DBsG11zjdRT+27hR15CZOlV7HU2bBjfe6HVU4c+fWS0CvAOsdM69dpptSvq2Q0Tq+fYbRSuWBJYI9O0L77yjU29ffllnjRw86HVk/uvWDZYt8zoKY0w0cA7uuAM2b9YmW5Fg2TKoX197jVSqpHV8jRt7HVVkyOHHNo2B24FfRGSJ77n/AeUAnHNDgfbA/SKSBBwEbvINu5gzuOsuKFcOrrtOp91u2KBro0RC7/7x4yN7jr0xJrzcdps2KowEX3+tRaT79mmy8fnnOnPR+CfdxMM59z1wxj8xzrnBwOBABRVLLr1U10Fp3VrXdmnYUIftwn21QhEYNEj/ffBBr6MxxkSq5GT9w92uXWS0ER8+HB54QOO+6SZ4993I7q7qhQh4m6NfzZraYOaii7TbXcOGOvc73F17LXTo4HUUxphI9s8/MGNG+I+gpqRAz57a8jw5We9/+KElHZlhiUeYKFUKZs2Cq66CnTt1JOTjj72O6szKlNFfGjE2K9oYEyBHjkDhwjB4cHgnHocOwS23wIsvag3K8OHw/PORMUITjuzbFkby59chxwcf1P+Qt9yiP9zhXi2zM7JakRhjwsQXX0CXLl5HcWb//KMfBMeO1UVAv/gC7r3X66gimyUeYSZ7dhg4EF5/XT8BPPmk/pAfPep1ZGk791ydErxhg9eRGGMiTbt2OtoRrv74Qy99z52rbc+//17boJusscQjDIlA167wySeQJ49Ou73yStizx+vI0rZ7t869P3LE60iMMZHitdfgu+/Ct0Zi7lxNOlav1nVjFizQBd9M1lniEcbatYOZM6F4cfj2W2jSBNat8zqqUxUuDIsXQ86cXkdijIkULVpAtWpeR5G2sWM1vh07dMbh7Nla02YCwxKPMFevnmba1arpqo0NGsBPP3kd1alE4OabicjF74wxoTV1KlSsGH6rtjoHL72k02QPH9bLyBMnam2HCRxLPCJAhQowbx40baqd/S65BKZM8TqqU/XqBeed53UUxphw5hxMmqR/2MPJ0aM6VbZHD33cvz+8+aZ2lzaBZYlHhChSRLvl3X477N8PbdrAkCFeR3Wi6tU1QYqEHiTGGG/s3w9Dh+raJuFi7164+moYMUJrTsaPh+7dw3uKbySzxCOC5MwJ778Pzz6rzWwefBAefVSb2YSLw4etyNQYk7b16+Hii8OrRcCGDRrT119r2/Pp06F9e6+jim6WeEQYEXjmGU1A4uJ02u3118OBA15Hplq2hGbN4O+/vY7EGBNuypbVpSHCZSRhyRJd6G3ZMl2mYsECncligssSjwjVoYNm6IUKwWef6R/7rVu9jkotWaKr1xpjzDGffaY9O8Jl+uyXX+pIx6ZN+u/8+VrwaoLPEo8I1qyZ/mcpXx5++EFnvKxc6XVUuubMhAnhNZxqjPFWw4ZaIB8Ohg7Vmo7ERO0Q/e23ULSo11HFDks8Ilz16jo8+J//6OWNRo2094fXjh7V5aJ37/Y6EmOM1776SuvSatb0No6UFHj8cbj/fq2Ne+op+OADyJXL27hijSUeUaBECU022rbVP/SXXQajR3sb07FC2MKFvY3DGOO9pUu977x88KD25+jfX6fIvvMO9O0bPvUmscQSjyiRN69e3ujaVUcbOnSAPn28vdxRubJ+mvjlF+9iMMZ4659/4IkndHTWK9u3ayfS8eOhYEGt77jrLu/iiXWWeESR7Nl1lsugQbpc8zPPwJ13eju9tUABjcsYE3v279eGh17Ouvv9d61/mz9fZ9XMnaurzRrvWOIRhR58ED7/XEdB3n8fWrXyrtaiTRstfv3tN2+Ob4zxTr58OlU1b15vjj9njha1/vmnFr0vWOB9nYnxI/EQkbIiMkNEVojIryLySBrbiIgMFJHVIrJMRC4KTrjGX1dfrQsblSwJM2Zo0alXvTW+/x5GjvTm2MYYbyxZUoiuXb1rOf7RRzqysXMnXHUVzJoFpUt7E4s5kT8jHklAN+dcDaAB0EVEapy0zRVAZd+tE/BWQKM0mVKnDixcqOunrFypjXJ+/DH0cVx2Gbz8MiQlhf7YxhhvVK++j06dQn9c5+D55+HWW/Uyc5cuOgKcP3/oYzFpSzfxcM5tds795Lu/D1gJnLxAcBtglFMLgMIiUirg0ZoMK1fu+DXNbdsgIUFXWwy1ffugVi04csSu7hkT7T7/HDZtyk2Nkz+iBtnRo3DvvfDkkzpb5bXXtObN6szCi7gMTHsQkfLAbKCmc25vquenAC8650qhkDIAACAASURBVL73PZ4GPOGcW3TS13dCR0SIj4+vM27cuKzGH5ESExPJH+L0OylJeO21Knz5ZSlEHA88sJr27TeGNIbdu+PIkWNXyM89XHjxvnuta9euJCcnM2jQIK9D8UQsvucA06YVp2TJ7Zx3Xuim1SUmZqd37/NYtKgouXIl8+STK7n44n9CdvwTY4nN971Zs2aLnXN1093QOefXDcgPLAauTeO1KUCTVI+nAXXPtL8qVaq4WDVjxgxPjpuS4ly/fs7pYKRzDz3kXFJSaGO45541btmy0B4zXHj1vnspISHB1apVy+swPBOL7/mKFfpvKM997VrnatbU32vx8c4tWBCyQ6cpFt9355wDFjk/8gm/xr1FJA74BPjQOfdpGptsBMqmeny27zkTRkR0CPLDD7XB16BB0K6dTnkLlWrV9hEfH7rjGWNC5/Bh6NRJl5kPlZ9+0umyy5dDtWo6c6V+/dAd32ScP7NaBHgHWOmce+00m00COvhmtzQA9jjnNgcwThNAx9YmKFIEJk/Wuo8tW0Jz7Dp1duGczqk3xkQP53TF7DlztElXKEyZon1CNm/W32Pz5sG554bm2Cbz/BnxaAzcDjQXkSW+W2sR6SwinX3bTAX+BFYDI4AHghOuCZRLLtE//ueeC4sX6yeEX38NzbHXrNFfEMaY6DFtGtxxR+iO9+ab2ido/3647TZdrbtIkdAd32ReujOsnRaMnrGbve/aTpdABWVCo2pVHZa85hr9t1Ej+OST4Hf1a9JEbzt2wFlnBfdYxpjQaNEiNM25UlLgscd0xgpAr17w7LO25koksbmNMS4+HqZPh/bt9brsFVfAu+8G/7j798PFF3vbStkYExiDBsEPP2jDwmA6cACuv16Tjhw54L33oHdvSzoijSUehjx5YOxY/RSRlKSLJz39dHAXmMuXT1es9KqVsjEmcGrWhLPPDu4xtm2D5s3h00+hUCH46ivo2DG4xzTBYYmHAXRRuZdfhrfe0vv9+sHtt2uVerDExUGPHvDFF8E7hjEmeJyDzz7TmrEyJ7eVDKDfftOZKwsXwjnnaI1YixbBO54JLks8zAk6d9ZK8fz5ddrtZZfpWgfBctdd0KxZ8PZvjAmexESYOlXrLoJl1ixd6O2vv6BuXa1HC3VHVBNYlniYU1xxhU6JK11aF5pr1EhnogRDlSqwaZMtImdMpDlwQGsrRozQ0ctg+OADaNlSV9e+5hqYOTP4dSQm+CzxMGmqXVuHNS+4AFat0mHOBQuCcyyr8zAm8kyapA0Jg8E56NtXL/cePQqPPKK1HfnyBed4JrQs8TCndfbZOvJx+eXwzz96SeSTTwJ/nNKl9ZLL3LnBLWg1xgSGc3DTTcentAbSkSP6+6BXLx1RGTBAb7bQW/SwxMOcUcGC2t20Uyc4dEinsr3ySuAThJQU/eWy2frdGhP2brwRliwJfDKwe7de6n3vPZ1t99lnOtphooslHiZdcXEwdCi89JImHI89Bl266NTbQMmWDcaP1+u31tvDmPD23HOBbxa2di00bqx9hUqU0KLSNm0CewwTHizxMH4Rgccf134fuXLptNs2bWDfvsAe57XX4I03ArtPY0xgbN+uPX4qVdIGXoGyaJHWka1YAdWraz3Zf/4TuP2b8GKJh8mQG27QNRnOOkun0V1yCWwM4DrEDz4ITzwRuP0ZYwInWzYd6Qhkp9BJk44vVNm8ufboKF8+cPs34ccSD5NhjRvrJ5LKlfU6b4MGsGxZYPadO7d2KGzTBpKTA7NPY0zWLV6sdV433hi4fQ4aBG3b6uXVjh3hyy+hcOHA7d+EJ0s8TKZUqqSr2zZpAhs26L9ffx2YfZcoodP0rIrdmPCxcGHgPmAkJ8N//wsPP6x1Y7176xpROXMGZv8mvFniYTLtrLPg2291Wt2+fXDllTB8eNb3KwL16mll+8qVWd+fMSZrtm6FBx7QGSdZtX8/XHedzmKLi4NRo45PnTWxwRIPkyW5c2tr9f/9Tz/F3Hefrr8SiBbKhQrpNWVjjHcSE7V7aCBmm23dqv2AJk7USyrffKNNwkxssV/rJsuyZdPpdSNG6OWRl16Cm2/W68FZ0a4dlC2rjcWMMaHnnK7b9PPPWe8wvGKF1oP9+KMWj86bB02bBiJKE2ks8TABc889OtOlQAEYNw4uvVQ7nmbFunU6omKMCb0RI/RDRVbrrWbM0DWf/v5bL6MuWKDTZk1sssTDBNRll+kIxbGRioYN4Y8/Mr+/atXgzTc1gbF26saEVocO+oEiK0aN0mUX9uzRUcwZM7SA3MSudBMPERkpIttEZPlpXm8qIntEZInv1ivwYZpIcv75+onmwgth9WpNPr7/Pmv7vPlm+OWXwMRnjDmzlBS4/37YuzfzSYJz8OyzOk326FGdxTJ+vC0KacCf3nPvAYOBUWfYZo5z7qqARGSiQunSMHu2znj54gto0UI/+WT2l9iXX2qnROes+t2YYBOBVq2gWLHMff2RI/DCC9X49lutAXvjDW0OaAz4MeLhnJsN7AxBLCbK5M8Pn3+u0/COHNEk5KOPymXqkkmOHFoBf++9gY/TGHPcmjX6YaFNm8zNKtu1S5OWb78tSd68+jvAkg6TWqC67TcUkaXAJqC7c+7XtDYSkU5AJ4D4+HhmzpwZoMNHlsTExJg69/btwbmzGTq0IiNGnMumTZvo2vUPcuTIaAYitG4dx8yZR4ISZ7DF2vsOsHv3bpKTk2PuvI+JxPd81aoC/PVXPvLn35Lhr928OTc9epzPunX5KFLkEC+8sJwCBRKJsG9BlkXi+x5Szrl0b0B5YPlpXisI5Pfdbw384c8+q1Sp4mLVjBkzvA7BE5984lzOnEkOnLvsMuf27Mn4PlJSnOvUybmNGwMfX7DF4vuekJDgatWq5XUYnom09/znn51LSsrc1y5c6Fzx4s6Bc+ed59yYMfMCG1wEibT3PVCARc6Pv/9ZntXinNvrnEv03Z8KxIlIJq8Mmmh27bXw+utLiI/XyyZNmsD69Rnbh4iOoBQtGpwYjYlVzunU2b/+yvjXfv659uTYtk2n0c+dCyVKHA54jCY6ZDnxEJGSIlruJyL1fPvckdX9muhUo8Y+FiyAqlV1lkr9+tqcKCNattRfjpMmBSdGY2JNcrIuezB+vK7D5C/ntPX5tdfCwYNw553ay6dQoeDFaiKfP9NpPwbmA1VFZIOI3C0inUWks2+T9sByX43HQOAm35CLMWk691ztWpiQAJs3w8UX6y+rjEhK0r4Axpis++abjBeAJifDI4/oNFnnoF8/eOcdXX/FmDNJt7jUOXdzOq8PRqfbGuO3okV1Ndt77oEPPoCrr9Ylsh94wL+vP/98vX3/vXZEtDVdjMmclBRd/K15c/+/Zv9+7a0zebKuKPvuu3DLLcGL0UQX+3VtPJMr1/GVKVNSoEsX6N7d/wXmUlJgyBAdNTHGZJxz2mNn9Wr9/+iPzZt1tHLyZChSRFeotqTDZIQlHsZTItC7t35iypEDXn0VbrhBrxenJ1s2+PhjKFnSkg9jMkME3n8fKlb0b/tff9WF3hYv1kum8+fDJZcEN0YTfSzxMGHhjjvgq6+0KO2TT3TYd9s2/7526lRNXowx/ps9G/r2hXLl/OsG/N13ellz3TpNPo4ViRuTUZZ4mLDRooUWnZ5zjv5Sa9AAfvst/a+76ipdSO5IZPYVM8YTNWtqh1F/vPuu1oHs3QvXXQfTp0N8fHDjM9HLEg8TVmrU0KSjbl2dMtuoEcyadeavEdHbpZfCypWhidOYSOUcvPii1kj95z/pb/v003DXXTqTrHt3GDcO8uQJTawmOlniYcJOyZIwc6auFbFrl/bt+OCDM3+NCEycCNWrhyREYyKWc5Avn97O5PBhuP12nSabLZuOKvbvbzPITNbZj5AJS/nyaa3HI4/oktq3367Xo8/UIaZIEVi4EO6+O3RxGhNJfvsNfvwRHnrozKMWO3fCZZfBhx/q/8XJk+H++0MXp4lulniYsJU9u3ZFfOMNHdHo1UuHfM9Uy1G7Njz+eOhiNCaSrFuXft3Un3/qJc7Zs6FUKZgzB1q3Dk18JjZY4mHC3sMP61oQefPCe+9pkdvu3WlvmyuXVto/80zGW7EbE81+/FFHMTp2PP02x4q6V63SBn0LF8KFF4YuRhMbLPEwEeGaa7TItEQJrahv3BjWrj399s2bQ/nyIQvPmLC2f78m4/v3n36bTz6BZs1g+3ZNUL7/HsqWDV2MJnak2zLdK3v37mXbtm0cPXrU61ACrlChQqyMsukXcXFxFC9enIIFCwbtGHXr6ieyK6+EFSt0gbkpU/T5kyUkwD//aPX+E0/416fAmGi0fbv2xzndekjOwWuvwWOP6f177tFCUltzxQRLWCYee/fuZevWrZQpU4Y8efIgUfZXY9++fRQoUMDrMALGOcfBgwfZuHEjQFCTj/LldcntY70EEhK0e+k115y6bb58kD+//jKNsh8hY/w2cCBUqKD1USdLStJLmW+9pY9feMESdRN8YXmpZdu2bZQpU4a8efNGXdIRjUSEvHnzUqZMGbb52240CwoXhi+/1G6nBw5A27b6y/VkefLoipuLFsGyZUEPy5iwk5gIffro/5W0XmvTRpOOnDlhzBjo0cOSDhN8YZl4HD16lDzWoSbi5MmTJ2SXxnLmhJEjj0+xfeQR6NpVl+o+2d9/21ouJvb89tvxzqQn997YtEnXWJk6VVeKnjYNbrwx9DGa2BSWiQdgIx0RKNTvmQg89RSMHq3Xo994Qy/BnFxAd8MNcPnluormmfqAGBMtkpKgWjX45ptTRzB++UXro37+GSpV0rqpJk28idPEprBNPIzx1223aVJRpIh2L23aFLZsOXGbpCQYNQp27PAkRGNCqlUrWL5cp6Cn9s03OiNswwbt1TF/PlSu7E2MJnZZ4mGiQkKCLjBXoYLWdDRooDNfjsmRQ0dGChTQpb2NiUbO6e3DD+G880587e23tRHYvn06CjhtGhQr5k2cJrZZ4mGiRrVqOmxcv772+GjUSGe+pPbzz2kXohoTDT76SOueSpQ4foklJQX+9z+4916tgXriCZ0Jlju3t7Ga2JVu4iEiI0Vkm4gsP83rIiIDRWS1iCwTkYsCH6Yx/ileHGbMgGuvhT17tLbj/fePv96gAQwbppdiDh3yLk5jgqFtW7jzzuOPDx2CW2/VabLZs+vP/osv2kJvxlv+/Pi9B7Q6w+tXAJV9t07AW1kPK3I1bdqUBx980PN9pGfXrl2UKFGCNWvWpLvt9ddfz6uvvhrUeAIpTx4YPx66ddPajjvu0K6NqQtL+/bVoWZjosG2bXD11bpkwLFuozt26MrOY8ZoP5spU6BTJ2/jNAb8SDycc7OBnWfYpA0wyqkFQGERKRWoAE1wPP/887Ru3ZqKFSumu22vXr147rnn2LNnTwgiC4xs2eCVV2DIEL3fp4+uUXH4sL4+eLB2QA1B2xFjgi4+XhdRzOFrCbl6NTRsqG3Py5TRf1ud6eOjMSEUiM6lZYD1qR5v8D13SucEEemEjooQHx/PzJkz09xhoUKF2LdvXwBCC73k5GSOHDlyxviTk5PTfT29fWTGkSNHyJkzJwcOHODtt99m7Nixfh2jfPnylC9fnrfffptO6XxkOnTo0GnfV4DExMQzvh5oNWpAv35F6dPnPEaPzs6yZbvp23c5BQokcfhwNh544CIGDvyZfPnSaAASYKE+93Cwe/dukpOTY+68jwnFez54cCVat97MuefuZ+ZMWL68IE89VZM9e3JSsWIiL7ywjF27jhDqtyAWf96PieVz94tzLt0bUB5YfprXpgBNUj2eBtRNb59VqlRxp7NixYpTnjterx3aW0YlJCS4+++/3/Xs2dOdddZZLj4+3nXr1s0lJyf/+/q99957wtd07NjRXXnllSfs47777nMPP/ywK1y4sCtcuLDr3r37v/twzrmUlBT30ksvuXPPPdflzp3b1axZ040ePfqUWDp37uy6devmihUr5urWreucc278+PGuSJEiLiUl5d9tX3rpJQeccnv66aedc8717t3bNW7cON3zT+u9S23GjBnp7iMYfvrJuVKl9D2tWtW5NWv0+aNHnUtJcW7nzuDH4NW5eykhIcHVqlXL6zA8E4r3fM4c5w4c0PvjxjmXK5f+nLdq5dzevUE//GnF4s/7MbF67sAi50dOEYgSo41A6jUMz/Y9F7M+/PBDcuTIwbx58xg8eDADBgxg7NixGd5HSkoK8+fPZ9iwYQwfPpwBAwb8+/pTTz3FO++8w5AhQ1ixYgU9e/bkvvvu44svvjhhPx988AHOOebMmcOoUaMAmDNnDnXq1Dmh4df999/P5s2b/71169aNkiVL0qFDBwDq1avHDz/8wMGDBzP7bfHUhRfqEt/nn69LfjdooI9z5NBh6Hvv9TpCYzLmyy9hxAht/pU7N7z8sk6TPXwYOneGyZN1+rgx4SYQl1omAQ+KyBigPrDHORfwBtWR1HGyRo0a9OnTB4AqVaowYsQIpk2bxs033+z3PkqVKsXAgQMREapVq8bvv//Oa6+9xqOPPsr+/ft57bXX+Oabb7j44osBqFChAj/88ANDhgzhyiuv/Hc/FSpUOKUwdO3atZQuXfqE5woUKPDvwnUvvfQSH3/8MTNnzqRSpUoAlC5dmqNHj7Jp0ya/6kLCUdmymmRcf702UmraVPsdXHst1KsHBw9qB9QcYbl0ojEnql5dazuSknRNomHD9PmXX4bu3W3NFRO+/JlO+zEwH6gqIhtE5G4R6SwinX2bTAX+BFYDI4AHghZthLjgggtOeFy6dOkML57WoEGDE0YkGjZsyMaNG9m7dy8rVqzg0KFDtGrVivz58/97e+utt06ZpVKnTp1T9n3w4EFyn2YS/wsvvMCgQYOYMWMGVatW/ff5Y2vnROqIxzEFC2p1/z336FTD9u11SfCcOeHppzURMSacbdqkaxOdcw5UraqzWYYN0xkt48bp8vaWdJhwlu5nO+fcGT+m+67rdAlYRFEgLi7uhMciQkpKCgDZsmU7Vgvzr4wurHZsX5MnT6ZcuXJnPHa+fPlO+fpixYqxa9euU57v168fQ4cOPWGk45idO3ViU3x8fIZiDUdxcTB8OFSsCD176rTbNWu010GBArrWSxrfNmPCQpEi0KIFbNwIV10FS5dqB9KJE7VpnjHhztrIhFh8fDxbt2494bmlS5eest3ChQtPSFAWLFhA6dKlKViwIDVq1CBXrlysXbuWSpUqnXA755xz0o3hwgsvZEXqfuJAnz59GD58OLNmzTol6QBYvnw5ZcqUoUSJEv6ealgT0SXAx4zR0Y4334RbbtF20k2baudTY8JJSgr897+wd6+OdjRooElH5crasdeSDhMpLPEIsebNm/Ptt98yadIkVq1axaOPPsr69etP2W7Tpk107dqVVatWMWHCBPr3789///tfQOsxunfvTvfu3Rk5ciSrV69myZIlDB06lOHDh6cbw+WXX87KlSvZ4VsxrV+/fgwcOJAxY8aQL18+tmzZwpYtWziUqrXnnDlzuPzyywP0XQgfN96ojcSKFoUvvtCk4+OP9Rd7hM7oNlFKRHtz/PCDFpRu3Kj/zp+vo3fGRApLPELsrrvu4rbbbuOuu+6icePGFChQgHbt2p2y3a233kpycjL169fn3nvv5e677/438QDo27cvzz77LK+88grnnXceLVu25JNPPqFChQrpxnD++edTr149xowZg3OO/v37s2PHDho3bkypUqX+vc2dOxfQ3hyfffYZ90bp1I8mTfQTY6VKupZLs2aajFxyia5tYYzXhgzRwujdu6FdO0hMhJtv1lWZzzrL6+iMySB/5twG45bRPh7RZK+Xk+t9vvzyS1elShWXlJSU7raDBw92LVu29Gu/4drHwx/btzvXqJH2QChQwLmJE7XHx549gdl/OJ97sFgfjxkB2c/Mmc517ny8v9CTTzqXqq1PWIrFn/djYvXc8bOPh00cjFGtWrWiS5cubNiwId26kLi4OAYNGhSiyLxTrJiOdNxxB4wdq9NsO3fWvggjRngdnYlFX38Ny5drz5nx448v9Hb33V5HZkzmWeIRwx5++GG/tkuvTXo0yZ1blxavUEFX8RwyRKcn7t6tr9lS4iaUypSBxx+HZct0xtWECXDZZV5HZUzWWI2HMSfJlk2n1g4frp8w+/eHxo1h5EivIzOxYvVqbXTXtq0mHWXLwty5lnSY6GCJhzGnce+9OtOlQAFYsUJHQpYs0WmNxgTT+vV6mWXNGm33v2CBtvs3JhpY4mHMGVx+uc4mOPts/cR58cXw6adeR2WiVWIi1KqlP3f79sGVV8Ls2XDSCgfGRDRLPIxJxwUX6CfO2rX1D0PnzvD++15HZaJNcjIMGqSXVo4ehQcegM8/h/z5vY7MmMCy4lJj/FCmjH7yvPFGXRX0zjv1j8M993gdmYkGR45o07otW7RR2CuvaJdSW3PFRCMb8TDGTwUKwKRJOuLhnNaAdOwYWSsnm/CzdauuubJli86amjABHn3Ukg4TvWzEw5gMyJFD13WpWFGn2Y4apYvODR2qrxmTEevXa9Honj26xP2kSboGizHRzEY8jMkgEejeXRs65c4N77yjBYF79ngdmYkk06dDvXr6c1OlitYRWdJhYoElHgHWrl07ihQpQvv27b0OxQRZ+/YwY4YuMLdihc542bDB66hMJJg6FVq10ssrCQm60Nu553odlTGhYYlHgD3yyCOMGjUqw1+3fv16mjZtSo0aNbjgggsYP358EKIzgdagga4WWqUK/PIL1KihvT6MOZ2+fbWm4+hRuPVW7ddRtKjXURkTOpZ4BFjTpk0pUKBAhr8uR44cDBgwgBUrVvDNN9/QtWtX9u/fH4QITaBVrKifWBs00N4LF1+sn2iNSS0lReuCevXSguSnn4bRoyFXLq8jMya0LPEIE6VKlaJ27doAlCxZkmLFirFz506PozL+KloUZs6EW27RXh9XXaUFp8YAHDyoTcFeeUWLkN99F/r0sZkrJjb5lXiISCsRWSUiq0WkRxqv3yEi20Vkie9m3Q2yYPHixSQnJ1O2bFmvQzEZkCsXfPAB9Oypn2jvvx+6drUW67Fu2zZo3hy++w7y5IGvvtIVkI2JVekmHiKSHRgCXAHUAG4WkRppbDrWOVfbd3s7wHHGjJ07d9KhQweGDx/udSgmE0Tg+ed1pku2bPDGG9p07OBBryMzXli3Ls+/nW/LlYMff4QWLbyOyhhv+TPiUQ9Y7Zz70zl3BBgDtAluWNHp5ZdfRkQoWLAgIvLvrVevXgAcPnyYtm3b0qNHDxo1auRxtCYr7rpLP9keW8q8YUPYvTvO67BMCM2aBV26XMTWrVp0vHAhnHee11EZ4z1/Eo8ywPpUjzf4njvZdSKyTEQmiEjMXiO49NJLuf7665k6dSpnn3028+fP//e1+++/n82bN/PHH3+wefNmunXrRsmSJenQoQPOOe644w6aN2/O7bff7uEZmEBp2RLmzdPGUEuX6h+hVau8jsqEwocf6shGYmIcV1+tM59KlvQ6KmPCg7h0+j2LSHuglXPuHt/j24H6zrkHU21zFpDonDssIvcBNzrnmqexr05AJ4D4+Pg648aNS/OYhQoVolKlSpk8pfCXnJzMwIEDGTp0KFOmTKFy5crMnz+fVq1aUbNmzX+3Gz58OOdF2Eek1atXs+cMnbQSExPJH2OrXu3YkZOzb3+Cgwezc0Xu73jxxV+oVSs2uo117dqV5ORkBg0a5HUoIZGcDEOHVmTChLLMoClFixxi+/gXyZ7d68hCLxb/rx8Tq+ferFmzxc65uulu6Jw74w1oCHyd6nFPoOcZts8O7Elvv1WqVHGns2LFitO+Fg2eeeYZV6ZMGbdq1SqvQwm49N67GTNmhCaQMJPUJMH9mL+xA+dy5nRu9GivIwqNhIQEV6tWLa/DCIndu5278krnwDkR5zZUSnC7YuTc0xKr/9edi91zBxa5dP72O+f8utTyI1BZRCqISE7gJmBS6g1EpFSqh9cAK/3Yb4Y9+6zeQBs2/f47LF4Mderoc926wauv6v3SpWHTJp3i2LSpPtepExyr2SxQQHsuTJ4MV1+tz91yC3z00bFzynh8qes20roB9OvXjxEjRjBz5kyqVKmS8YOYiJQ9O1Q8N5GHHtKVSG+/XRcCO3rU68hMIPzxh6658sUXOrX6u+90RWNjTBr8yU6A1sDvwBrgSd9zfYBrfPdfAH4FlgIzgGrp7TMaRzzWrVvnEhISXPXq1d3555/vxo0bd8LrvXv3dmXLlnVLlizxKMLgsxGP01i3zs0bO9Y559yAAc5lz66fjP/zH+e2bPE4tiCKhRGPL790rlAhfT/Ll3duzRrfC6ne81gUs//XXeyeOwEc8cA5N9U5V8U5V9E595zvuV7OuUm++z2dc+c552o555o5534LaHYUIc7UfbRfv34MHDiQMWPGkC9fPrZs2cKWLVs4dOiQx1GbkChblsPFiwPwyCM64+Gss3R65UUXaedTE1mSk7UL6RVX6EJvbdrAsmWp1lxJ9Z4bY46zzqUBdLruo845+vfvz44dO2jcuDGVK1emVKlSlCpVirlz53octQmJsWOJnz7934eNG8Py5dpefdMmaNIEBg3SxmMm/G3erC3y+/bVx//7H3z6qV7C/ddJ77kxRlniESSpu4+KCHv27Pl3mGnv3r3/3m9h3YRiw1tvUWbSCaVRlCwJ06ZB587a3fThh7XV+vbtHsVo/PLtt1C7NixaBIUL63v43HPaMO4EabznxhhLPILCuo8af8XFwVtvwdixULCgLi53/vnwzTdeR2ZOduQIPPkkXHaZtkFv0QJWrtR26MYY/1niEWDWfdRkxg03wC+/QKNGsHWrLijWpQscPux1ZAb0valVS9vhi8BTT+ly9tYUzJiMs8QjUDkT8gAAC0hJREFUgJx1HzVZUK4czJ59fNXSN9/UqeKLFnkdWexKSoIXXtAC4N9+0/do5kyt7YjFpmDGBIIlHgE0d+5cxo4dy+eff07t2rWpXbs2v/zyi9dhmQiSPTs8/bTOcqlYEX79FerVg8cegwMHvI4utqxapd/7//1PE5DOnfX9uOQSryMzJrLl8DqAaNKkSRNSbA10k5YJE/h17lwa+7l5/fq6vssTT+jIxyuv6PofH3xgNQXBdvCgjjq9+qo2eCtWTL/3l12WwR1l8D03JlbYiIcxoVCsGEcLFcrQl+TLB4MH65Lq556rUzhbtNAOu9u2BSnOGDd1qq4g++KLmnTcead2Jc1w0gGZes+NiQWWeBgTCu+9R8mvvsrUl9arp7Mn+vaFHDng44+hcmX9RH7kSIDjjFHr18N118GVV8Jff0HNmlpvM3KkTpnNlCy858ZEM0s8jAmFLP4RyplTZ1IsXw6tWsHevdC9O1SvrusNWeOxzNm9G3r21BGlTz+FPHl0tOOnn7S5W5ZY4mFMmizxMCaCVK0KX36plwTOOQf+/BOuuUY7n/7wg9fRRY7Dh6F/f/0evviiFo9ec40uPPnEE9pfxRgTHJZ4GBOBrrhCaw8GDNBP6fPmaUFqQoJNvz2TpCR47z1d3frxx3Xk6JJLdBbRxIlw9tleR2hM9AvbxMPZ2HHEsfcstOLidMG59euhRw/InVvrEv7zH01MfvrJ6wjDx4EDWqhbubIWjK5bp3UcX3yhfTkaNPA6QmNiR1gmHnFxcRw8eNDrMEwGHTx4kDgbow65s87SJlfr1mm/jzx54KuvtPlYQoJ+kk9O9jpKb+zapeuonHMOPPQQ/P03VKqkRaNLlkDr1tqszRgTOmGZeBQvXpyNGzdy4MAB+xQdAZxzHDhwgI0bN1LclgFP29SpLHvxxaAeIj4eXn5Z/7h27Qr58+sISNu2emnhtdd0+fZo5xz8+CPcey+ULq1Fuf/8o2vgfPKJdiC9884QdB4NwXtuTCQKywZiBQsWBGDTpk0cPXrU42gC79ChQ+TOndvrMAIqLi6OEiVK/PvemZPkzUtKiN7z4sXh9dfh2Wfh7bf1EsOff0K3btoV9brroGNHaNo0utp+790LH30Ew4fDzz8ff75ePV1jpXnzEI9uhPA9NyaShGXiAZp8ROsfsZkzZ3LhhRd6HYYJpTffpPTvv+tf+xApVEiTja5dYcoUHQ2ZNw9Gj9ZbmTK6ON1dd2nTrEi85JCYqHUa48frOR5bVK9AAU2uunSBatU8Cs6D99yYSBC2iYcxUWXcOIrv3u3JobNnhzZt9LZ6Nbz7rrYAX7tWR0Zefx3KltV6h+uu01keuXJ5Eqpftm2D777TRmrffQeHDh1/rXZtrXO59lottvWUh++5MeHMEg9jYkilSlps2a+fjn68+y58/rnOjBk2TG85c2qTsoQEaNQILrzQ20Rk716YNQumTdNY16498fU6dbSNfPv2unqsMSa8+ZV4iEgr4A0gO/C2c+7Fk17PBYwC6gA7gBudc38HNlRjTKCIQOPGehs2DBYu1EsWEyfqCqyTJukNNOmoVg2aNYNatfR+tWpZaCV+Gs7paMbSpToV+PvvtVfJ77+fuF2uXNpVtHVruP56671hTKRJN/EQkezAEKAlsAH4UUQmOedWpNrsbmCXc66SiNwEvATcGIyAjTGBlT27jmw0aqSjIevW6SWM6dO1G+off2gysHTpiV9XtKj2xShfXutJypWDEiV0NddcubTPyO7dsH9/DubPh/37Yd8+HcHYt09fW79eL/+sXq0zTw4cSDu+GjX0UlGLFtCwYXhfCjLGnJmkN11VRBoCzzrnLvc97gngnHsh1TZf+7aZLyI5gC1AvDvDzvPmzevq1asXgFOIPLt376ZwoD8uRoiYPfclS0hKSiJH3bpeR5JhSUnHk4XERE0gDh+GlBR/vnqJ79/afh0rWzbImxcKFtTpwAUK6ONsYTnxPx0R/J4HQsz+Xyd2z33WrFmLnXPp/sD7c6mlDLA+1eMNQP3TbeOcSxKRPcBZwD+pNxKRTkAn38PDs2bNWu7H8aNRMU763sSQ2D73WbNi8dyLgX/nnZKiyU1iYrBDCplYfc8h1v+vx+a5V/Vno5AWlzrnhgPDAURkkT+ZUTSyc7dzjyWxet5g527nHltExK+VovwZwNwIlE31+Gzfc2lu47vUUggtMjXGGGOM+Zc/icePQGURqSAiOYGbgEknbTMJ6Oi73x6Yfqb6DmOMMcbEpnQvtfhqNh4Evkan0450zv0qIn2ARc65ScA7wGgRWQ3sRJOT9AzPQtyRzs49NsXqucfqeYOde6yK1XP367zTndVijDHGGBMokThJzRhjjDERyhIPY4wxxoRMWCQeItJNRJyIFPM6llARkb4iskxElojINyJS2uuYQkFE+ovIb75z/0xEYqbLjohcLyK/ikiKiMTEVDsRaSUiq0RktYj08DqeUBGRkSKyTURiqleRiJQVkRkissL3s/6I1zGFiojkFpEfRGSp79x7ex1TqIlIdhH5WUSmnGk7zxMPESkLXAas8zqWEOvvnLvAOVcbmAL08jqgEPkWqOmcuwD4HejpcTyhtBy4FpjtdSChkGq5hSuAGsDNIlLD26hC5j2glddBeCAJ6OacqwE0ALrE0Ht+GGjunKuFtuptJSINPI4p1B4BVqa3keeJB/A68DgQU1Wuzrm9qR7mI0bO3zn3jXMuyfdwAdoXJiY451Y651Z5HUcI1QNWO+f+dM4dAcYAbTyOKSScc7PRGX4xxTm32Tn3k+/+PvSPUBlvowoNp4713I3z3WLi9zqAiJwNXAm8nd62niYeItIG2OicW5ruxlFIRJ4TkfXArcTOiEdqdwFfeh2ECZq0lluIiT9CBkSkPHAhsNDbSELHd6lhCbAN+NY5FzPnDgxABxHSXcUp6C3TReQ7oGQaLz0J/A+9zBKVznTuzrmJzrkngSd9C+89CDwT0gCDJL3z9m3zJDos+2EoYws2f87dmGgnIvmBT4CuJ43uRjXnXDJQ21e79pmI1HTORX2dj4hcBWxzzi0WkabpbR/0xMM5d2laz4vI+UAFYKmI/L+9e2eNIoyjMP6cQtBCOwXBIo3YWwiSSkVQCQkiiuIFwUq/gd/AykYLm3QGwcJOQQRTWggiXogfIIWNYqMELP4Ws4EU0cRi3gk7z6/bZYszLDt7Zua9QHfL/V2SY1X1te9cLfzt2DexBLxgSorHVsed5CYwB5yathVu/+M7H4PtbLegKZNkF13pWKqqZ0PnGUJV/UiyTDfOZ+qLBzALzCc5B+wG9iV5XFXXNvvwYI9aqupjVR2oqpmqmqG7DXt0WkrHVpIc3vByAfgyVJaWkpyhux03X1W/hs6jXm1nuwVNkXRXkYvASlXdHzpPS0n2r8/SS7IHOM1IzutVdbeqDk3+yy/TbZuyaemAnTG4dKzuJfmU5APd46axTDt7COwFXk2mEj8aOlArSc4nWQWOA8+TvBw6U58mg4jXt1tYAZ5W1edhU7WR5AnwBjiSZDXJraEzNTILXAdOTn7f7ydXwWNwEFienNPf0o3x+Oe00rFyyXRJktSMdzwkSVIzFg9JktSMxUOSJDVj8ZAkSc1YPCRJUjMWD0mS1IzFQ5IkNWPxkNSbJK83LCS1luTS0JkkDcsFxCT1Lslt4ARwZbKRlqSR6n2TOEnjluQGcBa4YOmQZPGQ1JskF4GrwEJV/R46j6ThWTwk9SLJHHAHmKuqtaHzSNoZHOMhqRdJvgHfgZ+Ttx5U1eKAkSTtABYPSZLUjNNpJUlSMxYPSZLUjMVDkiQ1Y/GQJEnNWDwkSVIzFg9JktSMxUOSJDXzB5b7K5bKyAo5AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 648x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kas2BJhGcbYS"
      },
      "source": [
        "**Note**: For better performance, we should use a vectorized implementation, as in this example. Moreover, if we want to benefit from TensorFlow’s graph features, we should use only TensorFlow operations.\n",
        "\n",
        "It is also preferable to return a tensor containing one loss per instance, rather than returning the mean loss. This way, Keras can apply class weights or sample weights when requested.\n",
        "\n",
        "\n",
        "Next, we can just use this loss when we compile the Keras model, then train our model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2JYPbPbc3wK",
        "outputId": "d8250319-d007-4afc-e71c-1541824c7f27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "input_shape = X_train.shape[1:]\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
        "                       input_shape=input_shape),\n",
        "    keras.layers.Dense(1),\n",
        "])\n",
        "\n",
        "model.compile(loss=huber_fn, optimizer=\"nadam\", metrics=[\"mae\"])\n",
        "model.fit(X_train_scaled, y_train, epochs=2,\n",
        "          validation_data=(X_valid_scaled, y_valid))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5429 - mae: 0.8978 - val_loss: 0.2136 - val_mae: 0.5082\n",
            "Epoch 2/2\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.2104 - mae: 0.5058 - val_loss: 0.1942 - val_mae: 0.4824\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f45b8ef6630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB8f746YdlG3"
      },
      "source": [
        "For each batch during training, Keras will call the `huber_fn()` function\n",
        "to compute the loss, and use it to perform a Gradient Descent step. Moreover, it will keep track of the total loss since the beginning of the epoch, and it will display the mean loss."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnpnaNhjdHYJ"
      },
      "source": [
        "### Saving and Loading Models That Contain Custom Components"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1JGecBNdLXU"
      },
      "source": [
        "Saving a model containing a custom loss function actually works fine, as Keras just saves the name of the function. However, whenever we load it, we need to provide a dictionary that maps the function name to the actual function. More generally, when we load a model containing custom objects, we need to map the names to the objects:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tckqT8H6w4H_"
      },
      "source": [
        "model.save(\"my_model_with_a_custom_loss.h5\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyPpOl9ndQwV"
      },
      "source": [
        "model = keras.models.load_model(\"my_model_with_a_custom_loss.h5\",\n",
        "                                custom_objects={\"huber_fn\": huber_fn})"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqXJssV9w-se",
        "outputId": "56039b8e-dd93-4271-e4a7-c633ee36b0e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "model.fit(X_train_scaled, y_train, epochs=2,\n",
        "          validation_data=(X_valid_scaled, y_valid))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2015 - mean_absolute_error: 0.4947 - val_loss: 0.1867 - val_mean_absolute_error: 0.4713\n",
            "Epoch 2/2\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.1972 - mean_absolute_error: 0.4880 - val_loss: 0.2022 - val_mean_absolute_error: 0.4878\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f45ad9a65c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfb8_rbUdbAv"
      },
      "source": [
        "With the current implementation, any error between -1 and 1 is considered “small”. But what if we want a different threshold? One solution is to create a function that creates a configured loss function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcTncK8Zddgb"
      },
      "source": [
        "def create_huber(threshold=1.0):\n",
        "    def huber_fn(y_true, y_pred):\n",
        "        error = y_true - y_pred\n",
        "        is_small_error = tf.abs(error) < threshold\n",
        "        squared_loss = tf.square(error) / 2\n",
        "        linear_loss = threshold * tf.abs(error) - threshold**2 / 2\n",
        "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
        "    return huber_fn\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pchxAJWxDl5"
      },
      "source": [
        "model.compile(loss=create_huber(2.0), optimizer=\"nadam\", metrics=[\"mae\"])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djNyjg8NxE3w",
        "outputId": "9ba19024-6c9b-4316-dd8b-684bddc3b4ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "model.fit(X_train_scaled, y_train, epochs=2,\n",
        "          validation_data=(X_valid_scaled, y_valid))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2179 - mae: 0.4878 - val_loss: 0.2302 - val_mae: 0.4763\n",
            "Epoch 2/2\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.2149 - mae: 0.4836 - val_loss: 0.2152 - val_mae: 0.4689\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f45ab82ce80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Syo6l8ddsvF"
      },
      "source": [
        "Unfortunately, when we save the model, the threshold will not be saved. This means that we will have to specify the threshold value when loading the model (note that the name to use is \"`huber_fn`\", which is the name of the function we gave Keras, not the name of the function that created it):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nn_oUV1AxLuT"
      },
      "source": [
        "model.save(\"my_model_with_a_custom_loss_threshold_2.h5\")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mU4sMy-d0V5"
      },
      "source": [
        "model = keras.models.load_model(\"my_model_with_a_custom_loss_threshold_2.h5\",\n",
        "                                custom_objects={\"huber_fn\": create_huber(2.0)})"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r34NCHLwxN-I",
        "outputId": "3cfb0473-9a8b-4486-d4c0-f3fc3694d806",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "model.fit(X_train_scaled, y_train, epochs=2,\n",
        "          validation_data=(X_valid_scaled, y_valid))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.2108 - mean_absolute_error: 0.4790 - val_loss: 0.1951 - val_mean_absolute_error: 0.4565\n",
            "Epoch 2/2\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.2073 - mean_absolute_error: 0.4739 - val_loss: 0.2024 - val_mean_absolute_error: 0.4563\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f45ab6fc828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vxb5-pFad5eY"
      },
      "source": [
        "We can solve this by creating a subclass of the `keras.losses.Loss` class, and implement its `get_config()` method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxJR6AdUd_Xj"
      },
      "source": [
        "class HuberLoss(keras.losses.Loss):\n",
        "    def __init__(self, threshold=1.0, **kwargs):\n",
        "        self.threshold = threshold\n",
        "        self.name = \"HuberLoss\"\n",
        "        super().__init__(**kwargs)\n",
        "    def call(self, y_true, y_pred):\n",
        "        tf.name_scope(\"name\")\n",
        "        error = y_true - y_pred\n",
        "        is_small_error = tf.abs(error) < self.threshold\n",
        "        squared_loss = tf.square(error) / 2\n",
        "        linear_loss = self.threshold * tf.abs(error) - self.threshold**2 / 2\n",
        "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "        return {**base_config, \"threshold\": self.threshold}"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1k9kLcXUfFsm"
      },
      "source": [
        "- The constructor accepts `**kwargs` and passes them to the parent constructor, which handles standard hyperparameters: the name of the loss and the reduction algorithm to use to aggregate the individual instance losses. By default, it is \"`sum_over_batch_size`\", which means that the loss will be the sum of the instance losses, possibly weighted by the sample weights, if any, and then divide the result by the batch size (not by the sum of weights, so this is not the weighted mean). Other possible values are `\"sum\"` and `None`.\n",
        "\n",
        "- The `call()` method takes the labels and predictions, computes all the instance losses, and returns them.\n",
        "\n",
        "- The `get_config()` method returns a dictionary mapping each hyperparameter name to its value. It first calls the parent class’s `get_config()` method, then adds the new hyperparameters to this dictionary (note that the convenient {`**x`} syntax was added in Python 3.5).\n",
        "\n",
        "We can then use any instance of this class when we compile the model:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Dd_bzPBxdtV"
      },
      "source": [
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
        "                       input_shape=input_shape),\n",
        "    keras.layers.Dense(1),\n",
        "])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HECxWDvUfyuT"
      },
      "source": [
        "model.compile(loss=HuberLoss(2.), optimizer=\"nadam\", metrics=[\"mae\"])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-J4s-YTxjh0",
        "outputId": "b83c5ee3-2f3a-49a5-95a4-6d2aec9b2808",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "model.fit(X_train_scaled, y_train, epochs=2,\n",
        "          validation_data=(X_valid_scaled, y_valid))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.8064 - mae: 0.9606 - val_loss: 0.3456 - val_mae: 0.5691\n",
            "Epoch 2/2\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.2475 - mae: 0.5175 - val_loss: 0.2299 - val_mae: 0.4930\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f45aa61c0b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dipUHNTHf0Cp"
      },
      "source": [
        "When we save the model, the threshold will be saved along with it, and when we load the model we just need to map the class name to the class itself:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9CxRJpBxmWs"
      },
      "source": [
        "model.save(\"my_model_with_a_custom_loss_class.h5\")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0ADVtNQf4N_",
        "outputId": "af679b5c-30be-4171-fa24-3daaba3b64aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model = keras.models.load_model(\"my_model_with_a_custom_loss_class.h5\",\n",
        "                                custom_objects={\"HuberLoss\": HuberLoss})\n",
        "print(model.loss.threshold)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVaXRvuzxsZm",
        "outputId": "b40a2663-483d-46f3-b50a-2e6cf87a3f22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "model.fit(X_train_scaled, y_train, epochs=2,\n",
        "          validation_data=(X_valid_scaled, y_valid))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2309 - mean_absolute_error: 0.5017 - val_loss: 0.2424 - val_mean_absolute_error: 0.5028\n",
            "Epoch 2/2\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.2259 - mean_absolute_error: 0.4964 - val_loss: 0.2107 - val_mean_absolute_error: 0.4785\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f45b8db6e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfO6fQalf8zg"
      },
      "source": [
        "When we save a model, Keras calls the loss instance’s `get_config()` method and saves the config as JSON in the HDF5 file. When we load the model, it calls the `from_config()` class method on the `HuberLoss` class: this method is implemented by the base class (`Loss`) and just creates an instance of the class, passing `**config` to the constructor.\n",
        "\n",
        "**Note**: The Keras API only specifies how to use subclassing to define layers, models, callbacks, and regularizers. If we build other components (such as losses, metrics, initializers or constraints) using subclassing, they may not be portable to other Keras implementations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piQZq_OogSSf"
      },
      "source": [
        "### Custom Activation Functions, Initializers, Regularizers, and Constraints"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyKYr8CxgZDO"
      },
      "source": [
        "Most Keras functionalities, such as losses, regularizers, constraints, initializers, metrics, activation functions, layers and even full models can be customized in very much the same way. Most of the time, we will just need to write a simple function, with the appropriate inputs and outputs. For example, here are examples of a custom activation function (equivalent to `keras.activations.softplus`), a custom Glorot initializer (equivalent to `keras.initializers.glorot_normal`), a custom $l_1$ regularizer (equivalent to `keras.regularizers.l1(0.01)`) and a custom constraint that ensures weights are all positive (equivalent to `keras.constraints.nonneg()`):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ar19foEKx-F9"
      },
      "source": [
        "keras.backend.clear_session()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GnEhVGPg4nl"
      },
      "source": [
        "def my_softplus(z): # return value is just tf.nn.softplus(z)\n",
        "    return tf.math.log(tf.exp(z) + 1.0)\n",
        "\n",
        "def my_glorot_initializer(shape, dtype=tf.float32):\n",
        "    stddev = tf.sqrt(2. / (shape[0] + shape[1]))\n",
        "    return tf.random.normal(shape, stddev=stddev, dtype=dtype)\n",
        "\n",
        "def my_l1_regularizer(weights):\n",
        "    return tf.reduce_sum(tf.abs(0.01 * weights))\n",
        "\n",
        "def my_positive_weights(weights): # return value is just tf.nn.relu(weights)\n",
        "    return tf.where(weights < 0., tf.zeros_like(weights), weights)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z42bwJVQhBQ4"
      },
      "source": [
        "As we can see, the arguments depend on the type of custom function. These custom functions can then be used normally, for example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xy9wRtDUhCpL"
      },
      "source": [
        "layer = keras.layers.Dense(30, activation=my_softplus,\n",
        "                           kernel_initializer=my_glorot_initializer,\n",
        "                           kernel_regularizer=my_l1_regularizer,\n",
        "                           kernel_constraint=my_positive_weights)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dw03Sn7cyJak"
      },
      "source": [
        "The activation function will be applied to the output of this `Dense` layer, and its result will be passed on to the next layer. The layer’s weights will be initialized using the value returned by the initializer. At each training step, the weights will be passed to the regularization function to compute the regularization loss, which will be added to the main loss to get the final loss used for training. Finally, the constraint function will be called after each training step, and the layer’s weights will be replaced by the constrained weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjEcZCEwyJ1i",
        "outputId": "484f6afd-7315-4edb-fa4e-54192c4b9bd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
        "                       input_shape=input_shape),\n",
        "    keras.layers.Dense(1, activation=my_softplus,\n",
        "                       kernel_regularizer=my_l1_regularizer,\n",
        "                       kernel_constraint=my_positive_weights,\n",
        "                       kernel_initializer=my_glorot_initializer),\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[\"mae\"])\n",
        "\n",
        "model.fit(X_train_scaled, y_train, epochs=2,\n",
        "          validation_data=(X_valid_scaled, y_valid))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 1.7394 - mae: 0.8748 - val_loss: inf - val_mae: inf\n",
            "Epoch 2/2\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.7544 - mae: 0.5274 - val_loss: inf - val_mae: inf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f45a746f6d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvpXCzDMyTKc"
      },
      "source": [
        "model.save(\"my_model_with_many_custom_parts.h5\")"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjBAqzmHyToy"
      },
      "source": [
        "model = keras.models.load_model(\n",
        "    \"my_model_with_many_custom_parts.h5\",\n",
        "    custom_objects={\n",
        "       \"my_l1_regularizer\": my_l1_regularizer,\n",
        "       \"my_positive_weights\": my_positive_weights,\n",
        "       \"my_glorot_initializer\": my_glorot_initializer,\n",
        "       \"my_softplus\": my_softplus,\n",
        "    })"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krqkUufZhYUx"
      },
      "source": [
        "If a function has some hyperparameters that need to be saved along with the model, then we will want to subclass the appropriate class, such as `keras.regularizers.Regularizer`, `keras.constraints.Constraint`, `keras.initializers.Initializer` or `keras.layers.Layer` (for any layer, including activation functions). For example, much like we did for the custom loss, here is a simple class for $l_1$ regularization, that saves its `factor` hyperparameter (this time we do not need to call the parent constructor or the `get_config()` method, as they are not defined by the parent class):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h98vbTy8iDUA"
      },
      "source": [
        "class MyL1Regularizer(keras.regularizers.Regularizer):\n",
        "    def __init__(self, factor):\n",
        "        self.factor = factor\n",
        "    def __call__(self, weights):\n",
        "        return tf.reduce_sum(tf.abs(self.factor * weights))\n",
        "    def get_config(self):\n",
        "        return {\"factor\": self.factor}"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVMoEDXmiINf"
      },
      "source": [
        "Note that we must implement the `call()` method for losses, layers (including activation functions) and models, or the `__call__()` method for regularizers, initializers and constraints. For metrics, things are a bit different, as we will see now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_QD6S5oyjmG",
        "outputId": "0c977078-a0e9-407b-9b63-cc35bc577968",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "import keras\n",
        "keras.backend.clear_session()\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
        "                       input_shape=input_shape),\n",
        "    keras.layers.Dense(1, activation=my_softplus,\n",
        "                       kernel_regularizer=MyL1Regularizer(0.01),\n",
        "                       kernel_constraint=my_positive_weights,\n",
        "                       kernel_initializer=my_glorot_initializer),\n",
        "])\n",
        "\n",
        "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[\"mae\"])\n",
        "\n",
        "model.fit(X_train_scaled, y_train, epochs=2,\n",
        "          validation_data=(X_valid_scaled, y_valid))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 1.6036 - mae: 0.8791 - val_loss: inf - val_mae: inf\n",
            "Epoch 2/2\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.6325 - mae: 0.5165 - val_loss: inf - val_mae: inf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f45a626a6d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAn5IKMYywkC"
      },
      "source": [
        "model.save(\"my_model_with_many_custom_parts.h5\")"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0LMN-gXyzKW"
      },
      "source": [
        "model = keras.models.load_model(\n",
        "    \"my_model_with_many_custom_parts.h5\",\n",
        "    custom_objects={\n",
        "       \"MyL1Regularizer\": MyL1Regularizer,\n",
        "       \"my_positive_weights\": my_positive_weights,\n",
        "       \"my_glorot_initializer\": my_glorot_initializer,\n",
        "       \"my_softplus\": my_softplus,\n",
        "    })"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2wtP1qeiQQJ"
      },
      "source": [
        "### Custom Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXn6s4zGiRdq"
      },
      "source": [
        "Losses and metrics are conceptually not the same things: losses are used by Gradient Descent to train a model, so they must be differentiable (at least where they are evaluated) and their gradients should not be 0 everywhere. Plus, it’s okay if they are not easily interpretable by humans (e.g. cross-entropy). \n",
        "\n",
        "In contrast, metrics are used to evaluate a model, they must be more easily interpretable, and they can be non-differentiable or have 0 gradients everywhere (e.g., accuracy).\n",
        "\n",
        "That said, in most cases, defining a custom metric function is exactly the same as defining a custom loss function. In fact, we could even use the Huber loss function we created earlier as a metric (the Huber loss is seldom used as a metric, the MAE or MSE are preferred), it would work just fine (and persistence would also work the same way, in this case only saving the name of the function, \"`huber_fn`\" ):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZS_WO_VXGNK",
        "outputId": "36b98442-46f4-4b3d-b0f1-60b6f46d02c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
        "                       input_shape=input_shape),\n",
        "    keras.layers.Dense(1),\n",
        "])\n",
        "\n",
        "model.compile(loss=create_huber(2.0), optimizer=\"nadam\", metrics=[create_huber(2.0)])\n",
        "\n",
        "history = model.fit(X_train_scaled, y_train, epochs=2)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.8707 - huber_fn: 0.8707\n",
            "Epoch 2/2\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.2595 - huber_fn: 0.2595\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLytkxIWXfXG"
      },
      "source": [
        "Using the MSE like loss function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUdxidS6y70O"
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
        "                       input_shape=input_shape),\n",
        "    keras.layers.Dense(1),\n",
        "])"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS2A2ycbkUqr"
      },
      "source": [
        "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[create_huber(2.0)])"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ8FYh28zDWW",
        "outputId": "b1e5de4a-dd55-4892-8124-61197058194e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "model.fit(X_train_scaled, y_train, epochs=2)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 2.0962 - huber_fn: 0.9386\n",
            "Epoch 2/2\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4944 - huber_fn: 0.2413\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f45af5a9748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ffk3I9nck3_J"
      },
      "source": [
        "For each batch during training, Keras will compute this metric and keep track of its mean since the beginning of the epoch. Most of the time, this is exactly what we want. But not always! \n",
        "\n",
        "Consider a binary classifier’s precision, for example. The precision is the number of true positives divided by the number of positive predictions (including both true positives and false positives). Suppose the model made 5 positive predictions in the first batch, 4 of which were correct: that’s 80% precision. Then suppose the model made 3 positive predictions in the second batch, but they were all incorrect: that’s 0% precision for the second batch. If we just compute the mean of these two precisions, we get 40%. But wait a second, this is not the model’s precision over these two batches! Indeed, there were a total of 4 true positives (4 + 0) out of 8 positive predictions (5 + 3), so the overall precision is 50%, not 40%.\n",
        "\n",
        "What we need is an object that can keep track of the number of true positives and the number of false positives, and compute their ratio when requested. This is precisely what the `keras.metrics.Precision` class does:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTD1MS_7YQvr"
      },
      "source": [
        "import keras\n",
        "import tensorflow as tf"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qf35Tj3zlRpn",
        "outputId": "1bbbcb9e-2f76-476d-a707-9212cb6a34d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "precision = tf.keras.metrics.Precision()\n",
        "print(precision([0, 1, 1, 1, 0, 1, 0, 1], [1, 1, 0, 1, 0, 1, 0, 1]))\n",
        "print(precision([0, 1, 0, 0, 1, 0, 1, 1], [1, 0, 1, 1, 0, 0, 0, 0]))\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(0.8, shape=(), dtype=float32)\n",
            "tf.Tensor(0.5, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7hsAIrFlnDg"
      },
      "source": [
        "In this example, we created a `Precision` object, then we used it like a function, passing it the labels and predictions for the first batch, then for the second batch (note that we could also have passed sample weights). We used the same number of true and false positives as in the example we just discussed. After the first batch, it returns the precision of 80%, then after the second batch it returns 50% (which is the overall precision so far, not the second batch’s precision). This is called a streaming metric (or stateful metric), as it is gradually updated, batch after batch.\n",
        "\n",
        "At any point, we can call the `result()` method to get the current value of the metric. We can also look at its variables (tracking the number of true and false positives) using the `variables` attribute, and reset these variables using the `reset_states()` method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vScyDr4Unvhb",
        "outputId": "7a36840c-8acd-41ed-e0f2-1bda8cc5b00d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "print(precision.result().numpy())\n",
        "print(precision.variables)\n",
        "precision.reset_states() # both variables get reset to 0.0"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5\n",
            "[<tf.Variable 'true_positives:0' shape=(1,) dtype=float32, numpy=array([4.], dtype=float32)>, <tf.Variable 'false_positives:0' shape=(1,) dtype=float32, numpy=array([4.], dtype=float32)>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApEVawXon99J"
      },
      "source": [
        "If we need to create such a streaming metric, we can just create a subclass of the `keras.metrics.Metric` class. Here is a simple example that keeps track of the total Huber loss and the number of instances seen so far. When asked for the result, it returns the ratio, which is simply the mean Huber loss:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UpOIukIh_y_"
      },
      "source": [
        "class HuberMetric(keras.metrics.Metric):\n",
        "    def __init__(self, threshold=1.0, **kwargs):\n",
        "        super().__init__(**kwargs) # handles base args (e.g., dtype)\n",
        "        self.threshold = threshold\n",
        "        self.huber_fn = create_huber(threshold)\n",
        "        self.total = self.add_weight(\"total\", initializer=\"zeros\")\n",
        "        self.count = self.add_weight(\"count\", initializer=\"zeros\")\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        metric = self.huber_fn(y_true, y_pred)\n",
        "        self.total.assign_add(tf.reduce_sum(metric))\n",
        "        self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
        "    def result(self):\n",
        "        return self.total / self.count\n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "        return {**base_config, \"threshold\": self.threshold}"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFV3_IaGoUYi"
      },
      "source": [
        "- The constructor uses the `add_weight()` method to create the variables needed to keep track of the metric’s state over multiple batches, in this case, the sum of all Huber losses (`total`) and the number of instances seen so far (`count`). We could just create variables manually if we preferred. Keras tracks any `tf.Variable` that is set as an attribute (and more generally, any \"trackable\" object, such as layers or models).\n",
        "\n",
        "- The `update_state()` method is called when we use an instance of this class as a function (as we did with the `Precision` object). It updates the variables given the labels and predictions for one batch (and sample weights, but in this case we just ignore them).\n",
        "\n",
        "- The `result()` method computes and returns the final result, in this case just the mean Huber metric over all instances. When we use the metric as a function, the `update_state()` method gets called first, then the `result()` method is called, and its output is returned.\n",
        "\n",
        "- We also implement the `get_config()` method to ensure the `threshold` gets saved along with the model.\n",
        "\n",
        "- The default implementation of the `reset_states()` method just resets all variables to 0.0 (but we can override it if needed).\n",
        "\n",
        "When we define a metric using a simple function, Keras automatically calls it for each batch, and it keeps track of the mean during each epoch, just like we did manually. So the only benefit of our `HuberMetric` class is that the `threshold` will be saved. But of course, some metrics, like precision, cannot simply be averaged over batches: in those cases, there’s no other option than to implement a streaming metric."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vTH4BhZjUw2"
      },
      "source": [
        "class HuberMetric(keras.metrics.Mean):\n",
        "    def __init__(self, threshold=1.0, name='HuberMetric', dtype=None):\n",
        "        self.threshold = threshold\n",
        "        self.huber_fn = create_huber(threshold)\n",
        "        super().__init__(name=name, dtype=dtype)\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        metric = self.huber_fn(y_true, y_pred)\n",
        "        super(HuberMetric, self).update_state(metric, sample_weight)\n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "        return {**base_config, \"threshold\": self.threshold}\n"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUxAdKvQZtLr",
        "outputId": "24f4acdd-4d0e-4958-fc07-9735bad08e11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "m = HuberMetric(2.)\n",
        "\n",
        "m(tf.constant([[2.]]), tf.constant([[10.]]))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=14.0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFV2X_pNaCNO",
        "outputId": "725ae4e4-be7e-4929-e189-1ac1883055a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "m(tf.constant([[0.], [5.]]), tf.constant([[1.], [9.25]]))\n",
        "\n",
        "m.result()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=7.0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ne0W-zHjaEfS"
      },
      "source": [
        "m.reset_states()"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16hEc8xqaLCi"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "input_shape = X_train.shape[1:]\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
        "                       input_shape=input_shape),\n",
        "    keras.layers.Dense(1),\n",
        "])"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1QeVNMOaN-Y"
      },
      "source": [
        "model.compile(loss=create_huber(2.0), optimizer=\"nadam\", metrics=[HuberMetric(2.0)])\n",
        "\n",
        "history = model.fit(X_train_scaled.astype(np.float32), y_train.astype(np.float32),\n",
        "                    epochs=2)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npOS0a_laPYF"
      },
      "source": [
        "model.save(\"my_model_with_a_custom_metric.h5\")"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwnjLnhrtpkH"
      },
      "source": [
        "model = keras.models.load_model(\"/content/my_model_with_a_custom_metric.h5\",           # TODO: check PR #25956\n",
        "                               custom_objects={\"huber_fn\": create_huber(2.0),\n",
        "                                               \"HuberMetric\": HuberMetric})"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZOWTMCSt2Ii",
        "outputId": "5a2ff474-b76c-4436-9469-7936f90a0e75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "model.fit(X_train_scaled.astype(np.float32), y_train.astype(np.float32), epochs=2)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.2350 - huber_metric: 0.2350\n",
            "Epoch 2/2\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.2278 - huber_metric: 0.2278\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f45a84b1668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyYIPw4Dt9pT"
      },
      "source": [
        "In TF 2.2, tf.keras adds an extra first metric in model.metrics at position 0 (see [TF issue](https://github.com/tensorflow/tensorflow/issues/38150)). This forces us to use `model.metrics[-1]` rather than `model.metrics[0]` to access the HuberMetric."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHhatZr6t62q",
        "outputId": "524087c5-6e6a-4fa9-ca8e-ba589ea09689",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.metrics[-1].threshold"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8RMLKUApHUt"
      },
      "source": [
        "### Custom Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQ3ZNJN9pMMC"
      },
      "source": [
        "We may occasionally want to build an architecture that contains an exotic layer for which TensorFlow does not provide a default implementation. In this case, we will need to create a custom layer. Or sometimes we may simply want to build a very repetitive architecture, containing identical blocks of layers repeated many times, and it would be convenient to treat each block of layers as a single layer. For example, if the model is a sequence of layers A, B, C, A, B, C, A, B, C, then we might want to define a custom layer D containing layers A, B, C, and our model would then simply be D, D, D. Let’s see how to build custom layers.\n",
        "\n",
        "First, some layers have no weights, such as `keras.layers.Flatten` or `keras.layers.ReLU`. If we want to create a custom layer without any weights, the simplest option is to write a function and wrap it in a `keras.layers.Lambda layer`. For example, the following layer will apply the exponential function to its inputs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evZTX6gpmE-1",
        "outputId": "0b6574b1-207b-46e5-ecf4-c46a35340256",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "exponential_layer = keras.layers.Lambda(lambda x: tf.exp(x))\n",
        "exponential_layer([-1., 0., 1.])"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.36787945, 1.        , 2.7182817 ], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QC6eFANQmb-4"
      },
      "source": [
        "This custom layer can then be used like any other layer, using the sequential API, the functional API, or the subclassing API. We can also use it as an activation function (or we could just use `activation=tf.exp`, or `activation=keras.activations.exponential`, or simply `activation=\"exponential\"` ). The exponential layer is sometimes used in the output layer of a regression model when the values to predict have very different scales (e.g., $0.001$, $10.$, $1000.$).\n",
        "\n",
        "To build a custom stateful layer (i.e., a layer with weights), we need to create a subclass of the `keras.layers.Layer` class. For example, the following class implements a simplified version of the Dense layer:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xuM5O-jm4ti"
      },
      "source": [
        "class MyDense(keras.layers.Layer):\n",
        "    def __init__(self, units, activation=None, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.activation = keras.activations.get(activation)\n",
        "\n",
        "    def build(self, batch_input_shape):\n",
        "        self.kernel = self.add_weight(\n",
        "            name=\"kernel\", shape=[batch_input_shape[-1], self.units],\n",
        "            initializer=\"glorot_normal\")\n",
        "        self.bias = self.add_weight(\n",
        "            name=\"bias\", shape=[self.units], initializer=\"zeros\")\n",
        "        super().build(batch_input_shape) # must be at the end\n",
        "\n",
        "    def call(self, X):\n",
        "        return self.activation(X @ self.kernel + self.bias)\n",
        "\n",
        "    def compute_output_shape(self, batch_input_shape):\n",
        "        return tf.TensorShape(batch_input_shape.as_list()[:-1] + [self.units])\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "        return {**base_config, \"units\": self.units,\n",
        "                \"activation\": keras.activations.serialize(self.activation)}"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DduKzvv9u0cJ"
      },
      "source": [
        "- The constructor takes all the hyperparameters as arguments (in this example just `units` and `activation`), and importantly it also takes a `**kwargs` argument. It\n",
        "calls the parent constructor, passing it the `kwargs`: this takes care of standard arguments such as `input_shape`, `trainable`, `name`, and so on. Then it saves the hyperparameters as attributes, converting the `activation` argument to the appropriate activation function using the `keras.activations.get()` function (it\n",
        "accepts functions, standard strings like `\"relu\"` or `\"selu\"` , or simply `None`) (this function is specific to `tf.keras`, we could use `keras.activations.Activation` instead).\n",
        "\n",
        "- The `build()` method’s role is to create the layer’s variables, by calling the `add_weight()` method for each weight. The `build()` method is called the first\n",
        "time the layer is used. At that point, Keras will know the shape of this layer’s inputs, and it will pass it to the `build()` method (The Keras API calls this argument input_shape, but since it also includes the batch dimension, we prefer to call it batch_input_shape, same for `compute_output_shape()`), which is often necessary to create some of the weights. For example, we need to know the number of neurons in the previous layer in order to create the connection weights matrix (i.e., the `\"kernel\"`): this corresponds to the size of the last dimension of the inputs. At the end of the `build()` method (and only at the end), we must call the parent’s `build()` method: this tells Keras that the layer is built (it just sets `self.built = True`).\n",
        "\n",
        "- The `call()` method actually performs the desired operations. In this case, we compute the matrix multiplication of the inputs `X` and the layer’s kernel, we add the bias vector, we apply the activation function to the result, and this gives us the output of the layer.\n",
        "\n",
        "- The `compute_output_shape()` method simply returns the shape of this layer’s outputs. In this case, it is the same shape as the inputs, except the last dimension\n",
        "is replaced with the number of neurons in the layer. Note that in tf.keras, shapes are instances of the `tf.TensorShape` class, which we can convert to Python lists\n",
        "using `as_list()`.\n",
        "\n",
        "- The `get_config()` method is just like earlier. Note that we save the activation function’s full configuration by calling `keras.activations.serialize()` . \n",
        "\n",
        "You can now use a `MyDense` layer just like any other layer!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCnQxV_0m7UQ",
        "outputId": "1cbce995-e75e-46a9-c5fe-eb2472961a37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    MyDense(30, activation=\"relu\", input_shape=input_shape),\n",
        "    MyDense(1)\n",
        "])\n",
        "\n",
        "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
        "model.fit(X_train_scaled, y_train, epochs=2,\n",
        "          validation_data=(X_valid_scaled, y_valid))\n",
        "model.evaluate(X_test_scaled, y_test)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 2.2563 - val_loss: 0.9472\n",
            "Epoch 2/2\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.6485 - val_loss: 0.6219\n",
            "162/162 [==============================] - 0s 825us/step - loss: 0.5474\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5473727583885193"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgXyrvHcwkHR"
      },
      "source": [
        "**Note**: You can generally omit the `compute_output_shape()` method, as tf.keras automatically infers the output shape, except when the\n",
        "layer is dynamic (as we will see shortly). In other Keras implementations, this method is either required or by default it assumes the output shape is the same as the input shape.\n",
        "\n",
        "To create a layer with multiple inputs (e.g., `Concatenate`), the argument to the `call()` method should be a tuple containing all the inputs, and similarly, the argument to the `compute_output_shape()` method should be a tuple containing each input’s batch\n",
        "shape. To create a layer with multiple outputs, the `call()` method should return the list of outputs, and the `compute_output_shape()` should return the list of batch output shapes (one per output). For example, the following toy layer takes two inputs and returns two outputs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbONCkpKyP4t"
      },
      "source": [
        "class MyMultiLayer(keras.layers.Layer):\n",
        "    def call(self, X):\n",
        "        X1, X2 = X\n",
        "        return X1 + X2, X1 * X2\n",
        "\n",
        "    def compute_output_shape(self, batch_input_shape):\n",
        "        batch_input_shape1, batch_input_shape2 = batch_input_shape\n",
        "        return [batch_input_shape1, batch_input_shape2]"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoenicroxD3N"
      },
      "source": [
        "This layer may now be used like any other layer, but of course only using the functional and subclassing APIs, not the sequential API (which only accepts layers with\n",
        "one input and one output).\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-tP7r7qxESA"
      },
      "source": [
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "inputs1 = keras.layers.Input(shape=[2])\n",
        "inputs2 = keras.layers.Input(shape=[2])\n",
        "outputs1, outputs2 = MyMultiLayer()((inputs1, inputs2))"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fb3vmfNuxKVR"
      },
      "source": [
        "If our layer needs to have a different behavior during training and during testing (e.g., if it uses `Dropout` or `BatchNormalization` layers), then we must add a `training` argument to the `call()` method and use this argument to decide what to do. For example, let’s create a layer that adds Gaussian noise during training (for regularization), but does nothing during testing (Keras actually has a layer that does the same thing: `keras.layers.GaussianNoise`):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6agXABQxUTG"
      },
      "source": [
        "class AddGaussianNoise(keras.layers.Layer):\n",
        "    def __init__(self, stddev, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.stddev = stddev\n",
        "\n",
        "    def call(self, X, training=None):\n",
        "        if training:\n",
        "            noise = tf.random.normal(tf.shape(X), stddev=self.stddev)\n",
        "            return X + noise\n",
        "        else:\n",
        "            return X\n",
        "\n",
        "    def compute_output_shape(self, batch_input_shape):\n",
        "        return batch_input_shape"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Otrq5AGnxY8V",
        "outputId": "adf54c17-76d6-409c-d757-3b24a02d6b6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
        "model.fit(X_train_scaled, y_train, epochs=2,\n",
        "          validation_data=(X_valid_scaled, y_valid))\n",
        "model.evaluate(X_test_scaled, y_test)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4904 - val_loss: 0.5329\n",
            "Epoch 2/2\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4226 - val_loss: 0.4786\n",
            "162/162 [==============================] - 0s 781us/step - loss: 0.3990\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.39900389313697815"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEf-7KCIy0TP"
      },
      "source": [
        "With that, we can now build any custom layer we need! Now let’s create custom models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZ1guxUopMVm"
      },
      "source": [
        "### Custom Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBV3gfYvpPtx"
      },
      "source": [
        "We already looked at custom model classes when we discussed the subclassing API (see [notebook](https://github.com/victorviro/Deep_learning_python/blob/master/Keras_Functional_API.ipynb)). It is actually quite straightforward, just subclass the `keras.models.Model` class, create layers and variables in the constructor, and implement the `call()` method to do whatever you want the model to do. For example, suppose you want to build the model represented in the next figure:\n",
        "\n",
        "![](https://i.ibb.co/NTvMVbt/custom-model.png)\n",
        "\n",
        "The inputs go through a first dense layer, then through a residual block composed of two dense layers and an addition operation (a residual block adds its inputs to its outputs), then through this same residual block 3 more times, then through a second residual block, and the final result goes through a dense output layer. Note that this model does not make much sense, it’s just an example to illustrate the fact that we can easily build any kind of model we want, even containing loops and skip connections. To implement this model, it is best to first create a `ResidualBlock` layer, since we are going to create a couple of identical blocks (and we might want to reuse it in another model):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSC3sWwLp2zu"
      },
      "source": [
        "class ResidualBlock(keras.layers.Layer):\n",
        "    def __init__(self, n_layers, n_neurons, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.hidden = [keras.layers.Dense(n_neurons, activation=\"elu\",\n",
        "                                          kernel_initializer=\"he_normal\")\n",
        "                       for _ in range(n_layers)]\n",
        "\n",
        "    def call(self, inputs):\n",
        "        Z = inputs\n",
        "        for layer in self.hidden:\n",
        "            Z = layer(Z)\n",
        "        return inputs + Z"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBuOdK1Ep4sn"
      },
      "source": [
        "This layer is a bit special since it contains other layers. This is handled transparently by Keras: it automatically detects that the hidden attribute contains trackable objects (layers in this case), so their variables are automatically added to this layer’s list of variables. The rest of this class is self-explanatory. Next, let’s use the subclassing API to define the model itself:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTztNal4qCIf"
      },
      "source": [
        "class ResidualRegressor(keras.models.Model):\n",
        "    def __init__(self, output_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.hidden1 = keras.layers.Dense(30, activation=\"elu\",\n",
        "                                          kernel_initializer=\"he_normal\")\n",
        "        self.block1 = ResidualBlock(2, 30)\n",
        "        self.block2 = ResidualBlock(2, 30)\n",
        "        self.out = keras.layers.Dense(output_dim)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        Z = self.hidden1(inputs)\n",
        "        for _ in range(1 + 3):\n",
        "            Z = self.block1(Z)\n",
        "        Z = self.block2(Z)\n",
        "        return self.out(Z)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOI749ZXqNLm"
      },
      "source": [
        "We create the layers in the constructor and use them in the `call()` method. This model can then be used like any other model (compile it, fit it, evaluate it, and use it to make predictions). If we also want to be able to save the model using the `save()` method, and load it using the `keras.models.load_model()` function, you must implement the `get_config()` method (as we did earlier) in both the `ResidualBlock` class and the `ResidualRegressor` class. Alternatively, we can just save and load the weights using the `save_weights()` and `load_weights()` methods.\n",
        "\n",
        "\n",
        "The `Model` class is actually a subclass of the `Layer` class, so models can be defined and used exactly like layers. But a model also has some extra functionalities, including of course its `compile()`, `fit()`, `evaluate()` and `predict()` methods (and a few variants, such as `train_on_batch()` or `fit_generator()`), plus the `get_layers()` method (which can return any of the model’s layers by name or by index), and the `save()` method (and support for `keras.models.load_model()` and `keras.models.clone_model()`). So if models provide more functionalities than layers, why not just define every layer as a model? Well, technically we could, but it is probably cleaner to distinguish the internal components of our model (layers or reusable blocks of layers) from the model itself. The former should subclass the `Layer` class, while the latter should subclass the `Model` class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6btFM0DDqDyB",
        "outputId": "21942ee2-01a2-4b3d-88ca-e9b67b8faaa3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "X_new_scaled = X_test_scaled\n",
        "\n",
        "model = ResidualRegressor(1)\n",
        "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
        "history = model.fit(X_train_scaled, y_train, epochs=5)\n",
        "score = model.evaluate(X_test_scaled, y_test)\n",
        "y_pred = model.predict(X_new_scaled)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 9.1324\n",
            "Epoch 2/5\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 1.0578\n",
            "Epoch 3/5\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.8866\n",
            "Epoch 4/5\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5842\n",
            "Epoch 5/5\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.6448\n",
            "162/162 [==============================] - 0s 2ms/step - loss: 0.6481\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQV2o6Hj0M07",
        "outputId": "72053dfc-5245-4507-e69f-9648af21c1df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "source": [
        "model.save(\"my_custom_model.ckpt\")"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "INFO:tensorflow:Assets written to: my_custom_model.ckpt/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBPtKceL0PM4"
      },
      "source": [
        "model = keras.models.load_model(\"my_custom_model.ckpt\")"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Me4J0Wh30RfK",
        "outputId": "d39fe64c-8b9a-4f88-98f5-db2a850014ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "history = model.fit(X_train_scaled, y_train, epochs=5)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.9154\n",
            "Epoch 2/5\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4779\n",
            "Epoch 3/5\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4867\n",
            "Epoch 4/5\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5609\n",
            "Epoch 5/5\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5365\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HtIqCTc0UUf"
      },
      "source": [
        "We could have defined the model using the sequential API instead:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zy9WUv6U0We3"
      },
      "source": [
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "block1 = ResidualBlock(2, 30)\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
        "    block1, block1, block1, block1,\n",
        "    ResidualBlock(2, 30),\n",
        "    keras.layers.Dense(1)\n",
        "])\n"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kuzAZaP0aWl",
        "outputId": "60e3fe8d-4af2-4c5b-aa6c-92ef3c5f8630",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
        "history = model.fit(X_train_scaled, y_train, epochs=5)\n",
        "score = model.evaluate(X_test_scaled, y_test)\n",
        "y_pred = model.predict(X_new_scaled)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.8695\n",
            "Epoch 2/5\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4720\n",
            "Epoch 3/5\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.5537\n",
            "Epoch 4/5\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3809\n",
            "Epoch 5/5\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4012\n",
            "162/162 [==============================] - 0s 1ms/step - loss: 0.4852\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6kvQOT1pPqc"
      },
      "source": [
        "With that, we can quite naturally and concisely build almost any model that we find in a paper, either using the sequential API, the functional API, the subclassing API, or even a mix of these. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XueA3eUVpPgl"
      },
      "source": [
        "### Computing Gradients Using Autodiff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdOpVBQ3pMG5"
      },
      "source": [
        "To understand how to use autodiff (see notebook [TensorFlow’s autodifferentiation](https://github.com/victorviro/Deep_learning_python/blob/master/TensorFlow%E2%80%99s_autodifferentiation.ipynb)) to compute gradients automatically, let’s consider a simple toy function:\n",
        "\n",
        "$$f(w_1,w_2) = 3w_1^2+2w_1w_2$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BJWPYv9wKEF"
      },
      "source": [
        "def f(w1, w2):\n",
        "    return 3 * w1 ** 2 + 2 * w1 * w2"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dQUx5hVwOng"
      },
      "source": [
        "We can analytically find that the partial derivative of this function with regards to $w_1$,  $\\frac{∂f}{∂w_1}=6w_1+2w_2$ . We can also find that its partial derivative with regards to $w_2$ is $\\frac{∂f}{∂w_2}=2w_1$ . For example, at the point $(w1, w2) = (5, 3)$ , these partial derivatives are equal to 36 and 10, respectively, so the gradient vector at this point is $\\nabla f(5,3)=(36, 10)$.\n",
        "\n",
        "But if this were a neural network, the function would be much more complex, typically with tens of thousands of parameters, and finding the partial derivatives analytically by hand would be an almost impossible task. One solution could be to compute an approximation of each partial derivative by measuring how much the function’s output changes when you tweak the corresponding parameter:\n",
        "\n",
        "$$\\nabla f(5,3)≈(\\frac{f(w_1+\\epsilon,+w_2)}{\\epsilon}, \\frac{f(w_1,w_2+\\epsilon)}{\\epsilon})$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nt6P58jdx1lW",
        "outputId": "c5447c7d-46c5-4903-a0f2-eac85a06c1b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "w1, w2 = 5, 3\n",
        "eps = 1e-6\n",
        "gradients = (f(w1 + eps, w2) - f(w1, w2)) / eps, (f(w1, w2 + eps) - f(w1, w2)) / eps\n",
        "print(gradients)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(36.000003007075065, 10.000000003174137)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQvS2AyOyHO-"
      },
      "source": [
        "This works rather well and it is trivial to implement, but it is just an approximation, and importantly we need to call `f()` at least once per parameter (not twice, since we could compute `f(w1, w2)` just once). This makes this approach intractable for large neural networks. So instead we should use autodiff (see notebook [TensorFlow’s autodifferentiation](https://github.com/victorviro/Deep_learning_python/blob/master/TensorFlow%E2%80%99s_autodifferentiation.ipynb)). TensorFlow makes this pretty simple:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyhD23sZyGV7"
      },
      "source": [
        "w1, w2 = tf.Variable(5.), tf.Variable(3.)\n",
        "with tf.GradientTape() as tape:\n",
        "    z = f(w1, w2)\n",
        "    gradients = tape.gradient(z, [w1, w2])"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsFHSEGjo9ID"
      },
      "source": [
        "We first define two variables `w1` and `w2`, then we create a `tf.GradientTape` context that will automatically record every operation that involves a variable, and finally, we ask this tape to compute the gradients of the result z with regards to both variables `[w1, w2]`. Let’s take a look at the gradients that TensorFlow computed:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6PNl24kzarq",
        "outputId": "236ea0ee-eb6b-40ef-8e3c-9d46ac5a7d77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "gradients"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzYYRJorzjqg"
      },
      "source": [
        "Not only is the result accurate (the precision is only limited by the floating-point errors), but the `gradient()` method only goes through the recorded computations once (in reverse order), no matter how many variables there are, so it is incredibly efficient.\n",
        "\n",
        "**Note**: We just put the strict minimum inside the `tf.GradientTape()` block, to save memory. Alternatively, we can pause recording by creating a `with tape.stop_recording()` block inside the `tf.GradientTape()` block.\n",
        "\n",
        "The tape is automatically erased immediately after we call its `gradient()` method, so we will get an exception if we try to call gradient() twice:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0ES48h_0NUL",
        "outputId": "64263f9b-85fa-47ed-f480-bc8350f5083e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "with tf.GradientTape() as tape:\n",
        "    z = f(w1, w2)\n",
        "    \n",
        "dz_dw1 = tape.gradient(z, w1) # => tensor 36.0\n",
        "try:\n",
        "    dz_dw2 = tape.gradient(z, w2) # RuntimeError!\n",
        "except Exception as err:\n",
        "    print(err)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GradientTape.gradient can only be called once on non-persistent tapes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5X_qS7W0TR0"
      },
      "source": [
        "If we need to call `gradient()` more than once, we must make the tape persistent, and delete it when you are done with it to free resources:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OqHOVGw0ZtU"
      },
      "source": [
        "with tf.GradientTape(persistent=True) as tape:\n",
        "    z = f(w1, w2)\n",
        "    \n",
        "dz_dw1 = tape.gradient(z, w1) # => tensor 36.0\n",
        "dz_dw2 = tape.gradient(z, w2) # => tensor 10.0, works fine now!\n",
        "del tape"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzSzapVNASv3"
      },
      "source": [
        "By default, the tape will only track operations involving variables, so if we try to compute the gradient of `z` with regards to anything else than a variable, the result will be `None`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsqHMvvXAWOx",
        "outputId": "1cd22b9a-fd87-4500-b668-dff786e05a16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "c1, c2 = tf.constant(5.), tf.constant(3.)\n",
        "with tf.GradientTape() as tape:\n",
        "    z = f(c1, c2)\n",
        "\n",
        "gradients = tape.gradient(z, [c1, c2])\n",
        "gradients"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, None]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7itjSOZAiAE"
      },
      "source": [
        "However, we can force the tape to watch any tensors we like, to record every operation that involves them. We can then compute gradients with regards to these tensors, as if they were variables:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTc1AGvWApBO",
        "outputId": "e3979512-87bc-4ae3-d10a-271d37e678c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "with tf.GradientTape() as tape:\n",
        "    tape.watch(c1)\n",
        "    tape.watch(c2)\n",
        "    z = f(c1, c2)\n",
        "\n",
        "gradients = tape.gradient(z, [c1, c2])\n",
        "gradients\n"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9KKilIOA0cc"
      },
      "source": [
        "This can be useful in some cases, for example, if you want to implement a regularization loss that penalizes activations that vary a lot when the inputs vary little: the loss will be based on the gradient of the activations with regards to the inputs. Since the\n",
        "inputs are not variables, you would need to tell the tape to watch them.\n",
        "\n",
        "If you compute the gradient of a list of tensors (e.g., `[z1, z2, z3]` ) with regards to some variables (e.g., `[w1, w2]` ), TensorFlow actually efficiently computes the sum of the gradients of these tensors (i.e., gradient `(z1, [w1, w2])`, plus gradient `(z2, [w1, w2])`, plus gradient `(z3, [w1, w2])`). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNwOnp_HBhW7",
        "outputId": "5a9fedf8-b1ef-48fc-e8bd-e51bf6755d79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "with tf.GradientTape() as tape:\n",
        "    z1 = f(w1, w2 + 2.)\n",
        "    z2 = f(w1, w2 + 5.)\n",
        "    z3 = f(w1, w2 + 7.)\n",
        "\n",
        "tape.gradient([z1, z2, z3], [w1, w2])"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(), dtype=float32, numpy=136.0>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=30.0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EcwSXprBh9A"
      },
      "source": [
        "Due to the way reverse-mode autodiff works, it is not possible to compute the individual gradients (`z1`, `z2` and `z3`) without actually calling `gradient()` multiple times (once for `z1`, once for `z2` and once for `z3`),\n",
        "which requires making the tape persistent (and deleting it afterward)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RM8WsugxBiYI"
      },
      "source": [
        "with tf.GradientTape(persistent=True) as tape:\n",
        "    z1 = f(w1, w2 + 2.)\n",
        "    z2 = f(w1, w2 + 5.)\n",
        "    z3 = f(w1, w2 + 7.)\n",
        "\n",
        "tf.reduce_sum(tf.stack([tape.gradient(z, [w1, w2]) for z in (z1, z2, z3)]), axis=0)\n",
        "del tape"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E46tAtXPBqN3"
      },
      "source": [
        "In some rare cases, we may want to stop gradients from backpropagating through some part of our neural network. To do this, we must use the `tf.stop_gradient()`\n",
        "function: it just returns its inputs during the forward pass (like `tf.identity()`), but it does not let gradients through during backpropagation (it acts like a constant). For example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJ6kkX34B6Gq",
        "outputId": "d31096be-6710-486c-c00e-8d1b2a691bd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def f(w1, w2):\n",
        "    return 3 * w1 ** 2 + tf.stop_gradient(2 * w1 * w2)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    z = f(w1, w2)\n",
        "\n",
        "tape.gradient(z, [w1, w2])"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(), dtype=float32, numpy=30.0>, None]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djfiuvGPCBuC"
      },
      "source": [
        "Finally, you may occasionally run into some numerical issues when computing gradients. For example, if you compute the gradients of the `my_softplus()` function for\n",
        "large inputs, the result will be NaN:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Tdcr4DTCG9z",
        "outputId": "7f5f95e5-7270-4184-dc56-68025ce81530",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = tf.Variable(100.)\n",
        "with tf.GradientTape() as tape:\n",
        "    z = my_softplus(x)\n",
        "\n",
        "tape.gradient(z, [x])"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(), dtype=float32, numpy=nan>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sI-4ZA9DCNGt"
      },
      "source": [
        "This is because computing the gradients of this function using autodiff leads to some numerical difficulties: due to floating-point precision errors, autodiff ends up computing infinity divided by infinity (which returns NaN). Fortunately, we can analytically find that the derivative of the softplus function is just $\\frac{1}{1+\\frac{1}{e^x}}$, which is numerically stable. Next, we can tell TensorFlow to use this stable function when\n",
        "computing the gradients of the `my_softplus()` function, by decorating it with `@tf.custom_gradient` , and making it return both its normal output and the function\n",
        "that computes the derivatives (note that it will receive as input the gradients that were backpropagated so far, down to the softplus function, and according to the chain rule we should multiply them with this function’s gradients):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHotbfjBCywd"
      },
      "source": [
        "@tf.custom_gradient\n",
        "def my_better_softplus(z):\n",
        "    exp = tf.exp(z)\n",
        "    def my_softplus_gradients(grad):\n",
        "        return grad / (1 + 1 / exp)\n",
        "    return tf.math.log(exp + 1), my_softplus_gradients"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oemC42W9DRGH"
      },
      "source": [
        "Now when we compute the gradients of the `my_better_softplus()` function, we get the proper result, even for large input values (however, the main output still explodes because of the exponential: one workaround is to use `tf.where()` to just return the\n",
        "inputs when they are large)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nm5DCW0zDcE2"
      },
      "source": [
        "def my_better_softplus(z):\n",
        "    return tf.where(z > 30., z, tf.math.log(tf.exp(z) + 1.))"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teP5h4SbDJnK",
        "outputId": "90d2302b-8adb-4f19-d90f-bc1bc248082b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "x = tf.Variable([1000.])\n",
        "with tf.GradientTape() as tape:\n",
        "    z = my_better_softplus(x)\n",
        "\n",
        "z, tape.gradient(z, [x])"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1000.], dtype=float32)>,\n",
              " [<tf.Tensor: shape=(1,), dtype=float32, numpy=array([nan], dtype=float32)>])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZv-DGHfpYfX"
      },
      "source": [
        "### Custom Training Loops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeja-KT4pYbJ"
      },
      "source": [
        "In some rare cases, the `fit()` method may not be flexible enough for what we need to do. For example, if we want to use two different optimizers. Since the `fit()` method only uses one optimizer (the one that we specify when compiling the model), implementing this requires writing our own custom loop.\n",
        "\n",
        "We may also like to write our own custom training loops simply to feel more confident that it does precisely what we intended it to do (perhaps we are unsure about\n",
        "some details of the `fit()` method). It can sometimes feel safer to make everything explicit. However, remember that writing a custom training loop will make our code longer, more error-prone, and harder to maintain.\n",
        "\n",
        "**Note**: Unless we really need the extra flexibility, we should prefer using the `fit()` method rather than implementing our own training loop, especially if we work in a team.\n",
        "\n",
        "First, let’s build a simple model. No need to compile it, since we will handle the training loop manually:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChWIRdO7s_X4"
      },
      "source": [
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "l2_reg = keras.regularizers.l2(0.05)\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation=\"elu\", kernel_initializer=\"he_normal\",\n",
        "                       kernel_regularizer=l2_reg),\n",
        "    keras.layers.Dense(1, kernel_regularizer=l2_reg)\n",
        "])"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMME6pUVtDMy"
      },
      "source": [
        "Next, let’s create a tiny function that will randomly sample a batch of instances from the training set (the Data API offers a much better alternative):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZOlCpvCtDkT"
      },
      "source": [
        "def random_batch(X, y, batch_size=32):\n",
        "    idx = np.random.randint(len(X), size=batch_size)\n",
        "    return X[idx], y[idx]"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMK0tK_AtGlK"
      },
      "source": [
        "Let’s also define a function that will display the training status, including the number of steps, the total number of steps, the mean loss since the start of the epoch (i.e., we will use the `Mean` metric to compute it), and other metrics:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSh3T7C6tG_U"
      },
      "source": [
        "def print_status_bar(iteration, total, loss, metrics=None):\n",
        "    metrics = \" - \".join([\"{}: {:.4f}\".format(m.name, m.result())\n",
        "                         for m in [loss] + (metrics or [])])\n",
        "    end = \"\" if iteration < total else \"\\n\"\n",
        "    print(\"\\r{}/{} - \".format(iteration, total) + metrics,\n",
        "          end=end)"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXRzW3GHtNj1"
      },
      "source": [
        "This code is self-explanatory, unless you are unfamiliar with Python string formatting: `{:.4f}` will format a float with 4 digits after the decimal point. Moreover, using `\\r` (carriage return) along with `end=\"\"` ensures that the status bar always gets printed on the same line. \n",
        "\n",
        "First, we need to define some hyperparameters, choose the optimizer, the loss function, and the metrics (just the MAE in this example):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJ5h0UrstTxZ"
      },
      "source": [
        "n_epochs = 5\n",
        "batch_size = 32\n",
        "n_steps = len(X_train) // batch_size\n",
        "optimizer = keras.optimizers.Nadam(lr=0.01)\n",
        "loss_fn = keras.losses.mean_squared_error\n",
        "mean_loss = keras.metrics.Mean()\n",
        "metrics = [keras.metrics.MeanAbsoluteError()]"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxvStbACsrZ3"
      },
      "source": [
        "And now we are ready to build the custom loop!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UD4uE9dqF_oU",
        "outputId": "b5f89565-0650-46c4-9b87-4d0799279051",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "for epoch in range(1, n_epochs + 1):\n",
        "    print(\"Epoch {}/{}\".format(epoch, n_epochs))\n",
        "    for step in range(1, n_steps + 1):\n",
        "        X_batch, y_batch = random_batch(X_train_scaled, y_train)\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = model(X_batch)\n",
        "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
        "            loss = tf.add_n([main_loss] + model.losses)\n",
        "        gradients = tape.gradient(loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "        for variable in model.variables:\n",
        "            if variable.constraint is not None:\n",
        "                variable.assign(variable.constraint(variable))\n",
        "        mean_loss(loss)\n",
        "        for metric in metrics:\n",
        "            metric(y_batch, y_pred)\n",
        "        print_status_bar(step * batch_size, len(y_train), mean_loss, metrics)\n",
        "    print_status_bar(len(y_train), len(y_train), mean_loss, metrics)\n",
        "    for metric in [mean_loss] + metrics:\n",
        "        metric.reset_states()"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "11610/11610 - mean: 1.3955 - mean_absolute_error: 0.5722\n",
            "Epoch 2/5\n",
            "11610/11610 - mean: 0.6774 - mean_absolute_error: 0.5280\n",
            "Epoch 3/5\n",
            "11610/11610 - mean: 0.6351 - mean_absolute_error: 0.5177\n",
            "Epoch 4/5\n",
            "11610/11610 - mean: 0.6384 - mean_absolute_error: 0.5181\n",
            "Epoch 5/5\n",
            "11610/11610 - mean: 0.6440 - mean_absolute_error: 0.5222\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TL5Xk5rG77W"
      },
      "source": [
        "- We create two nested loops: one for the epochs, the other for the batches within an epoch.\n",
        "\n",
        "- Then we sample a random batch from the training set.\n",
        "\n",
        "- Inside the `tf.GradientTape()` block, we make a prediction for one batch (using the model as a function), and we compute the loss: it is equal to the main loss\n",
        "plus the other losses (in this model, there is one regularization loss per layer). Since the `mean_squared_error()` function returns one loss per instance, we compute the mean over the batch using `tf.reduce_mean()` (if we wanted to apply different weights to each instance, this is where we would do it). The regularization losses are already reduced to a single scalar each, so we just need to sum them (using `tf.add_n()`, which sums multiple tensors of the same shape\n",
        "and data type).\n",
        "\n",
        "- Next, we ask the tape to compute the gradient of the loss with regards to each trainable variable (not *all* variables!), and we apply them to the optimizer to perform a Gradient Descent step.\n",
        "\n",
        "- Next, we update the mean loss and the metrics (over the current epoch), and we display the status bar.\n",
        "\n",
        "- At the end of each epoch, we display the status bar again to make it look complete and to print a line feed, and we reset the states of the mean loss and the\n",
        "metrics.\n",
        "\n",
        "**Note**: We did not process every single instance in the training set because we sampled instances randomly, so some were processed more than once while others were not processed at all. In practice that’s fine. Moreover, if the training set size is not a multiple of the batch size, we will miss a few instances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7_ZFOdVHBaM"
      },
      "source": [
        "If we set the optimizer’s `clipnorm` or `clipvalue` hyperparameters, it will take care of this for us. If we want to apply any other transformation to the gradients, simply do so before calling the `apply_gradients()` method.\n",
        "\n",
        "If we add weight constraints to your model (e.g., by setting `kernel_constraint` or `bias_constraint` when creating a layer), we should update the training loop to\n",
        "apply these constraints just after `apply_gradients()`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGeaUcivIr6_"
      },
      "source": [
        "for variable in model.variables:\n",
        "    if variable.constraint is not None:\n",
        "        variable.assign(variable.constraint(variable))"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "En_7iUyAIx3I"
      },
      "source": [
        "Most importantly, this training loop does not handle layers that behave differently during training and testing (e.g., `BatchNormalization` or `Dropout`). To handle these, we need to call the model with `training=True` and make sure it propagates this to\n",
        "every layer that needs it.\n",
        "\n",
        "As we can see, there are quite a lot of things we need to get right, it is easy to make a mistake. But on the bright side, we get full control, so it’s your call."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eBheALvG1A4"
      },
      "source": [
        "We could use the handy tqdm library to see a progress bar in the training loop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8k4NMOJGNT1",
        "outputId": "d46bf98d-6ecb-48ba-9cc9-93bc9817dc04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310,
          "referenced_widgets": [
            "ab3b177aa6fe45f68c6b4831a731499f",
            "eeb870f05f2046e89e8078bbe2e0452a",
            "b4efa3905c0a40ee9dac6a3e227b5d0d",
            "2b359bd240c7437cb122956ef9d56ab6",
            "2e236e7dce8e4b0b83c7edebb2e88a45",
            "bf63dfac41f64df3b9507c88d39d94a5",
            "3619bdccc5fb4f50a9d3138846a6b1ce",
            "07ee55e6f6a247e2a7cf00cf80ccc957",
            "e8ed3f44549b43b1a92a6d65b8d5ad37",
            "984c522f1b5b48648befe1348bd31dcc",
            "b0235005238f46bca04aa28e2d48cc61",
            "f0edaf04900a4f9fa117ca223e5b067f",
            "86a2ac2628dc4aa48d57abb366338487",
            "d195eb4192c444dd9ae30ae2be37824d",
            "7aec9dfab871432d9e7112c29405d7f1",
            "16482d0ada2d4668a40559af722bca06",
            "d805b895500f40839351b4fe3a0f2e26",
            "19ed51b346064d32a860519f9eb9cf1c",
            "9432aa2bb71f4581bcfdd7dd6556a5bd",
            "18c8e2b629744a529dc26406efa17d9e",
            "6c8afa2989b54fe89c33db93b435d95c",
            "64ab43f3037b41edabb309361f3c13a1",
            "866bdd5e17644aa0aa5f344ac02326e4",
            "a4042aa2c2874ff4a2bf087fe192eb88",
            "543de1f4bfd74eaca08b711f3b3c4550",
            "5ea70542f6074226b5cc14280d062e8b",
            "057a3f988d44488bb5fa2d9d5afaaaff",
            "781def7aaeb745df9f60b546640b1eb9",
            "a925ff622699485a9ad9fa742bb2c318",
            "d5d30bddd4904d34b77375a5a9bedb8b",
            "9420a43c62214519986fd763c62bd083",
            "5c98cc8d0ec541a891b99c25a2b09bc9",
            "85137b668110498080b26a54246c3fc2",
            "62a1b189e09c4a7ebf83be46ad51705b",
            "a8671a2bc2f54b0e9e832e07c351fb6f",
            "4cb508f2cb114752881e4dadb6d661e9",
            "fafbc0c5eac14798872212978de62b25",
            "f46bb703a35a41b38189e450f0026adf",
            "d5f74ce6ced24d278991517dd0095afb",
            "d54b420c703e4809abdde79725b59c9f",
            "8f5d9d259ef94d85b97077bf6acbe90d",
            "148ab3ab0f3e41dbb68efb61bfe70d04",
            "b2e61c4337144cb294cca7f2d86ad624",
            "f38771ab4cda4fc0ba5a9aba60ef5267",
            "c1f92e171f2c4762a137328ff5b4639a",
            "5701402239e24853ad4ac9b2b062a408",
            "192f99213e6e4fa0b4577a86e2cd7781",
            "0c54473affb24bd9875d2e30096066f8"
          ]
        }
      },
      "source": [
        "try:\n",
        "    from tqdm.notebook import trange\n",
        "    from collections import OrderedDict\n",
        "    with trange(1, n_epochs + 1, desc=\"All epochs\") as epochs:\n",
        "        for epoch in epochs:\n",
        "            with trange(1, n_steps + 1, desc=\"Epoch {}/{}\".format(epoch, n_epochs)) as steps:\n",
        "                for step in steps:\n",
        "                    X_batch, y_batch = random_batch(X_train_scaled, y_train)\n",
        "                    with tf.GradientTape() as tape:\n",
        "                        y_pred = model(X_batch)\n",
        "                        main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
        "                        loss = tf.add_n([main_loss] + model.losses)\n",
        "                    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "                    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "                    for variable in model.variables:\n",
        "                        if variable.constraint is not None:\n",
        "                            variable.assign(variable.constraint(variable))                    \n",
        "                    status = OrderedDict()\n",
        "                    mean_loss(loss)\n",
        "                    status[\"loss\"] = mean_loss.result().numpy()\n",
        "                    for metric in metrics:\n",
        "                        metric(y_batch, y_pred)\n",
        "                        status[metric.name] = metric.result().numpy()\n",
        "                    steps.set_postfix(status)\n",
        "            for metric in [mean_loss] + metrics:\n",
        "                metric.reset_states()\n",
        "except ImportError as ex:\n",
        "    print(\"To run this cell, please install tqdm, ipywidgets and restart Jupyter\")"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ab3b177aa6fe45f68c6b4831a731499f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='All epochs', max=5.0, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e8ed3f44549b43b1a92a6d65b8d5ad37",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch 1/5', max=362.0, style=ProgressStyle(description_wi…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d805b895500f40839351b4fe3a0f2e26",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch 2/5', max=362.0, style=ProgressStyle(description_wi…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "543de1f4bfd74eaca08b711f3b3c4550",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch 3/5', max=362.0, style=ProgressStyle(description_wi…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "85137b668110498080b26a54246c3fc2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch 4/5', max=362.0, style=ProgressStyle(description_wi…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8f5d9d259ef94d85b97077bf6acbe90d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch 5/5', max=362.0, style=ProgressStyle(description_wi…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2twP2BlwJCAd"
      },
      "source": [
        "In the next notebook, we will see how we can use TensorFlow’s automatic graph generation feature: it can speed up our custom code considerably, and it will also make it portable to any platform supported by TensorFlow."
      ]
    }
  ]
}