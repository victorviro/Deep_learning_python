{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Faster_optimizers_DNNs.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "udj8N1L4Fpo3",
        "9KaImCHHF9mv",
        "RqsNTecjGIxe",
        "ZC7ni1ozhdhD"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP1fmtc1cR8p7FVKULVdjwV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victorviro/Deep_learning_python/blob/master/Faster_optimizers_DNNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IO6aee_iFYHq",
        "colab_type": "text"
      },
      "source": [
        "# Training Deep Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5NlkipYFYQO",
        "colab_type": "text"
      },
      "source": [
        "In a past article we introduced artificial neural networks and trained our first deep neural networks. But they were shallow nets, with just a few hidden layers. What if you need to tackle a complex problem, such as detecting hundreds of types of objects in high-resolution images? You may need to train a much deeper DNN, perhaps with 10 layers or many more, each containing hundreds of neurons, linked by hundreds of thousands of connections. Training a deep DNN isn’t a walk in the park. Here are some of the problems you could run into:\n",
        "\n",
        "- You may be faced with the tricky *vanishing gradients* problem or the related *exploding gradients* problem. This is when the gradients grow smaller and smaller, or larger and larger, when flowing backward through the DNN during training. Both of these problems make lower layers very hard to train.\n",
        "\n",
        "- You might not have enough training data for such a large network, or it might be too costly to label.\n",
        "\n",
        "- Training may be extremely slow.\n",
        "\n",
        "- A model with millions of parameters would severely risk overfitting the training set, especially if there are not enough training instances or if they are too noisy.\n",
        "\n",
        "In this notebook we will discuss various optimizers that can speed up training large models tremendously."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrxThpP5FYTF",
        "colab_type": "text"
      },
      "source": [
        "## Faster optimizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNRKC4M_FYVz",
        "colab_type": "text"
      },
      "source": [
        "Training a very large deep neural network can be painfully slow. There are diferent ways to speed up training (and reach a better solution): applying a good initialization strategy for the connection weights, using a good activation function, using [Batch Normalization](https://github.com/victorviro/Deep_learning_python/blob/master/Vanishing_Exploding_gradients_problem_DNNs.ipynb), and reusing parts of a pretrained network (possibly built on an auxiliary task or using unsupervised learning). Another huge speed boost comes from using a faster optimizer than the regular [Gradient Descent optimizer](https://github.com/victorviro/ML_algorithms_python/blob/master/Introduction_gradient_descent_algorithm.ipynb). In this section we will present the most popular algorithms: momentum optimization, Nesterov Accelerated Gradient, AdaGrad, RMSProp, and finally Adam and Nadam optimization.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udj8N1L4Fpo3",
        "colab_type": "text"
      },
      "source": [
        "### Momentum Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMUjhVUTFYYY",
        "colab_type": "text"
      },
      "source": [
        "Imagine a bowling ball rolling down a gentle slope on a smooth surface: it will start out slowly, but it will quickly pick up momentum until it eventually reaches terminal velocity (if there is some friction or air resistance). This is the very simple idea behind momentum optimization, proposed by Boris Polyak in 1964. In contrast, regular Gradient Descent will simply take small, regular steps down the slope, so the algorithm will take much more time to reach the bottom.\n",
        "\n",
        "Recall that Gradient Descent updates the weights $\\boldsymbol{\\theta}$ by directly subtracting the gradient of the cost function $J(\\boldsymbol{\\theta})$ with regard to the weights $(\\nabla_{\\theta}J(\\boldsymbol{\\theta}))$ multiplied by the learning rate $\\eta$. The equation is: \n",
        "$$\\boldsymbol{\\theta}_t \\leftarrow  \\boldsymbol{\\theta}_{t-1} - \\eta \\nabla_{\\theta_{t-1}}J(\\boldsymbol{\\theta}_{t-1})$$\n",
        "\n",
        "It does not care about what the earlier gradients were. If the local gradient is tiny, it goes very slowly.\n",
        "\n",
        "Momentum optimization cares a great deal about what previous gradients were: at each iteration, it subtracts the local gradient from the *momentum vector* $\\boldsymbol{m}$ (multiplied by the learning rate $\\eta$), and it updates the weights by adding this momentum vector (see equation). In other words, the gradient is used for acceleration, not for speed. To simulate some sort of friction mechanism and prevent the momentum from growing too large, the algorithm introduces a new hyperparameter β, called the momentum, which must be set between 0 (high friction) and 1 (no friction). A typical momentum value is 0.9.\n",
        "\n",
        "\\begin{cases}\n",
        "\\boldsymbol{m}_t \\leftarrow  \\beta\\boldsymbol{m}_{t-1} - \\eta \\nabla_{\\theta_{t-1}}J(\\boldsymbol{\\theta}_{t-1})\\\\\\\\\n",
        "\\boldsymbol{\\theta}_t \\leftarrow  \\boldsymbol{\\theta}_{t-1} + \\boldsymbol{m}_t\n",
        "\\end{cases}\n",
        "\n",
        "**Note**: Some implementations exchange the signs in the equations.\n",
        "\n",
        "Essentially, when using momentum, we push a ball down a hill. The ball accumulates momentum as it rolls downhill, becoming faster and faster on the way (until it reaches its terminal velocity if there is friction or air resistance, i.e. $\\beta < 1$). The same thing happens to our parameter updates: The momentum term increases for dimensions whose gradients point in the same directions and reduces updates for dimensions whose gradients change directions. As a result, we gain faster convergence and reduced oscillation.\n",
        "\n",
        "You can easily verify that if the gradient remains constant, the terminal velocity (i.e., the maximum size of the weight updates) is equal to that gradient multiplied by the learning rate $\\eta$ multiplied by $\\frac{1}{1-\\beta}$ (ignoring the sign). For example, if $\\beta = 0.9$, then the terminal velocity is equal to $10$ times the gradient times the learning rate, so momentum optimization ends up going $10$ times faster than Gradient Descent! This allows momentum optimization to escape from plateaus much faster than Gradient Descent. We saw in ([notebook gradient descent](https://github.com/victorviro/ML_algorithms_python/blob/master/Introduction_gradient_descent_algorithm.ipynb)) that when the inputs have very different scales, the cost function will look like an elongated bowl (see Figure 4-7). Gradient Descent goes down the steep slope quite fast, but then it takes a very long time to go down the valley. In contrast, momentum optimization will roll down the valley faster and faster until it reaches the bottom (the optimum). In deep neural networks that don’t use Batch Normalization, the upper layers will often end up having inputs with very different scales, so using momentum optimization helps a lot. It can also help roll past local optima.\n",
        "\n",
        "![texto alternativo](https://i.ibb.co/Qkr1DHz/sgd-vd-momentum.png)\n",
        "\n",
        "**Note**: Due to the momentum, the optimizer may overshoot a bit, then come back, overshoot again, and oscillate like this many times before stabilizing at the minimum. This is one of the reasons it’s good to have a bit of friction in the system: it gets rid of these oscillations and thus speeds up convergence.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIcILUxGF4JP",
        "colab_type": "text"
      },
      "source": [
        "Implementing momentum optimization in Keras is simple: just use the `SGD` optimizer and set its `momentum` hyperparameter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aok8l0QwF49t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "\n",
        "optimizer = keras.optimizers.SGD(lr=0.001, momentum=0.9)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUV9wBQRF7D5",
        "colab_type": "text"
      },
      "source": [
        "The one drawback of momentum optimization is that it adds yet another hyperparameter to tune. However, the momentum value of $0.9$ usually works well in practice and almost always goes faster than regular Gradient Descent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KaImCHHF9mv",
        "colab_type": "text"
      },
      "source": [
        "### Nesterov Accelerated Gradient"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uSt9KW0F-qf",
        "colab_type": "text"
      },
      "source": [
        "However, a ball that rolls down a hill, blindly following the slope, is highly unsatisfactory. We'd like to have a smarter ball, a ball that has a notion of where it is going so that it knows to slow down before the hill slopes up again.\n",
        "\n",
        "One small variant to momentum optimization, proposed by Yurii Nesterov in 1983, is almost always faster than vanilla momentum optimization. The **Nesterov Accelerated Gradient** (NAG) method, also known as **Nesterov momentum optimization**, measures the gradient of the cost function not at the local position $\\boldsymbol{\\theta}$ but slightly ahead in the direction of the momentum, at $\\boldsymbol{\\theta}+\\beta \\boldsymbol{m}$:\n",
        "\n",
        "\\begin{cases}\n",
        "\\boldsymbol{m}_t \\leftarrow  \\beta\\boldsymbol{m}_{t-1} - \\eta \\nabla_{\\theta_{t-1}}J(\\boldsymbol{\\theta}_{t-1}+\\beta \\boldsymbol{m_{t-1}})\\\\\\\\\n",
        "\\boldsymbol{\\theta}_t \\leftarrow  \\boldsymbol{\\theta}_{t-1} + \\boldsymbol{m}_t\n",
        "\\end{cases}\n",
        "\n",
        "\n",
        "This small tweak works because in general the momentum vector will be pointing in the right direction (i.e., toward the optimum), so it will be slightly more accurate to use the gradient measured a bit farther in that direction rather than the gradient at the original position, as you can see in Figure 11-6 (where $\\nabla_1$ represents the gradient of the cost function measured at the starting point $\\boldsymbol{\\theta}$, and $\\nabla_2$ represents the gradient at the point located at $\\boldsymbol{\\theta}+\\beta \\boldsymbol{m}$).\n",
        "\n",
        "As you can see, the Nesterov update ends up slightly closer to the optimum. After a while, these small improvements add up and NAG ends up being significantly faster than regular momentum optimization. Moreover, note that when the momentum pushes the weights across a valley, $\\nabla_1$ continues to push farther across the valley, while $\\nabla_2$ pushes back toward the bottom of the valley. This helps reduce oscillations and thus NAG converges faster.\n",
        "\n",
        "![texto alternativo](https://i.ibb.co/2K8Wd5x/NAG.png)\n",
        "\n",
        "Again, we set the momentum term $\\beta=0.9$. While Momentum first computes the current gradient and then takes a big jump in the direction of the updated accumulated gradient, NAG first makes a big jump in the direction of the previous accumulated gradient, measures the gradient and then makes a correction, which results in the complete NAG update. This anticipatory update prevents us from going too fast and results in increased responsiveness, which has significantly increased the performance of RNNs on a number of tasks.\n",
        "\n",
        "NAG is generally faster than regular momentum optimization. To use it, simply set `nesterov=True` when creating the `SGD` optimizer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6HcCSPVGHs_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = keras.optimizers.SGD(lr=0.001, momentum=0.9, nesterov=True)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqsNTecjGIxe",
        "colab_type": "text"
      },
      "source": [
        "### AdaGrad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFKCjJrpGLGl",
        "colab_type": "text"
      },
      "source": [
        "Consider the elongated bowl problem again: Gradient Descent starts by quickly going down the steepest slope, which does not point straight toward the global optimum, then it very slowly goes down to the bottom of the valley. It would be nice if the algorithm could correct its direction earlier to point a bit more toward the global optimum. The AdaGrad [algorithm](http://jmlr.org/papers/v12/duchi11a.html) achieves this correction by scaling down the gradient vector along the steepest dimensions (see Equation 11-6).\n",
        "\n",
        "\\begin{cases}\n",
        "\\boldsymbol{s}_t \\leftarrow \\boldsymbol{s}_{t-1} - \\nabla_{\\theta_{t-1}}J(\\boldsymbol{\\theta}_{t-1}) \\otimes \\nabla_{\\theta_{t-1}}J(\\boldsymbol{\\theta}_{t-1})\\\\\\\\\n",
        "\\boldsymbol{\\theta}_t \\leftarrow \\boldsymbol{\\theta}_{t-1} -\\eta\\nabla_{\\theta_{t-1}}J(\\boldsymbol{\\theta}_{t-1}) \\oslash \\sqrt{\\boldsymbol{s}_t+\\epsilon}\n",
        "\\end{cases}\n",
        "\n",
        "The first step accumulates the square of the gradients into the vector $\\boldsymbol{s}$ (the $\\otimes$ symbol represents the element-wise multiplication). This vectorized form is equivalent to computing $s_i = s_i + (\\frac{\\partial J(\\boldsymbol{\\theta}) }{\\partial \\theta_i})^2$ for each element $s_i$ of the vector $\\boldsymbol{s}$; in other words, each $s_i$ accumulates the squares of the partial derivative of the cost function with regard to parameter $\\theta_i$. If the cost function is steep along the $i^\\text{th}$ dimension, then $s_i$ will get larger and larger at each iteration.\n",
        "\n",
        "The second step is almost identical to Gradient Descent, but with one big difference: the gradient vector is scaled down by a factor of $\\sqrt{\\boldsymbol{s}+\\epsilon}$ (the $\\oslash$ symbol represents the element-wise division, and $\\epsilon$ is a smoothing term to avoid division by zero, typically set to $10^{–10}$). This vectorized form is equivalent to simultaneously computing \n",
        "$\\theta_i = \\theta_i - \\eta \\frac{\\partial J(\\boldsymbol{\\theta}) }{\\partial \\theta_i} \\frac{1}{\\sqrt{s_i+\\epsilon}}$ for all parameters $\\theta_i$.\n",
        "\n",
        "In short, this algorithm decays the learning rate, but it does so faster for steep dimensions than for dimensions with gentler slopes. This is called an *adaptive learning rate*. It helps point the resulting updates more directly toward the global optimum (see Figure 11-7). One additional benefit is that it requires much less tuning of the learning rate hyperparameter $\\eta$.\n",
        "\n",
        "![texto alternativo](https://i.ibb.co/7KSqXHX/adagrad.png)\n",
        "\n",
        "\n",
        "AdaGrad frequently performs well for simple quadratic problems, but it often stops too early when training neural networks. Its main weakness is its accumulation of the squared gradients in the denominator: Since every added term is positive, the accumulated sum keeps growing during training. This in turn causes the learning rate to shrink and eventually become infinitesimally small, at which pointthe algorithm ends up stopping entirely before reaching the global optimum. So even though Keras has an Adagrad optimizer, you should not use it to train deep neural networks (it may be efficient for simpler tasks such as Linear Regression, though). Still, understanding AdaGrad is helpful to grasp the other adaptive learning rate optimizers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0cyBTbtR7q7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = keras.optimizers.Adagrad(lr=0.001)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZBLuyoIGUAX",
        "colab_type": "text"
      },
      "source": [
        "### RMSProp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grelK2cHGVB3",
        "colab_type": "text"
      },
      "source": [
        "As we’ve seen, AdaGrad runs the risk of slowing down a bit too fast and never converging to the global optimum. The RMSProp [algorithm](http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf) fixes this by accumulating only the gradients from the most recent iterations (as opposed to all the gradients since the beginning of training). It does so by using exponential decay in the first step.\n",
        "\n",
        "\\begin{cases}\n",
        "\\boldsymbol{s}_t \\leftarrow  \\beta\\boldsymbol{s}_{t-1} - (1-\\beta)\\nabla_{\\theta_{t-1}}J(\\boldsymbol{\\theta}_{t-1}) \\otimes \\nabla_{\\theta_{t-1}}J(\\boldsymbol{\\theta}_{t-1})\\\\\\\\\n",
        "\\boldsymbol{\\theta}_t \\leftarrow  \\boldsymbol{\\theta}_{t-1} -\\eta\\nabla_{\\theta_{t-1}}J(\\boldsymbol{\\theta}_{t-1}) \\oslash\\sqrt{\\boldsymbol{s}_t+\\epsilon}\n",
        "\\end{cases}\n",
        "\n",
        "\n",
        "The decay rate $\\beta$ is typically set to 0.9. Yes, it is once again a new hyperparameter, but this default value often works well, so you may not need to tune it at all.\n",
        "\n",
        "Keras has an `RMSprop` optimizer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIU7Ug02GZwk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = keras.optimizers.RMSprop(lr=0.001, rho=0.9)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kwWy9zmGbVy",
        "colab_type": "text"
      },
      "source": [
        "Except on very simple problems, this optimizer almost always performs much better than AdaGrad. In fact, it was the preferred optimization algorithm of many researchers until Adam optimization came around."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETfwJxakGegO",
        "colab_type": "text"
      },
      "source": [
        "### Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8hOx4J9GflA",
        "colab_type": "text"
      },
      "source": [
        "[Adam ](https://arxiv.org/abs/1412.6980) which stands for *adaptive moment estimation*, combines the ideas of momentum optimization and RMSProp: just like momentum optimization, it keeps track of an exponentially decaying average of past gradients; and just like RMSProp, it keeps track of an exponentially decaying average of past squared gradients.\n",
        "\n",
        "\\begin{cases}\n",
        "\\boldsymbol{m}_t \\leftarrow  \\beta_1\\boldsymbol{m}_{t-1} + (1-\\beta_1) \\nabla_{\\theta_{t-1}}J(\\boldsymbol{\\theta}_{t-1})\\\\\\\\\n",
        "\\boldsymbol{s}_t \\leftarrow  \\beta_2\\boldsymbol{s}_{t-1} + (1-\\beta_2)\\nabla_{\\theta_{t-1}}J(\\boldsymbol{\\theta}_{t-1})\\otimes\\nabla_{\\theta_{t-1}}J(\\boldsymbol{\\theta}_{t-1})\n",
        "\\end{cases}\n",
        "\n",
        "\n",
        "$\\boldsymbol{m}_t$ and $\\boldsymbol{s}_t$ are estimates of the first moment (the mean) and the second moment (the uncentered variance) of the gradients respectively, hence the name of the method. As $\\boldsymbol{m}_t$ and $\\boldsymbol{s}_t$ are initialized as vectors of 0's, the authors of Adam observe that they are biased towards zero, especially during the initial time steps, and especially when the decay rates are small (i.e. $\\beta_1$ and $\\beta_2$ are close to 1).\n",
        "\n",
        "They counteract these biases by computing bias-corrected first and second moment estimates:\n",
        "\n",
        "\\begin{cases}\n",
        "\\hat{\\boldsymbol{m}}_t \\leftarrow  \\frac{\\boldsymbol{m}_t}{1-\\beta_1^t}\\\\\\\\\n",
        "\\hat{\\boldsymbol{s}}_t \\leftarrow  \\frac{\\boldsymbol{s}_t}{1-\\beta_2^t}\n",
        "\\end{cases}\n",
        "\n",
        "\n",
        "They then use these to update the parameters just as we have seen in Momentum and RMSprop, which yields the Adam update rule:\n",
        "\n",
        "$$\\boldsymbol{\\theta}_t \\leftarrow  \\boldsymbol{\\theta}_{t-1} -\\eta \\hat{\\boldsymbol{m}}_t\\oslash\\sqrt{\\hat{\\boldsymbol{s}}_t+\\epsilon}$$\n",
        "\n",
        "- In this equation, $t$ represents the iteration number (starting at 1).\n",
        "\n",
        "If you just look at the steps, you will notice Adam’s close similarity to both momentum optimization and RMSProp. The only difference is that the first step computes an exponentially decaying average rather than an exponentially decaying sum, but these are actually equivalent except for a constant factor (the decaying average is just $1 - \\beta_1$ times the decaying sum). The third and fourth steps are somewhat of a technical detail: since $\\boldsymbol{m}_t$ and $\\boldsymbol{s}_t$ are initialized at $\\boldsymbol{0}$, they will be biased toward $\\boldsymbol{0}$ at the beginning of training, so these two steps will help boost $\\boldsymbol{m}_t$ and $\\boldsymbol{s}_t$ at the beginning of training.\n",
        "\n",
        "The momentum decay hyperparameter $\\beta_1$ is typically initialized to 0.9, while the scaling decay hyperparameter $\\beta_2$ is often initialized to 0.999. As earlier, the smoothing term $\\epsilon$ is usually initialized to a tiny number such as $10^{-7}$. These are the default values for the Adam class (to be precise, `epsilon` defaults to `None`, which tells Keras to use `keras.backend.epsilon()`, which defaults to $10^{-7}$; you can change it using `keras.backend.set_epsilon()`).\n",
        "\n",
        "Here is how to create an Adam optimizer using Keras:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iirL26GpGj4n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XjSITQlGlkA",
        "colab_type": "text"
      },
      "source": [
        "Since Adam is an adaptive learning rate algorithm (like AdaGrad and RMSProp), it requires less tuning of the learning rate hyperparameter $\\eta$. You can often use the default value $\\eta = 0.001$, making Adam even easier to use than Gradient Descent.\n",
        "\n",
        "Finally, two variants of Adam:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJH0g_XhTLZj",
        "colab_type": "text"
      },
      "source": [
        "#### Adamax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgpZTq5MFYf2",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "It is introduced in the same paper as Adam: notice that in second step of  the equation, Adam accumulates the squares of the gradients in $\\boldsymbol{s}_t$ (with a greater weight for more recent weights). In the last step, if we ignore $\\epsilon$ and steps 3 and 4 (which are technical details anyway), Adam just scales down the parameter updates by the square root of $\\boldsymbol{s}_t$. In short, Adam scales down the parameter updates by the $\\boldsymbol{l}_2$ norm of the time-decayed gradients (recall that the $\\boldsymbol{l}_2$ norm is the square root of the sum of squares). Adamax just replaces the $\\boldsymbol{l}_2$ norm with the $\\boldsymbol{l}_{\\infty}$ norm (a fancy way of saying the max). Specifically, it replaces the second step in equations with\n",
        "$\\boldsymbol{s}_t\\leftarrow\\text{max}(\\beta_2\\boldsymbol{s}_{t-1},\\nabla_{\\theta_{t-1}}J(\\boldsymbol{\\theta}_{t-1}))$, it drops step 4, and in step 5 it scales down the gradient updates by a factor of $\\boldsymbol{s}_t$ , which is just the max of the time-decayed gradients. \n",
        "\n",
        "In practice, this can make Adamax more stable than Adam, but this really depends on the dataset, and in general Adam actually performs better. So it’s just one more optimizer you can try if you experience problems with Adam on some task.\n",
        "\n",
        "Here is how to create an Adamax optimizer using Keras:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A01F7SQQd6QN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = keras.optimizers.Adamax(lr=0.001, beta_1=0.9, beta_2=0.999)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYTQZl5-FYdM",
        "colab_type": "text"
      },
      "source": [
        "#### Nadam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCPBH6QjFYbN",
        "colab_type": "text"
      },
      "source": [
        "As we have seen before, Adam can be viewed as a combination of RMSprop and momentum: RMSprop contributes the exponentially decaying average of past squared gradients $\\boldsymbol{s}_t$, while momentum accounts for the exponentially decaying average of past gradients $\\boldsymbol{m}_t$. We have also seen that Nesterov accelerated gradient (NAG) is superior to vanilla momentum.\n",
        "\n",
        "[Nadam](http://cs229.stanford.edu/proj2015/054_report.pdf) (Nesterov-accelerated Adaptive Moment Estimation) thus combines Adam and NAG, so it will often converge slightly faster than Adam. In his\n",
        "report, Timothy Dozat compares many different optimizers on various tasks, and\n",
        "finds that Nadam generally outperforms Adam, but is sometimes outperformed\n",
        "by RMSProp.\n",
        "\n",
        "Here is how to create an Nadam optimizer using Keras:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I75BUim3ecz2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = keras.optimizers.Nadam(lr=0.001, beta_1=0.9, beta_2=0.999)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uswt1E9DhZcH",
        "colab_type": "text"
      },
      "source": [
        "### Notes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sEQq0FVepmp",
        "colab_type": "text"
      },
      "source": [
        "- Adaptive optimization methods (including RMSProp, Adam and Nadam optimization) are often great, converging fast to a good solution. However, a  [paper](https://arxiv.org/abs/1705.08292) by Ashia C. Wilson in 2017 showed\n",
        "that they can lead to solutions that generalize poorly on some datasets. So when you are disappointed by your model’s performance, try using plain Nesterov Accelerated Gradient instead: your dataset may just be allergic to adaptive gradients.\n",
        "\n",
        "- All the optimization techniques discussed so far only rely on the first-order partial derivatives (*Jacobians*). The optimization literature contains amazing algorithms based on the second-order partial derivatives (the *Hessians*, which are the partial derivatives of the Jacobians). Unfortunately, these algorithms are very hard to apply to deep neural networks because there are $n^2$ Hessians per output (where $n$ is the number of parameters), as opposed to just $n$ Jacobians per output. Since DNNs typically have tens of thousands of parameters, the second-order optimization algorithms often don’t even fit in memory, and even when they do, computing the Hessians is just too slow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZC7ni1ozhdhD",
        "colab_type": "text"
      },
      "source": [
        "#### Training Sparse Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSfPjY7uhjpA",
        "colab_type": "text"
      },
      "source": [
        "All the optimization algorithms just presented produce dense models (most parameters will be nonzero). If you need a blazingly fast model at runtime, or if you need it to take up less memory, you may prefer to end up with a sparse model instead.\n",
        "\n",
        "One trivial way to achieve this is to train the model as usual, then get rid of the tiny weights (set them to 0). However, this will typically not lead to a very sparse model, and it may degrade the model’s performance.\n",
        "\n",
        "A better option is to apply strong $l_1$ regularization during training, as it pushes the optimizer to zero out as many weights as it can (as discussed [here](https://github.com/victorviro/ML_algorithms_python/blob/master/Introduction_generalized_linear_models.ipynb) about Lasso Regression).\n",
        "\n",
        "However, in some cases these techniques may remain insufficient. One last option is to apply *Dual Averaging*, often called *Follow The Regularized Leader* (FTRL), a technique [proposed](http://webdoc.sub.gwdg.de/ebook/serien/e/CORE/dp2005_67.pdf) by Yurii Nesterov. When used with $l_1$ regularization, this technique often leads to very sparse models. Keras implements a variant of FTRL called [FTRL-Proximal](https://static.googleusercontent.com/media/research.google.com/es//pubs/archive/41159.pdf) in the `FTRL` optimizer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teaC8JptiUdv",
        "colab_type": "text"
      },
      "source": [
        "### Learning Rate Scheduling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nu32boZKiW76",
        "colab_type": "text"
      },
      "source": [
        "Finding a good learning rate can be tricky. If you set it way too high, training may actually diverge (as we discussed [here](https://github.com/victorviro/ML_algorithms_python/blob/master/Introduction_gradient_descent_algorithm.ipynb)). If you set it too low, training will eventually converge to the optimum, but it will take a very long time. If you set it slightly too high, it will make progress very quickly at first, but it will end up dancing around the optimum, never really settling down. If you have a limited computing budget, you may have to interrupt training before it has converged properly, yielding a suboptimal solution.\n",
        "\n",
        "One approach is to start with a large learning rate, and divide it by 3 until the training algorithm stops diverging. You will not be too far from the optimal learning rate, which will learn quickly and converge to good solution.\n",
        "\n",
        "\n",
        "However, you can do better than a constant learning rate: if you start with a high learning rate and then reduce it once it stops making fast progress, you can reach a good solution faster than with the optimal constant learning rate. There are many different strategies to reduce the learning rate during training. These strategies are called *learning schedules*. A [paper](https://static.googleusercontent.com/media/research.google.com/es//pubs/archive/40808.pdf) by Andrew Senior in 2013 compared the performance of some of the most popular learning schedules when training deep neural networks for speech recognition using Momentum optimization. The authors concluded that, in this setting, both performance scheduling and exponential scheduling performed well. They favored exponential scheduling because it was easy to tune and it converged slightly faster to the optimal solution (they also mentioned that it was easier to implement than performance scheduling, but in Keras both options are easy). Let's see the most common learning schedules.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D87CL0EGhVXJ",
        "colab_type": "text"
      },
      "source": [
        "#### Power scheduling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEsdrZxLhaSC",
        "colab_type": "text"
      },
      "source": [
        "Set the learning rate to a function of the iteration number $t$: $\\eta(t)=\\frac{\\eta_0}{(1+\\frac{t}{s})^c}$. The initial learning rate $\\eta_0$, the power $c$ (typically set to 1) and the steps $s$ are\n",
        "hyperparameters. The learning rate drops at each step, and after $s$ steps it is down to $\\frac{\\eta_0}{2}$. After $s$ more steps, it is down to $\\frac{\\eta_0}{3}$. Then down to $\\frac{\\eta_0}{4}$, and so on. As you can see, this schedule first drops quickly, then more and more slowly. Of course, this requires tuning  $\\eta_0$, $s$ (and possibly $c$).\n",
        "\n",
        "Implementing power scheduling in Keras is the easiest option: just set the decay hyperparameter when creating an optimizer. The decay is the inverse of $s$ (the number of steps it takes to divide the learning rate by one more unit), and Keras assumes that $c$ is equal to $1$. For example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1y2VwFxXh0z1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "X_train_full = X_train_full / 255.0\n",
        "X_test = X_test / 255.0\n",
        "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "\n",
        "\n",
        "pixel_means = X_train.mean(axis=0, keepdims=True)\n",
        "pixel_stds = X_train.std(axis=0, keepdims=True)\n",
        "X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
        "X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
        "X_test_scaled = (X_test - pixel_means) / pixel_stds"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pu_DwSgjh1JJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = keras.optimizers.SGD(lr=0.01, decay=1e-4)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZHk05aQh4_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBh9DmU7h5Cj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 945
        },
        "outputId": "75ba7fc4-dd03-4f80-f03c-5a5ebfdd58bb"
      },
      "source": [
        "n_epochs = 25\n",
        "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
        "                    validation_data=(X_valid_scaled, y_valid))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 55000 samples, validate on 5000 samples\n",
            "Epoch 1/25\n",
            "55000/55000 [==============================] - 6s 104us/step - loss: 0.4911 - accuracy: 0.8259 - val_loss: 0.3954 - val_accuracy: 0.8652\n",
            "Epoch 2/25\n",
            "55000/55000 [==============================] - 6s 102us/step - loss: 0.3812 - accuracy: 0.8648 - val_loss: 0.3836 - val_accuracy: 0.8642\n",
            "Epoch 3/25\n",
            "55000/55000 [==============================] - 6s 102us/step - loss: 0.3474 - accuracy: 0.8751 - val_loss: 0.3654 - val_accuracy: 0.8732\n",
            "Epoch 4/25\n",
            "55000/55000 [==============================] - 6s 102us/step - loss: 0.3256 - accuracy: 0.8829 - val_loss: 0.3462 - val_accuracy: 0.8768\n",
            "Epoch 5/25\n",
            "55000/55000 [==============================] - 6s 102us/step - loss: 0.3103 - accuracy: 0.8889 - val_loss: 0.3419 - val_accuracy: 0.8794\n",
            "Epoch 6/25\n",
            "55000/55000 [==============================] - 6s 103us/step - loss: 0.2965 - accuracy: 0.8937 - val_loss: 0.3417 - val_accuracy: 0.8794\n",
            "Epoch 7/25\n",
            "55000/55000 [==============================] - 6s 102us/step - loss: 0.2861 - accuracy: 0.8973 - val_loss: 0.3358 - val_accuracy: 0.8822\n",
            "Epoch 8/25\n",
            "55000/55000 [==============================] - 6s 102us/step - loss: 0.2772 - accuracy: 0.9008 - val_loss: 0.3347 - val_accuracy: 0.8812\n",
            "Epoch 9/25\n",
            "55000/55000 [==============================] - 6s 102us/step - loss: 0.2701 - accuracy: 0.9034 - val_loss: 0.3275 - val_accuracy: 0.8850\n",
            "Epoch 10/25\n",
            "55000/55000 [==============================] - 6s 102us/step - loss: 0.2627 - accuracy: 0.9069 - val_loss: 0.3249 - val_accuracy: 0.8830\n",
            "Epoch 11/25\n",
            "55000/55000 [==============================] - 6s 102us/step - loss: 0.2567 - accuracy: 0.9088 - val_loss: 0.3225 - val_accuracy: 0.8866\n",
            "Epoch 12/25\n",
            "55000/55000 [==============================] - 6s 102us/step - loss: 0.2509 - accuracy: 0.9104 - val_loss: 0.3218 - val_accuracy: 0.8848\n",
            "Epoch 13/25\n",
            "55000/55000 [==============================] - 6s 113us/step - loss: 0.2462 - accuracy: 0.9124 - val_loss: 0.3176 - val_accuracy: 0.8882\n",
            "Epoch 14/25\n",
            "55000/55000 [==============================] - 6s 108us/step - loss: 0.2412 - accuracy: 0.9136 - val_loss: 0.3205 - val_accuracy: 0.8846\n",
            "Epoch 15/25\n",
            "55000/55000 [==============================] - 6s 102us/step - loss: 0.2369 - accuracy: 0.9162 - val_loss: 0.3227 - val_accuracy: 0.8840\n",
            "Epoch 16/25\n",
            "55000/55000 [==============================] - 6s 101us/step - loss: 0.2329 - accuracy: 0.9174 - val_loss: 0.3163 - val_accuracy: 0.8890\n",
            "Epoch 17/25\n",
            "55000/55000 [==============================] - 6s 101us/step - loss: 0.2292 - accuracy: 0.9196 - val_loss: 0.3174 - val_accuracy: 0.8880\n",
            "Epoch 18/25\n",
            "55000/55000 [==============================] - 6s 102us/step - loss: 0.2254 - accuracy: 0.9215 - val_loss: 0.3181 - val_accuracy: 0.8894\n",
            "Epoch 19/25\n",
            "55000/55000 [==============================] - 5s 100us/step - loss: 0.2227 - accuracy: 0.9220 - val_loss: 0.3156 - val_accuracy: 0.8900\n",
            "Epoch 20/25\n",
            "55000/55000 [==============================] - 6s 101us/step - loss: 0.2198 - accuracy: 0.9230 - val_loss: 0.3171 - val_accuracy: 0.8880\n",
            "Epoch 21/25\n",
            "55000/55000 [==============================] - 6s 100us/step - loss: 0.2166 - accuracy: 0.9234 - val_loss: 0.3137 - val_accuracy: 0.8922\n",
            "Epoch 22/25\n",
            "55000/55000 [==============================] - 6s 101us/step - loss: 0.2137 - accuracy: 0.9258 - val_loss: 0.3201 - val_accuracy: 0.8886\n",
            "Epoch 23/25\n",
            "55000/55000 [==============================] - 6s 101us/step - loss: 0.2111 - accuracy: 0.9269 - val_loss: 0.3142 - val_accuracy: 0.8900\n",
            "Epoch 24/25\n",
            "55000/55000 [==============================] - 6s 103us/step - loss: 0.2088 - accuracy: 0.9272 - val_loss: 0.3140 - val_accuracy: 0.8906\n",
            "Epoch 25/25\n",
            "55000/55000 [==============================] - 6s 100us/step - loss: 0.2061 - accuracy: 0.9281 - val_loss: 0.3169 - val_accuracy: 0.8902\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwPQa9r6h_nX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "d274eb2c-4a31-47d9-afca-3a296f66831b"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "learning_rate = 0.01\n",
        "decay = 1e-4\n",
        "batch_size = 32\n",
        "n_steps_per_epoch = len(X_train) // batch_size\n",
        "epochs = np.arange(n_epochs)\n",
        "lrs = learning_rate / (1 + decay * epochs * n_steps_per_epoch)\n",
        "\n",
        "plt.figure(figsize=(11, 4))\n",
        "plt.plot(epochs, lrs,  \"o-\")\n",
        "plt.axis([0, n_epochs - 1, 0, 0.01])\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.title(\"Power Scheduling\", fontsize=14)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 792x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wqp4KC95iCTj",
        "colab_type": "text"
      },
      "source": [
        "#### Exponential scheduling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rA3XAK8wiEso",
        "colab_type": "text"
      },
      "source": [
        "Set the learning rate to: $\\eta(t)=\\eta_0 (0.1)^{\\frac{t}{s}}$. The learning rate will gradually drop by a factor of $10$ every $s$ steps. While power scheduling reduces the learning rate more and more slowly, exponential scheduling keeps slashing it by a factor of $10$ every $s$ steps.\n",
        "\n",
        "Implementing Exponential scheduling is quite simple too. You first need to define a function that takes the current epoch and returns the learning rate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEO354y9iPmi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def exponential_decay_fn(epoch):\n",
        "    return 0.01 * 0.1**(epoch / 20)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_v4n3pIItA1l",
        "colab_type": "text"
      },
      "source": [
        "If you do not want to hard-code $\\eta_0$ and $s$, you can create a function that returns a configured function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzQDV5fptEHh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def exponential_decay(lr0, s):\n",
        "    def exponential_decay_fn(epoch):\n",
        "        return lr0 * 0.1**(epoch / s)\n",
        "    return exponential_decay_fn\n",
        "\n",
        "exponential_decay_fn = exponential_decay(lr0=0.01, s=20)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jj23MG0ttEKY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
        "n_epochs = 25"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bav5xqVtKO_",
        "colab_type": "text"
      },
      "source": [
        "Next, just create a `LearningRateScheduler` callback, giving it the schedule function, and pass this callback to the `fit()` method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHOZ7J-9tNZl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 945
        },
        "outputId": "2fc66b3c-9dd5-4579-8204-07edeac95575"
      },
      "source": [
        "lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
        "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
        "                    validation_data=(X_valid_scaled, y_valid),\n",
        "                    callbacks=[lr_scheduler])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 55000 samples, validate on 5000 samples\n",
            "Epoch 1/25\n",
            "55000/55000 [==============================] - 8s 140us/step - loss: 0.8347 - accuracy: 0.7621 - val_loss: 0.7131 - val_accuracy: 0.7830\n",
            "Epoch 2/25\n",
            "55000/55000 [==============================] - 8s 139us/step - loss: 0.6670 - accuracy: 0.7983 - val_loss: 0.7745 - val_accuracy: 0.8052\n",
            "Epoch 3/25\n",
            "55000/55000 [==============================] - 8s 139us/step - loss: 0.6176 - accuracy: 0.8168 - val_loss: 0.7733 - val_accuracy: 0.8038\n",
            "Epoch 4/25\n",
            "55000/55000 [==============================] - 8s 139us/step - loss: 0.5166 - accuracy: 0.8397 - val_loss: 0.5539 - val_accuracy: 0.8356\n",
            "Epoch 5/25\n",
            "55000/55000 [==============================] - 8s 138us/step - loss: 0.4902 - accuracy: 0.8489 - val_loss: 0.6190 - val_accuracy: 0.8166\n",
            "Epoch 6/25\n",
            "55000/55000 [==============================] - 8s 138us/step - loss: 0.4413 - accuracy: 0.8586 - val_loss: 0.5042 - val_accuracy: 0.8548\n",
            "Epoch 7/25\n",
            "55000/55000 [==============================] - 8s 138us/step - loss: 0.4046 - accuracy: 0.8690 - val_loss: 0.5245 - val_accuracy: 0.8624\n",
            "Epoch 8/25\n",
            "55000/55000 [==============================] - 8s 138us/step - loss: 0.3771 - accuracy: 0.8776 - val_loss: 0.4464 - val_accuracy: 0.8670\n",
            "Epoch 9/25\n",
            "55000/55000 [==============================] - 8s 139us/step - loss: 0.3564 - accuracy: 0.8818 - val_loss: 0.4775 - val_accuracy: 0.8770\n",
            "Epoch 10/25\n",
            "55000/55000 [==============================] - 8s 138us/step - loss: 0.3257 - accuracy: 0.8916 - val_loss: 0.4898 - val_accuracy: 0.8778\n",
            "Epoch 11/25\n",
            "55000/55000 [==============================] - 8s 139us/step - loss: 0.3011 - accuracy: 0.8984 - val_loss: 0.4710 - val_accuracy: 0.8728\n",
            "Epoch 12/25\n",
            "55000/55000 [==============================] - 8s 139us/step - loss: 0.2803 - accuracy: 0.9056 - val_loss: 0.4410 - val_accuracy: 0.8848\n",
            "Epoch 13/25\n",
            "55000/55000 [==============================] - 8s 138us/step - loss: 0.2591 - accuracy: 0.9113 - val_loss: 0.4185 - val_accuracy: 0.8844\n",
            "Epoch 14/25\n",
            "55000/55000 [==============================] - 8s 138us/step - loss: 0.2390 - accuracy: 0.9171 - val_loss: 0.4806 - val_accuracy: 0.8830\n",
            "Epoch 15/25\n",
            "55000/55000 [==============================] - 8s 138us/step - loss: 0.2235 - accuracy: 0.9231 - val_loss: 0.4487 - val_accuracy: 0.8844\n",
            "Epoch 16/25\n",
            "55000/55000 [==============================] - 8s 138us/step - loss: 0.2080 - accuracy: 0.9279 - val_loss: 0.4811 - val_accuracy: 0.8814\n",
            "Epoch 17/25\n",
            "55000/55000 [==============================] - 8s 138us/step - loss: 0.1942 - accuracy: 0.9327 - val_loss: 0.4788 - val_accuracy: 0.8894\n",
            "Epoch 18/25\n",
            "55000/55000 [==============================] - 8s 138us/step - loss: 0.1813 - accuracy: 0.9374 - val_loss: 0.5093 - val_accuracy: 0.8792\n",
            "Epoch 19/25\n",
            "55000/55000 [==============================] - 8s 138us/step - loss: 0.1700 - accuracy: 0.9413 - val_loss: 0.4997 - val_accuracy: 0.8878\n",
            "Epoch 20/25\n",
            "55000/55000 [==============================] - 8s 142us/step - loss: 0.1599 - accuracy: 0.9449 - val_loss: 0.5088 - val_accuracy: 0.8862\n",
            "Epoch 21/25\n",
            "55000/55000 [==============================] - 8s 138us/step - loss: 0.1486 - accuracy: 0.9491 - val_loss: 0.4972 - val_accuracy: 0.8922\n",
            "Epoch 22/25\n",
            "55000/55000 [==============================] - 8s 139us/step - loss: 0.1396 - accuracy: 0.9530 - val_loss: 0.5353 - val_accuracy: 0.8902\n",
            "Epoch 23/25\n",
            "55000/55000 [==============================] - 8s 140us/step - loss: 0.1314 - accuracy: 0.9558 - val_loss: 0.5433 - val_accuracy: 0.8906\n",
            "Epoch 24/25\n",
            "55000/55000 [==============================] - 8s 139us/step - loss: 0.1224 - accuracy: 0.9588 - val_loss: 0.6019 - val_accuracy: 0.8896\n",
            "Epoch 25/25\n",
            "55000/55000 [==============================] - 8s 138us/step - loss: 0.1179 - accuracy: 0.9610 - val_loss: 0.5799 - val_accuracy: 0.8900\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsfNMnXetQSH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "26c2ba34-b4c1-4e4d-ae04-9822293d4e1d"
      },
      "source": [
        "#@title\n",
        "plt.figure(figsize=(11, 4))\n",
        "plt.plot(history.epoch, history.history[\"lr\"], \"o-\")\n",
        "plt.axis([0, n_epochs - 1, 0, 0.011])\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.title(\"Exponential Scheduling\", fontsize=14)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqUAAAEXCAYAAACUMj3RAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXxU1f3/8dcn+0YSdkjYJYAoKqK4K3X54tIqVfyqba1ttdaq3Wu/Wrv47a9+rUtb26qtVK17UXHDiuKCcUHZVfYlsod9CSSQhCR8fn/MTRzCJATJZJLM+/l43MfMPffcO587Vycfzj3nXHN3RERERERiKSHWAYiIiIiIKCkVERERkZhTUioiIiIiMaekVERERERiTkmpiIiIiMScklIRERERiTklpSIiLcTMvmVmZQe5T6GZ3RetmILPWGlmP4/Cccea2UHNO1j/O/oi35mItE1KSkUk6szsUTPzCMu0WMcWLcH5ja1X/AwwIAqfdY2ZfWxmZWa2w8zmmtnvm/tzYiQq35mItD5JsQ5AROLGW8CV9cr2xCKQWHH3cqC8OY9pZt8B/gr8BHgbSAaOBE5qzs+JlWh8ZyLSOqmlVERaSqW7b6i3bAMwszPMrMrMRtVWNrPvmdlOMxsQrBea2T/M7C9mtj1Y7jazhLB9OprZY8G2cjN7y8yOCNv+raA18Swzm29mu8zsHTPrHx6omX3FzGabWYWZrTCz280sJWz7SjP7lZk9GMS41sxuCt8evH0uaDFdGf75YfUOM7OXzWxDEMscM/vyQX6vFwIvuPuD7l7k7ovc/Tl3/2m9czrfzKYH38tWM3vFzNLCqqQ1dD7B/jlmNs7MNplZqZm9a2bH1avzTTNbZWa7zew/QPd6228zs/n1yhq9PR/hO7stuHaXm9lnQSwvmVmXsDpJZvbnsP9O/mxmfzezwgN/nSISK0pKRSTm3P1d4G7giSCxHAL8CfiBuy8Pq/p1Qr9bJwHfA64Ffhy2/VHgBOAiYCSwG3jdzNLD6qQCtwDfCY6TC/yjdqOZjQaeAu4DjgjqjQX+r17YPwHmAccCdwJ3mVlt6+Txwet3gZ5h6/VlAa8B5wBHA88DLwTn31QbgJG1yXskZnYuMBF4ExgBfAl4l33/BjR4PmZmwKtAPvBlYDjwHjDFzHoGdU4g9P2PA44BXgF+dxDncTD6AZcBXwX+K4jn9rDtPwe+BVwDnEjoPL8WpVhEpLm4uxYtWrREdSGUrFQDZfWWO8PqJAMzgReAOcAz9Y5RCCwFLKzsV8Da4H0B4MDpYdtzgB3ANcH6t4I6g8PqfB2orD0uoWTr1/U+e0wQb22dlcC/69VZBvwqbN2BsfXqfAsoO8B3Na3ecQqB+xqp3xP4KPi8ZcCTwDeB5LA6U4HxjRyj0fMBzgzOP71enU+AXwTvnwberLf9odCfmbr124D5jX0nTVi/DagAcsLKbgWKwtbXAzeHrRuwBCiM9f8LWrRoaXhRS6mItJT3CLWghS9312509ypCrVlfBroRagmtb5q7h4/m/gjIN7Ns4HBgb1BWe8wdhFr/hobtU+nuS8LW1wEpQMdgfQRwa3Cbvyy4dfw0kAn0CNtvbr3Y1gVxN5mZZZrZXWa2MLjNXAYcB/Rp6jHcfb27nwQMA+4llIA9CMwws4yg2nBC/U0b09j5jAAygM31vpcjgcOCOocT9t0H6q83l1XBtd0vVjPLIXSdZtRuDP6bmYGItGoa6CQiLWW3uxcdoE7trdZcoCtQ0kyfHZ7IVjewLSHs9X+B5yIcZ3PY+6oIxznYf+jfA5xL6HbzMkLdDR4nlCQfFHefD8wH7jezU4H3gf8m1ErdFI2dTwKwETgtwn47DyLMvYSS5nDJB7F/reb47kWkldH/xCLSKgSDje4DbiDU9/FJM6v/D+cTgv6NtU4E1rn7TmARn/c3rT1mNqEWxIUHEcocYIiHBg3VX+ontI2pAhIPUOdU4HF3f97d5wJr+bzl8VDUnm9W8PoxcNYhHG8OoUFLeyN8J5uCOosIXY9w9dc3A93rXcNjDiGu/QQtqBsI68cbfF5D/XpFpJVQS6mItJRUM+tRr6zG3TebWSLwBPCuuz9oZhMI3Xb/LfDrsPp5wL1m9gChZPMm4PcA7r7MzF4GHjSzawm1st5OqCXv6YOI83fAf8xsFfAsoZbVI4GR7v6LgzjOSuAsM3uXUJeB7RHqLAW+GsRdReh80yLUa5CZ/Z3Q7esphJLanoT62u4G3giq3Q68YmZFhL4LIzRA6EF3392Ej3mLUL/Ul83sF8BiQrfIzwXecvf3CU1L9aGZ3QJMAEYRGogUrhDoBPzSzMYHderP5doc/gL8wsyWEkrQv0foe1kfhc8SkWaillIRaSlnE0oKwpePg22/BAYCVwO4+1bgKuDm4FZ0racItT5OB/4JPAz8OWz7twn1HZwYvGYA53porssmcffJwAWERqjPCJabgdVNP1UAfhYcYw2fn2d9PwU2EbrV/hqhQU7vH+TnvEloxoFnCSW5Lwbl57j7UgB3n0QoQTwviOXdILa9TfmAoE/m+YQS338SGjT0LDCYUEKMu08jdP2+T6h/6sWEBiWFH2dRsP3aoM457D+rQXO4h9A/cv5F6DuF0PdSEYXPEpFmUjuSVESkVQvmmJzv7jfGOhZpe8zsY+ADd/9BrGMRkch0+15ERNoVM+sLjCbUIpxMaL7Yo4JXEWmllJSKiEh7s5fQXK13E+qmthA4z91nxTQqEWmUbt+LiIiISMxpoJOIiIiIxFxc3L7Pzc31gQMHxjoMiYFdu3aRmZkZ6zAkRnT945uuf3zT9W+dZs+evcXdu0baFhdJaffu3Zk1S12J4lFhYSGjRo2KdRgSI7r+8U3XP77p+rdOwRzQEen2vYiIiIjEnJJSEREREYk5JaUiIiIiEnNKSkVEREQk5pSUioiIiEjMKSkVERERkZhTUioiIiIiMaekVERERERiTkmpiIiIiMScklIRERERiTklpSIiIiISc0pKRURERCTmlJSKiIiISMwpKRURERGRmFNSKiIiIiIxF9Wk1MzONbMlZlZkZjdH2J5qZs8E26ebWb+gvLOZvWNmZWZ2X719RpjZvGCfv5qZHSiOlTv3csofpvDSx8XNdWoiIiIi0oyilpSaWSJwP3AeMBS4wsyG1qt2NbDd3QcCfwbuDMorgF8DP49w6L8D3wUKguXcpsRTXFLOLS/MU2IqIiIi0gpFs6V0JFDk7svdfQ8wHrioXp2LgMeC9xOAs8zM3H2Xu39AKDmtY2Y9gWx3n+buDjwOjGlqQOVVNdw9eckXPB0RERERiZakKB47H1gTtr4WOKGhOu5ebWY7gM7AlkaOubbeMfMjVTSza4FrAVJ6DKwrLy4pp7CwsKnnIG1cWVmZrncc0/WPb7r+8U3Xv+2JZlIaU+4+DhgHkNqzwGvL83PTGTVqVKzCkhZWWFio6x3HdP3jm65/fNP1b3uiefu+GOgdtt4rKItYx8ySgBxg6wGO2esAx2zUwG6Z1Oz1A1cUERERkRYTzaR0JlBgZv3NLAW4HJhYr85E4Krg/VhgStBXNCJ3Xw/sNLMTg1H33wRebkoweblpnFbQhXeXbuG7j8+itKLqYM9HRERERKIkarfvgz6iNwKTgUTgEXdfYGa/A2a5+0TgYeAJMysCthFKXAEws5VANpBiZmOA/3L3hcD1wKNAOvBasDSqX3YCH958FgBPTFvFbRMXMPbvH/HQVcfRu1NGs52ziIiIiHwxUe1T6u6TgEn1yn4T9r4CuLSBffs1UD4LOPKLxnTliX3p1zmD65+aw5j7pzLumyMY0bfTFz2ciIiIiDSDuHyi02kFXXnx+lPISkviinHTNXepiIiISIzFZVIKMLBbFi9dfwrD++Ty42c+4Y9vLGGvBkCJiIiIxETcJqUAHTNTeOLqE7jsuN78bUoRN/57DuV7amIdloiIiEjcieukFCAlKYE/XDKMW88/nNfmb+CycR+xcWfFgXcUERERkWYT90kpgJnx3dMHMO7K4yjaVMZF901lfvGOWIclIiIiEjeUlIY5Z2h3Jlx3MgkGl/7jI16fvz7WIYmIiIjEBSWl9QzNy+alG09hcI8OXPfkHB4oLKKR+fxFREREpBkoKY2gW4c0xl97Ihcencddry/hZ899SmW1BkCJiIiIREtUJ89vy9KSE/nL5cdwWNcs/vzWUtZs280/vjGCzlmpsQ5NREREpN1RS2kjzIwfnV3A364Yzty1OxjzwFSWbiyNdVgiIiIi7Y6S0ib4ytF5PPO9kyjfs5dLHviQwiWbYh2SiIiISLuipLSJjumdy8QbT6FXpwy+8+hMHp26QgOgRERERJqJktKDkJebzoTrTuLMId257ZWF/Prl+VTV7I11WCIiIiJtngY6HaTM1CQevHIEd72+mAffW86M5dsoraxmw44K8nLTuWn0YMYMz491mCIiIiJtipLSLyAxwbjl/MPZUVHF+Blr6sqLS8q55YV5AEpMRURERA6Cbt8fgveXbtmvrLyqhrsnL4lBNCIiIiJtl5LSQ7CupPygykVEREQkMiWlhyAvNz1ieVKisWbb7haORkRERKTtUlJ6CG4aPZj05MR9ylISjQTggr++z+QFG2ITmIiIiEgbo6T0EIwZns8dFw8jPzcdA/Jz07lr7NG8+dNR9O2cyfeemM3vXlnInmpNGyUiIiLSGI2+P0RjhudHHGk/4fsnccekxTwydQWzV23jvq8dS+9OGTGIUERERKT1U0tplKQmJXLbhUfwj28cy/Itu3Q7X0RERKQRSkqj7Nwje/LqD06jX5fQ7fz/fWWBbueLiIiI1KOktAX06ZzBc9edxLdP6ce/pq7k0n98qNH5IiIiImGUlLaQ1KREfvuVz2/nn//X93l9vm7ni4iIiICS0hZ37pE9mfTD0xjQJZPrntTtfBERERFQUhoTvTtl8Nx1J/OdU/rzr6krGfuPD1m9VbfzRUREJH4pKY2RlKQEfvOVoTx45QhWbNnFBX97n9fnr491WCIiIiIxoaQ0xkYf0SPsdv4cbpu4gMrqmliHJSIiItKilJS2AuG38x/9cCVj//6RbueLiIhIXFFS2kqE385ftTU02f5r83Q7X0REROJDVJNSMzvXzJaYWZGZ3Rxhe6qZPRNsn25m/cK23RKULzGz0WHlPzGzBWY238z+bWZp0TyHljb6iB68+sPTGNAti+8/pdv5IiIiEh+SonVgM0sE7gfOAdYCM81sorsvDKt2NbDd3Qea2eXAncBlZjYUuBw4AsgD3jKzQUAP4IfAUHcvN7Nng3qPRus8YqF3pwye+95J3Pn6Yh7+YAWzV21nzDF5PDJ1JetKysnLTeem0YMZMzw/1qGKiIiINItotpSOBIrcfbm77wHGAxfVq3MR8FjwfgJwlplZUD7e3SvdfQVQFBwPQol0upklARnAuiieQ8ykJCXw6y8PZdyVI1i2cSf/79VFFJeU40BxSTm3vDCPlz4ujnWYIiIiIs0iai2lQD6wJmx9LXBCQ3XcvdrMdgCdg/Jp9fbNd/ePzOweYDVQDrzh7m9E+nAzuxa4FqBr164UFhYe8gnFQgqQlggV1fuWl1fV8P9e/pTcHctiEldbUVZW1mavvRw6Xf/4pusf33T9255oJqXNzsw6EmpF7Q+UAM+Z2Tfc/cn6dd19HDAOYPDgwT5q1KiWDLVZ7Xj91Yjl2yqctnxeLaGwsFDfURzT9Y9vuv7xTde/7Ynm7ftioHfYeq+gLGKd4HZ8DrC1kX3PBla4+2Z3rwJeAE6OSvStSF5uesTy9JRESiuqWjgaERERkeYXzaR0JlBgZv3NLIXQgKSJ9epMBK4K3o8Fpri7B+WXB6Pz+wMFwAxCt+1PNLOMoO/pWcCiKJ5Dq3DT6MGkJyfuU5aUYOzeU8O5977P+8s2xygyERERkeYRtaTU3auBG4HJhBLHZ919gZn9zswuDKo9DHQ2syLgp8DNwb4LgGeBhcDrwA3uXuPu0wkNiJoDzAviHxetc2gtxgzP546Lh5Gfm44B+bnp3HPp0bxw/cmkJidw5cMzuOWFeWo1FRERkTYrqn1K3X0SMKle2W/C3lcAlzaw7+3A7RHKfwv8tnkjbf3GDM+POAXUpB+exp/fXMo/31/Oe0s3c+clR3FqQZcYRCgiIiLyxemJTm1cWnIit5x/OM9dF2o1/cbD0/nli/Moq6w+8M4iIiIirYSS0nZiRN+OTPrhaVx7+gD+PWM1o//8Hh8s2xLrsERERESaRElpO5KWnMgvzz+cCdedTGpSqNX0VrWaioiISBugpLQdGtG3I5N+dBrfPa0/TwetplOL1GoqIiIirZeS0nYqLTmRWy8YyoTrTiI1KYGvP6RWUxEREWm9lJS2cyP6dmLSj07jmlNDrabn3vseH6rVVERERFoZJaVxIC05kV99eSjPfe8kkhMT+NpD0/nVS/PYpVZTERERaSWUlMaR4/p1YtIPT+PqU/vz1PTVjL73PT78TK2mIiIiEntKSuNMekoiv/7yUJ6tbTX953R+/dJ8tZqKiIhITEX1iU7Seh0ftJre88YSHpm6gsKlm/jK0Xm8/PE61pWUk5ebzk2jB0d8ipSIiIhIc1NLaRwLbzUtr6zmgXc+o7ikHAeKS8q55YV5vPRxcazDFBERkThwwKTUzAaZ2dtmNj9YP8rMfhX90KSlHN+vEylJifuVl1fVcPfkJTGISEREROJNU1pK/wncAlQBuPtc4PJoBiUtb/2Oiojl60rKWzgSERERiUdNSUoz3H1GvTKNimln8nLTI5Y7cM/kJezeo0suIiIi0dOUpHSLmR1GKD/BzMYC66MalbS4m0YPJj1531v4aUkJHNc3l/veKeLsP77LpHnrcfcYRSgiIiLtWVNG398AjAOGmFkxsAL4elSjkhZXO8r+7slL9ht9P2PFNn7z8nyuf2oOpw7swm0XDmVgtw4xjlhERETak6Ykpe7uZ5tZJpDg7qVm1j/agUnLGzM8P+IUUCP7d+I/PziVp2es5p7JSzj33vf5zqn9+eFZBWSlalYxEREROXRNuX3/PIC773L30qBsQvRCktYoKTGBb57Ujyk/H8Ulx/Zi3HvLOfOeQl7+pFi39EVEROSQNZiUmtkQM7sEyDGzi8OWbwFpLRahtCpdslK5c+xRvHj9yXTPTuNH4z/hsnHTWLxhZ6xDExERkTassZbSwcCXgVzgK2HLscB3ox+atGbD+3TkpRtO4Y6Lh7FsYykX/PUDbpu4gB3lVbEOTURERNqgBjsEuvvLwMtmdpK7f9SCMUkbkZhgXDGyD+cd2YN73ljCYx+t5JVP1/E/5w1h7LG9SEiwWIcoIiIibURT+pR+bGY3mNkDZvZI7RL1yKTNyM1I4fdjhvHKjafSt3MGv5gwl0v+8SHz1u6IdWgiIiLSRjQlKX0C6AGMBt4FegGlje4hcenI/BwmXHcy91x6NGu27ebC+z/g1hfnsX3XnliHJiIiIq1cU5LSge7+a2CXuz8GXACcEN2wpK1KSDDGjujFlJ+P4tsn92f8zDV86Y+FPDV9FTV7NUpfREREImvKJJO1I1dKzOxIYAPQLXohSXuQnZbMb74ylP8+vhe/fXkBt744n/Ez1vC/Fx3B6q27I07SLyIiIvGrKUnpODPrCPwKmAhkAb+OalTSbgzpkc34a0/klbnruf3VhVz8wIckmlETzG1aXFLOLS/MA1BiKiIiEscOePve3R9y9+3u/p67D3D3bsBrLRCbtBNmxoVH5/H2z0aRlZpUl5DWKq+q4e7JS2IUnYiIiLQGjSalZnaSmY01s27B+lFm9jQwtUWik3YlKzWJXZXVEbetKylv4WhERESkNWnsiU53A48AlwCvmtnvgTeA6UBBy4Qn7U1ebnrE8sQE4/X56/XIUhERkTjVWEvpBcBwd78C+C/gx8CJ7v4Xd69okeik3blp9GDSkxP3KUtJNDplpnDdk3MYc/9UphZtiVF0IiIiEiuNJaUVtcmnu28Hlrn7yoM5uJmda2ZLzKzIzG6OsD3VzJ4Jtk83s35h224JypeY2eiw8lwzm2Bmi81skZmddDAxSWyNGZ7PHRcPIz83HQPyc9O5a+zRfHjzmdw19ig2l1by9Yem842HpjN3bUmswxUREZEW0tjo+wFmNjFsvX/4urtf2NiBzSwRuB84B1gLzDSzie6+MKza1cB2dx9oZpcDdwKXmdlQ4HLgCCAPeMvMBrl7DfAX4HV3H2tmKUBGk89WWoUxw/MjjrT/7+N6c+HReTw5bRUPFH7GhfdN5fxhPfjpOYMZ2C0rBpGKiIhIS2ksKb2o3vofD/LYI4Eid18OYGbjg2OGJ6UXAbcF7ycA95mZBeXj3b0SWGFmRcBIM1sInA58C8Dd9wB6XFA7kpacyDWnDeCy43vz0PsreOj95bw+fwOXjujNj84uaLBPqoiIiLRtDSal7v7uIR47H1gTtr6W/Z8EVVfH3avNbAfQOSifVm/ffKAc2Az8y8yOBmYDP3L3XfU/3MyuBa4F6Nq1K4WFhYd4OtLShifDHaem8p/P9vD87DU8P2cNZ/dJ4ssDUshKsSYdo6ysTNc+jun6xzdd//im69/2NGXy/NYkCTgW+IG7TzezvwA3E2Eyf3cfB4wDGDx4sI8aNaol45RmdCGwdvtu7n1rGS/MWcvU9fDd0wdw9an9yUxt/D/hwsJCdO3jl65/fNP1j2+6/m3PASfPPwTFQO+w9V5BWcQ6ZpYE5ABbG9l3LbDW3acH5RMIJanSzvXqmME9lx7N6z8+nZMO68yf3lzKGXe/w6NTV1BZXRPr8EREROQQRTMpnQkUmFn/YEDS5YQeUxpuInBV8H4sMMVDE1VOBC4PRuf3JzQv6gx33wCsMbPBwT5nsW8fVWnnBnXvwLhvHscL15/MwG5Z3PbKQs68512en72Wmr2a41RERKStOuDtezN7Baj/134HMAt4sKE5S4M+ojcCk4FE4BF3X2BmvwNmuftE4GHgiWAg0zZCiStBvWcJJZzVwA3ByHuAHwBPBYnucuDbB3XG0i4c26cj//7uiby/bAt3TV7Mz577lAff+4ybRg/h7MO7ERovJyIiIm1FU/qULge6Av8O1i8DSoFBwD+BKxva0d0nAZPqlf0m7H0FcGkD+94O3B6h/BPguCbELe2cmXH6oK6cOrALk+av549vLOW7j8/i2D65nHxYZ178eB3FJeXkT5vCTaMHR5yGSkRERFqHpiSlJ7v78WHrr5jZTHc/3swWRCswkaZKSDC+fFQeo4/owYTZa7lj0kLmrP584v3iknJueWEegBJTERGRVqopfUqzzKxP7UrwvnYmc80RKq1GcmICV4zsQ1Zq8n7byqtquHvykhhEJSIiIk3RlJbSnwEfmNlngAH9gevNLBN4LJrBiXwR63dE7OZMcUk57y7dzOkFXdTnVEREpJU5YFLq7pPMrAAYEhQtCRvcdG/UIhP5gvJy0ykuKd+vPMHgqkdmcEReNtePGsi5R/YgMUHJqYiISGvQ1CmhRhB6Dv3RwH+b2TejF5LIoblp9GDSkxP3KUtPTuSuS47izkuGsXtPDTc8PYdz/vQuz8xczZ7qvTGKVERERGo1ZUqoJ4DDgE+A2mmZHHg8inGJfGG1g5nunrwkNPo+N32f0fdjR/Tm9fkbeKCwiP95fh5/fnMZ15zWnytG9jngE6JEREQkOpryF/g4YGgwqb1ImzBmeD5jhudHfMxcYoJxwVE9OX9YD95btoUH3ini968u4r53ivjWyf341sn9yM1IiU3gIiIicaopSel8oAewPsqxiLQoM+OMQV05Y1BXZq/azt8Li7j3rWWMe285XxvZh2tOG0CPnLRYhykiIhIXmpKUdgEWmtkMoLK20N0vjFpUIi1sRN+OPHTV8SzesJN/FH7Gvz5cyWMfreSSY3vxvTMOo3+XzFiHKCIi0q41JSm9LdpBiLQWQ3pkc+/lw/nZfw3mwfc+49lZa3lm1hrOH9aT759xGEfm58Q6RBERkXapKVNCvdsSgYi0Jr07ZfD7McP44VkFPPLBSp6ctopX567njEFduX7UYYzs30lznYqIiDSjBpNSM/vA3U81s1JCo+3rNgHu7tlRj04kxrp1SOPm84bw/VGH8eS0VTzywQouGzeNEX078v0zDqO0oop73ljKupJy8uqN8hcREZGmazApdfdTg9cOLReOSOuUk57MDV8ayHdO6c+zs9Yw7r3lXPP4rNC/0II6xSXl3PLCPAAlpiIiIgepSZPnm1mimeWZWZ/aJdqBibRG6SmJXHVyPwpvGkXHjGTqz5NWXlXD3ZOXxCQ2ERGRtqwpk+f/APgtsBGoffSNA0dFMS6RVi05MYGS3VURtxWXlDN3bQlH9cpt4ahERETarqaMvv8RMNjdt0Y7GJG2JC83neKS8v3KDbjwvqkc0zuXq07uy/nDepKalLj/AURERKROU27frwF2RDsQkbbmptGDSU/eN9lMT07k/y4+kt9+ZSg7y6v4yTOfcvIdU7h78mLWRUhgRUREJKQpLaXLgUIze5V9J8//U9SiEmkDagcz3T15ScTR91ed1I+pn23hsQ9X8UDhZ/zj3eWcc3h3vnlyX04a0FlTSomIiIRpSlK6OlhSgkVEAmOG5zc40j4hwTitoCunFXRlzbbdPDV9NeNnrub1BRso6JbFN0/ux1eH55OV2pT/DUVERNq3Rv8amlkiMMjdv95C8Yi0S707ZXDzeUP48dkFvPLpOh77aCW/fmk+d762mLEjenHlSX05rGtWrMMUERGJmUaTUnevMbO+Zpbi7ntaKiiR9iotOZFLj+vN2BG9+HhNCY9/uJKnpq/i0Q9XclpBF755Uj/OHNKNxATd2hcRkfjS1D6lU81sIrCrtlB9SkW+ODPj2D4dObZPR269YCjPzFzNk9NW893HZ5Gfm86VJ/XlsuN60zFTPWZERCQ+NCUp/SxYEgA93UmkmXXtkMqNZxZw3RmH8ebCjTz20Ur+8Npi/vTmUi48Oo+rTurHZ5vLGhxQJSIi0h4cMCl19/9tiUBE4l1SYgLnDevJecN6smRDKU9MW8kLc4qZMHstZuDB46P0OFMREWmPDjhPqZl1NYJf+kIAAB1hSURBVLO7zWySmU2pXVoiOJF4NbhHB34/ZhjTfnkWOelJdQlprdDjTBfHJjgREZEoaMrk+U8Bi4H+wP8CK4GZUYxJRALZacnsLK+OuK24pIJ/vPsZG3dWtHBUIiIiza8pSWlnd38YqHL3d939O8CZUY5LRAJ5uekRy1MSE/jDa4s56Y63+da/ZvCfueuoqKpp4ehERESaR1MGOlUFr+vN7AJgHdApeiGJSLibRg/mlhfmUR6WcKYnJ3LHxcM4qlcOL8wp5vk5a7nx6Y/JSU/mwqPzGDuiF0f1ytFTo0REpM1oSlL6ezPLAX4G/A3IBn4S1ahEpM6BHmf689GD+ck5g/jwsy1MmL2WZ2et4YlpqyjolsXYEb346vB8umWnxfIUREREDqgpo+//E7zdAXwpuuGISCSNPc4UIDHskaY7K6p4de56Jsxeyx2vLebO1xdzxqCujB3Rm7OHdiM1KbEFIxcREWmaAyalZjYI+DvQ3d2PNLOjgAvd/fdRj05EDlp2WjJXjOzDFSP7sHxzGc/PWcvzs4u54ek55KQnc9Exodv7w/J1e19ERFqPpgx0+idwC0HfUnefC1zelIOb2blmtsTMiszs5gjbU83smWD7dDPrF7btlqB8iZmNrrdfopl9bGb/qX9MEfncgK5Z3DR6CFNvPpPHvzOSMwZ15ZmZa7jwvqmMvvc9xr33GZtKQ6P3X/q4mFP+MIX+N7/KKX+YwksfF8c4ehERiSdN6VOa4e4z6rWoRJ6jJoyZJQL3A+cAa4GZZjbR3ReGVbsa2O7uA83scuBO4DIzG0oo8T0CyAPeMrNB7l470uNHwCJC/VtF5AASE4zTB3Xl9EFd2VFee3t/Df83aTF3vr6Ewd2zKNpUxp6a0ISomqBfRERaWlNaSreY2WGAA5jZWGB9E/YbCRS5+3J33wOMBy6qV+ci4LHg/QTgLAtlvxcB49290t1XAEXB8TCzXsAFwENNiEFE6slJT+ZrJ/ThhetP4e2fncH3Th/A4g2ldQlprdAE/UtiFKWIiMSbprSU3gCMA4aYWTGwAvh6E/bLB9aEra8FTmiojrtXm9kOoHNQPq3evrXNNfcCvwA6NPbhZnYtcC1A165dKSwsbELI0t6UlZXp2h/AyDR4wCNvKy4p58EX3qagYwIJbbD/qa5/fNP1j2+6/m1PU0bfLwfONrNMIMHdS83sx4SSwxZlZl8GNrn7bDMb1Vhddx9HKJlm8ODBPmpUo9WlnSosLETX/sDyp02huKQ84rY7ZlTQrUMq5w/ryfnDenJc344kJLSNBFXXP77p+sc3Xf+2pyktpQC4+66w1Z9y4KS0GOgdtt4rKItUZ62ZJQE5wNZG9r0QuNDMzgfSgGwze9Ldv9HU8xCR/TU0Qf9tXxlKemoSk+au598zVvPohyvpnp3KeUf25IKjejKiT9tJUEVEpHVrclJaT1P+Cs0ECsysP6GE8nLga/XqTASuAj4CxgJT3N3NbCLwtJn9idBApwJghrt/RGgmAIKW0p8rIRU5dAeaoP/Co/Moq6zm7UUbmTRvPU8HCWqP7DTOG9aDC4b15FglqCIicgi+aFLaQA+0sAqhPqI3ApOBROARd19gZr8DZrn7ROBh4AkzKwK2EUw1FdR7FlhIaKT/DWEj70UkCg40QX9WahIXHZPPRcfk1yWor85dz1PTV/OvqaEE9fxhoRbU4b1zlaCKiMhBaTApNbNSIiefBqQ35eDuPgmYVK/sN2HvK4BLG9j3duD2Ro5dCBQ2JQ4RaV7hCWppRRVvL9rEq/PW8+S0VTwydQU9c/ZNUDVJv4iIHEiDSam7Nzq6XUQEoENacl0r686KqqAFdQNPfLSKhz9YQV5YgnpM71xe/mRdg90EREQkfn3R2/ciIvvJTkvmq8N78dXhvdhZUcVbC0N9UB//aBUPfbCC3PRkyiqrqd6rSfpFRGRfSkpFJCqy05K5+NheXHxsL3aUhxLUW1+cV5eQ1iqvquGu1xcrKRURiXNNeaKTiMghyUlP5pIRvais3htx+7odFXzn0Zk8OW0V63dEni9VRETaN7WUikiLyctNjzhJf2ZqIkWbypiyeBO/egmG9szmrMO7cdbh3TkqP0cj+UVE4oCSUhFpMQ1N0n/7mGFcdEwen20u4+1Fm3h70Sbuf6eIv00poktWCl8aHEpQTyvoQmaqfrZERNoj/bqLSIs50CT9A7t1YGC3DnzvjMMo2b2Hd5du5q1Fm3h9wQaem72WlMQETjysM2cN6caZQ7rRu1NGLE9HRESakZJSEWlRB5qkv1ZuRkrdXKhVNXuZvWo7by/ayNuLN/HbiQv47cQFDO7egTMP78ZZQ7oxvE9HEoPb/C99XMzdk5dQXFJO/rQpmnZKRKQNUFIqIq1ecmICJw7ozIkDOnPrBUNZsWUXby/ayJTFm/jne8v5e+FndMxI5kuDu9EhLYlnZq2hoio0qErTTomItA1KSkWkzenfJZNrThvANacNYGdFFe8t3cyURZt4Z8kmtu+u2q9+eVUNd09eoqRURKQV05RQItKmZacl8+Wj8vjTZccw61fn0NA4/eKScp6btYZ1EUb/i4hI7KmlVETajcQEa3DaqQSDmybMBWBA10xOHdiFUwZ24cQBnclJT27pUEVEpB4lpSLSrjQ07dT/ffVIDs/L5oNlW5hatIUJs9fy+EerSDA4qlduXZJ6bN9cUpMSY3gGIiLxSUmpiLQr4dNOFZeUk19v2qkhPbK55rQB7KneyydrSvigKJSk/v3dz7jvnSLSkhMY2b8zpw7szCkDu3B4j2xN3i8i0gKUlIpIu1M77VRhYSGjRo2KWCclKYGR/Tsxsn8nfnrOIEorqpi+fFtdkvp/kxYD0CkzhZMP61zXkho+N2rt1FOR5lwVEZGDo6RURATokJbM2UO7c/bQ7gBs3FnB1KItfFC0hQ+WbeE/c9cD0LdzBqcM7EJKojF+pqaeEhFpLkpKRUQi6J6dxsXH9uLiY3vh7hRtKqtrRZ34yTrKKqv320dTT4mIfHFKSkVEDsDMKOjegYLuHfj2Kf2pqtnLoFtfwyPUrW0xHdm/I8f360R+bjpm6pMqInIgSkpFRA5ScmJCg1NPpSYl8J9P1/HvGasB6JmTxvH9OnF8/04c368jg7p10MApEZEIlJSKiHwBDU09dcfFw/jK0Xks2VDKzJXbmLFyG9OWb2Xip+sAyE5L4rh+nTi+XydG9u/Ikfk5moJKRAQlpSIiX0j41FORRt8PzctmaF42V53cD3dnzbZyZqzcxqwgUZ2yeBMQalk9uncuI/t14rh+HRnRtyMd0j6fzF8j/EUkXigpFRH5gmqnnjoQM6NP5wz6dM5g7IheAGwpq2TWyu3MXLmNmSu38fd3P6PmHSfB4PCe2RzfrxPuzjMz11BRrRH+ItL+KSkVEYmBLlmpnHtkD849sgcAuyqr+Xh1SV2S+szMNft0DahVXlXDXZMXKykVkXZHSamISCuQmZrEqQVdOLWgC0CjI/zXlVRw8QNTObp3LscES59OGRrlLyJtmpJSEZFWqLER/lmpiSQmGP+esZp/TV0JQG5GMkf3yg0S1RyO6pVLl6zUFo5aROSLU1IqItJKNTTC//djhjFmeD7VNXtZurGMT9eW8OmaEj5ZU8J9U5axN2he7dUxPZSkBsnqkfnZZKToZ19EWif9OomItFIHGuGflJhQN8r/ipF9ANi9p5r5xTtDSWqQrL4aPCI1wWBQ9w51t/yP7p1LQbcskhITNMpfRGJOSamISCvW1BH+tTJSkhjZvxMj+3eqK9tSVsnctSV8srqET9bu4LX5Gxg/cw0QanntmZPG6m27qQ6aWDXKX0RiQUmpiEg71yUrlTOHdOfMId0BcHdWbd3Np2tDt/yfnLaqLiGtVV5Vw60vzWNPzV6G9symoHuWJvkXkahSUioiEmfMjH5dMunXJZOLjsnn0WCwVH27Kmv4xYS5ACQlGAO7ZTE0L5sj8nIY2jOboT2zyclIjriviMjBimpSambnAn8BEoGH3P0P9banAo8DI4CtwGXuvjLYdgtwNVAD/NDdJ5tZ76B+d8CBce7+l2ieg4hIe9fQKP+83DSeuuZEFq7byYJ1O1i4ficfLNvCC3OK6+rk56aH+rX2zOaIoH9rfm56g9NTqe+qiDQkakmpmSUC9wPnAGuBmWY20d0XhlW7Gtju7gPN7HLgTuAyMxsKXA4cAeQBb5nZIKAa+Jm7zzGzDsBsM3uz3jFFROQgNDTK/xejh9C/Syb9u2RywVE967ZtLq1k0fqdLFi3k4Xrd7Jw3Q7eWrQRD3oAZKclBYlqTtCyms3Ablm8Onf9Pp+jvqsiEi6aLaUjgSJ3Xw5gZuOBi4DwBPIi4Lbg/QTgPgv98/oiYLy7VwIrzKwIGOnuHwHrAdy91MwWAfn1jikiIgfhQKP86+vaIZWuHbpy+qCudWW791SzZEMpC2uT1XU7eXrGKiqqQo9ITUlMwHGqavbvu3r35CVKSkUEc4/0vJBmOLDZWOBcd78mWL8SOMHdbwyrMz+oszZY/ww4gVCiOs3dnwzKHwZec/cJYfv2A94DjnT3nRE+/1rgWoCuXbuOePbZZ6NwltLalZWVkZWVFeswJEZ0/WNrrzsbdjmrS/eyeudeJq2oarDumb2TyMtKID9YslMP/elUuv7xTde/dfrSl740292Pi7StTQ50MrMs4Hngx5ESUgB3HweMAxg8eLCPGjWq5QKUVqOwsBBd+/il69+6nPKHKRH7rqYkJjBzM5Su2VNX1ikzhYJuWQzq3oFB3bMo6N6BQd070Ckzpcmfp+sf33T9255oJqXFQO+w9V5BWaQ6a80sCcghNOCpwX3NLJlQQvqUu78QndBFRKS5NdR39Y6Lh3HRMXls3FnJ0o2lLN1YyrKNZSzdVMqLHxdTVlldV79LVgoF3fZNVAu6ZdExLFmtHUxVXFJO/rQpGkwl0kZEMymdCRSYWX9CCeXlwNfq1ZkIXAV8BIwFpri7m9lE4Gkz+xOhgU4FwIygv+nDwCJ3/1MUYxcRkWZ2oL6rPXLS6JGTtk9fVXdn/Y6KzxPVjaUs3VTGhNlr2bXn8+S2S1Yqg7pnkZhgTFu+ta7vqgZTibQdUUtK3b3azG4EJhOaEuoRd19gZr8DZrn7REIJ5hPBQKZthBJXgnrPEhrAVA3c4O41ZnYqcCUwz8w+CT7ql+4+KVrnISIizedgn1BlZuTlppOXm86owd3qyt2d4pJylm0qY9nGUpZuDL3OXbuD+iMlyqtq+OWL81i3o5wBXTLp3yWLvp0zSEvWwwBEWpOo9ikNksVJ9cp+E/a+Ari0gX1vB26vV/YBcOi930VEpE0zM3p1zKBXxwy+FJas9r/51Yj1d++p4a7Xl4TtH5pjtX+XzCBRzWRA1yz6d8kkLzedxIQD/6nRnKsizatNDnQSERGJpKEHAeTnpvP6j09j5ZbdLN9SxvLNu1ixJbTU7wqQkpRAv84ZDOiSRf+umXWJ64CuWXTMSMbMeOnjYs25KtLMlJSKiEi70dBgqptGD6ZDWjLDeuUwrFfOPvu4O5tLK1m+5fNEdfnm0ECrtxZtpHrv5x0CctKT6d8lkyUbSvf5DNCcqyKHSkmpiIi0G+GDqYpLyslvwm11M6NbdhrdstM4cUDnfbZV1+xl7fby/VpX6yektYpLyrnh6Tn06ZSxz9IzJ42kxITmO1GRdkhJqYiItCu1g6maY57KpMQE+nXJpF+XTM4c8nl5Q3OupiYlsKB4B5Pnb9inhTUpwcjvmE6fThn0rpew9u6UQU56csTPV79ViSdKSkVERA5SY3OujhmeT3XNXjbsrGD1tt2s3ro79LptN2u27ea1eevZvnvfp1vlpCfTt/O+Ceuabbt5+IMVVFaHHtWqfqvS3ikpFREROUgHmnM1KTGhbnaAkw/bf/+dFVWsCZLU1XVLOQvX7eSNBRvq5lmtr7yqhl+/NJ/K6pq6qbLyc9M1vZW0C0pKRUREvoCDnXM1XHZaMkfk5XBEXs5+22r2Out3lHPqne9E3Le0spr/eX7ePmWdM1PI75hOXk6QqHZMJz83jfzcDPJy0+iUmULo+TORqZuAtAZKSkVERFqRxITQHKz5DUxvlZebxjPXnsS6knKKS8qD1wqKS8op2lzGu0s37zcQKy05oa5VNT9oYa1dX7huB3e/sYSKKnUTkNhSUioiItIKNdRv9Rejh9A7GCAVibtTsruK4vCkdXs563aEXhetL2VLWWWjn11eVcNvXp6P43TPTqNHdugRsBkpShskevRfl4iISCt0oH6rDTEzOmam0DEzhSPz9+8eAFBRVcP6HRWsKynn6w9Nj1hnZ0U1P3nm033KOqQl1SWota/hSWv37DQ6Z6aQ0MATsdRNQBqjpFRERKSVOpR+q41JS06kf/B41Ya6CfTMSePJa05g444KNuwMlh2hZePOCpZuLGVzaSV7643JSk40unVIo3t2Kj1z0kNJa04qa7bt5plZa9mj2QSkAUpKRURE4lhD3QT+59whHNY1i8O6ZjW4b3XNXraU7alLWDcGyevGHRWs31HBovU7eWfJJnbvifywgfKqGn4xYS5vLtxI1w6p+y5ZqXTrkEqnzJSDevBAbWtscUk5+dOmqDW2DVFSKiIiEse+aDcBCE191SMndOue3pHruDulldUcfdsbRJroak/NXhZt2Ml7yyoprajeb7tZaHaBrh3S6pLV+slr1w6pdMtO5e2FG/nli/PrEmy1xrYtSkpFRETiXLS6CUCoj2t2WjJ5DXQTyM9NZ8rPRgFQvqeGLWWVbCqtZHNpJZvLgtfSSjaXVrC5tJKijaVsLqtscC7X+sqravjtxPlBchtqee2SFepzm3wIj35V/9jmp6RUREREoq6hbgI3jR78+XpKYqMzC9Ryd3aUV7G5NCyBLa3k9kmLItbfUV7Nj8Z/sl95TnoynTNT6JyVQqfMFDpnpYbWM1PolJVKl8wUOmWl0DkzlY4ZyXXdCF76uHifc1GLbPNQUioiIiJRdyjdBOozM3IzUsjNSKGge4e68kc/XNngoK0nrj6BrWWVbNu1hy279rCtbA9bd1WyddcetpZVsmLLLmat3M723Xv2G7wV+kzITU+mU2YKa7aVs6dm7z7by6tq+H//WUi/Lpl0zEimY2YKHVKTGn1owYHEW2usklIRERFpEdHsJgCND9oa2C2Lgd0aHrRVq2avU7J7Tyh5LQu9bt1VydYgid22aw+fbd4Vcd+tu/Yw5v6pdetJCUZuRjK5GSmhRDUjhY4ZKeRm1r4PXjND73MzUshND7XIxmNrrJJSERERaRfCW2OLS8rJ/wKti4kJFrqNn5VKQffIdU75w5SILbJdslK585JhbN9dxfZde9i+ew/bd1dRsjv0ftXW3XyypoSS3VX7tbSGy05LYteeGmrqNdnW9o+t3uvkpCeTk55MbkZy3fu05MQmn2e41tIiq6RURERE2o3a1tjCwkJGjRoVlc9oqEX2VxcczlmHN5DJhnF3du+pCSWtu6qC5HUPJbur6l4f/XBlxH13lFfz8+c+jbgtJSmhLkGtv2SnJ5MbXhYksx99toU7Xlsc9cfM1ia+KT0GjmiojpJSERERkYNwqP1jzYzM1CQyU5Po1TFynTcXbmywf+z4a09kR3lV5GX35+9rH3Kwo7wq4nRbDSmvquF/np/LGws30CE1mQ5pSWSnh147pAXr9V47pCU1OJ9s/a4IDVFSKiIiInKQYtk/tm/nzIM+Xs1ep7Ri/yT2xqc/jli/snovSzeWsTNIaA+UUAJkpCRGTFynLN7UpP2VlIqIiIi0Ms05WwGE+srWzlgQ7o5JixucP/atn55Rt15Vs5eyimp2VoSS1LrXIGkNLVV15aUV1ZTs3sPqbbsbfKJXfUpKRURERFqhaLfGQtPmjwVITkwIzRKQmVL/EAfU0MCw+r74owxEREREpE0bMzyfOy4eRn5uOkaohfSOi4c1azJ80+jBpDdhZgC1lIqIiIjEsWi3yIZ3RVjfSD21lIqIiIhIVI0Zns/Um89kz4ai2Q3VUVIqIiIiIjGnpFREREREYk5JqYiIiIjEnJJSEREREYk5JaUiIiIiEnNRTUrN7FwzW2JmRWZ2c4TtqWb2TLB9upn1C9t2S1C+xMxGN/WYIiIiItL2RC0pNbNE4H7gPGAocIWZDa1X7Wpgu7sPBP4M3BnsOxS4HDgCOBd4wMwSm3hMEREREWljotlSOhIocvfl7r4HGA9cVK/ORcBjwfsJwFlmZkH5eHevdPcVQFFwvKYcU0RERETamGg+0SkfWBO2vhY4oaE67l5tZjuAzkH5tHr71j5q4EDHBMDMrgWuDVYrzWz+FzgHafu6AFtiHYTEjK5/fNP1j2+6/q1T34Y2tNvHjLr7OGAcgJnNcvfjYhySxICufXzT9Y9vuv7xTde/7Ynm7ftioHfYeq+gLGIdM0sCcoCtjezblGOKiIiISBsTzaR0JlBgZv3NLIXQwKWJ9epMBK4K3o8Fpri7B+WXB6Pz+wMFwIwmHlNERERE2pio3b4P+ojeCEwGEoFH3H2Bmf0OmOXuE4GHgSfMrAjYRijJJKj3LLAQqAZucPcagEjHbEI445r59KTt0LWPb7r+8U3XP77p+rcxFmqYFBERERGJHT3RSURERERiTkmpiIiIiMRcu05K9UjS+GZmK81snpl9YmazYh2PRJeZPWJmm8LnJDazTmb2ppktC147xjJGiZ4Grv9tZlYc/AZ8YmbnxzJGiR4z621m75jZQjNbYGY/Csr1G9CGtNukVI8klcCX3P0YzVUXFx4l9FjicDcDb7t7AfB2sC7t06Psf/0B/hz8Bhzj7pNaOCZpOdXAz9x9KHAicEPwN1+/AW1Iu01K0SNJReKKu79HaBaPcOGPMn4MGNOiQUmLaeD6S5xw9/XuPid4XwosIvQkSP0GtCHtOSmN9JjT/AbqSvvkwBtmNjt47KzEn+7uvj54vwHoHstgJCZuNLO5we193bqNA2bWDxgOTEe/AW1Ke05KRU5192MJdeG4wcxOj3VAEjvBgzk0B158+TtwGHAMsB74Y2zDkWgzsyzgeeDH7r4zfJt+A1q/9pyU6pGkcc7di4PXTcCLhLp0SHzZaGY9AYLXTTGOR1qQu2909xp33wv8E/0GtGtmlkwoIX3K3V8IivUb0Ia056RUjySNY2aWaWYdat8D/wXMb3wvaYfCH2V8FfByDGORFlabjAS+in4D2i0zM0JPiVzk7n8K26TfgDakXT/RKZj+414+fyTp7TEOSVqImQ0g1DoKocfpPq3r376Z2b+BUUAXYCPwW+Al4FmgD7AK+G9312CYdqiB6z+K0K17B1YC3wvrXyjtiJmdCrwPzAP2BsW/JNSvVL8BbUS7TkpFREREpG1oz7fvRURERKSNUFIqIiIiIjGnpFREREREYk5JqYiIiIjEnJJSEREREYk5JaUiIi3IzGrM7JOw5eZmPHY/M9NcnCLSJiXFOgARkThT7u7HxDoIEZHWRi2lIiKtgJmtNLO7zGyemc0ws4FBeT8zm2Jmc83sbTPrE5R3N7MXzezTYDk5OFSimf3TzBaY2Rtmlh6zkxIROQhKSkVEWlZ6vdv3l4Vt2+Huw4D7CD2NDuBvwGPufhTwFPDXoPyvwLvufjRwLLAgKC8A7nf3I4AS4JIon4+ISLPQE51ERFqQmZW5e1aE8pXAme6+3MySgQ3u3tnMtgA93b0qKF/v7l3MbDPQy90rw47RD3jT3QuC9f8Bkt3999E/MxGRQ6OWUhGR1sMbeH8wKsPe16CxAyLSRigpFRFpPS4Le/0oeP8hcHnw/uvA+8H7t4HvA5hZopnltFSQIiLRoH9Bi4i0rHQz+yRs/XV3r50WqqOZzSXU2nlFUPYD4F9mdhOwGfh2UP4jYJyZXU2oRfT7wPqoRy8iEiXqUyoi0goEfUqPc/ctsY5FRCQWdPteRERERGJOLaUiIiIiEnNqKRURERGRmFNSKiIiIiIxp6RURERERGJOSamIiIiIxJySUhEREZH/v1Ew4AAA5fp3neBEKhgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 792x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwcxhh6ktflR",
        "colab_type": "text"
      },
      "source": [
        "The `LearningRateScheduler` will update the optimizer’s `learning_rate` attribute at the beginning of each epoch. Updating the learning rate just once per epoch is usually enough, but if you want it to be updated more often, for example at every step, you need to write your own callback. This can make sense if there are many steps per epoch.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1F-NPzx4tieU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 945
        },
        "outputId": "7fd4a7f6-c093-46ec-e988-3628b2ffb722"
      },
      "source": [
        "K = keras.backend\n",
        "\n",
        "class ExponentialDecay(keras.callbacks.Callback):\n",
        "    def __init__(self, s=40000):\n",
        "        super().__init__()\n",
        "        self.s = s\n",
        "\n",
        "    def on_batch_begin(self, batch, logs=None):\n",
        "        # Note: the `batch` argument is reset at each epoch\n",
        "        lr = K.get_value(self.model.optimizer.lr)\n",
        "        K.set_value(self.model.optimizer.lr, lr * 0.1**(1 / s))\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "        logs['lr'] = K.get_value(self.model.optimizer.lr)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "lr0 = 0.01\n",
        "optimizer = keras.optimizers.Nadam(lr=lr0)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "n_epochs = 25\n",
        "\n",
        "s = 20 * len(X_train) // 32 # number of steps in 20 epochs (batch size = 32)\n",
        "exp_decay = ExponentialDecay(s)\n",
        "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
        "                    validation_data=(X_valid_scaled, y_valid),\n",
        "                    callbacks=[exp_decay])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 55000 samples, validate on 5000 samples\n",
            "Epoch 1/25\n",
            "55000/55000 [==============================] - 9s 171us/step - loss: 0.8615 - accuracy: 0.7556 - val_loss: 0.8354 - val_accuracy: 0.7950\n",
            "Epoch 2/25\n",
            "55000/55000 [==============================] - 9s 166us/step - loss: 0.6598 - accuracy: 0.7960 - val_loss: 0.5924 - val_accuracy: 0.8348\n",
            "Epoch 3/25\n",
            "55000/55000 [==============================] - 9s 166us/step - loss: 0.5719 - accuracy: 0.8227 - val_loss: 0.5188 - val_accuracy: 0.8486\n",
            "Epoch 4/25\n",
            "55000/55000 [==============================] - 9s 165us/step - loss: 0.5284 - accuracy: 0.8381 - val_loss: 0.4740 - val_accuracy: 0.8516\n",
            "Epoch 5/25\n",
            "55000/55000 [==============================] - 9s 168us/step - loss: 0.4618 - accuracy: 0.8503 - val_loss: 0.5180 - val_accuracy: 0.8436\n",
            "Epoch 6/25\n",
            "55000/55000 [==============================] - 10s 177us/step - loss: 0.4339 - accuracy: 0.8596 - val_loss: 0.5001 - val_accuracy: 0.8522\n",
            "Epoch 7/25\n",
            "55000/55000 [==============================] - 9s 164us/step - loss: 0.3934 - accuracy: 0.8734 - val_loss: 0.5406 - val_accuracy: 0.8512\n",
            "Epoch 8/25\n",
            "55000/55000 [==============================] - 9s 165us/step - loss: 0.3710 - accuracy: 0.8804 - val_loss: 0.4602 - val_accuracy: 0.8630\n",
            "Epoch 9/25\n",
            "55000/55000 [==============================] - 9s 165us/step - loss: 0.3306 - accuracy: 0.8901 - val_loss: 0.4615 - val_accuracy: 0.8728\n",
            "Epoch 10/25\n",
            "55000/55000 [==============================] - 9s 165us/step - loss: 0.3155 - accuracy: 0.8964 - val_loss: 0.4381 - val_accuracy: 0.8780\n",
            "Epoch 11/25\n",
            "55000/55000 [==============================] - 9s 165us/step - loss: 0.2880 - accuracy: 0.9029 - val_loss: 0.4403 - val_accuracy: 0.8800\n",
            "Epoch 12/25\n",
            "55000/55000 [==============================] - 9s 164us/step - loss: 0.2674 - accuracy: 0.9103 - val_loss: 0.4561 - val_accuracy: 0.8772\n",
            "Epoch 13/25\n",
            "55000/55000 [==============================] - 9s 165us/step - loss: 0.2477 - accuracy: 0.9160 - val_loss: 0.4408 - val_accuracy: 0.8812\n",
            "Epoch 14/25\n",
            "55000/55000 [==============================] - 9s 165us/step - loss: 0.2318 - accuracy: 0.9205 - val_loss: 0.4733 - val_accuracy: 0.8806\n",
            "Epoch 15/25\n",
            "55000/55000 [==============================] - 9s 165us/step - loss: 0.2178 - accuracy: 0.9259 - val_loss: 0.5244 - val_accuracy: 0.8794\n",
            "Epoch 16/25\n",
            "55000/55000 [==============================] - 9s 165us/step - loss: 0.1988 - accuracy: 0.9322 - val_loss: 0.5167 - val_accuracy: 0.8834\n",
            "Epoch 17/25\n",
            "55000/55000 [==============================] - 9s 166us/step - loss: 0.1859 - accuracy: 0.9362 - val_loss: 0.5249 - val_accuracy: 0.8862\n",
            "Epoch 18/25\n",
            "55000/55000 [==============================] - 9s 165us/step - loss: 0.1734 - accuracy: 0.9411 - val_loss: 0.5351 - val_accuracy: 0.8912\n",
            "Epoch 19/25\n",
            "55000/55000 [==============================] - 9s 165us/step - loss: 0.1612 - accuracy: 0.9450 - val_loss: 0.5424 - val_accuracy: 0.8890\n",
            "Epoch 20/25\n",
            "55000/55000 [==============================] - 9s 165us/step - loss: 0.1482 - accuracy: 0.9500 - val_loss: 0.5510 - val_accuracy: 0.8900\n",
            "Epoch 21/25\n",
            "55000/55000 [==============================] - 9s 164us/step - loss: 0.1375 - accuracy: 0.9536 - val_loss: 0.5721 - val_accuracy: 0.8924\n",
            "Epoch 22/25\n",
            "55000/55000 [==============================] - 9s 164us/step - loss: 0.1293 - accuracy: 0.9567 - val_loss: 0.6048 - val_accuracy: 0.8934\n",
            "Epoch 23/25\n",
            "55000/55000 [==============================] - 9s 164us/step - loss: 0.1202 - accuracy: 0.9600 - val_loss: 0.6477 - val_accuracy: 0.8922\n",
            "Epoch 24/25\n",
            "55000/55000 [==============================] - 9s 165us/step - loss: 0.1138 - accuracy: 0.9626 - val_loss: 0.6555 - val_accuracy: 0.8930\n",
            "Epoch 25/25\n",
            "55000/55000 [==============================] - 9s 165us/step - loss: 0.1067 - accuracy: 0.9657 - val_loss: 0.6878 - val_accuracy: 0.8926\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ykAqOu_tk_K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "cellView": "both",
        "outputId": "79ed2e20-36ff-4087-9048-1b7b4cacf112"
      },
      "source": [
        "#@title\n",
        "n_steps = n_epochs * len(X_train) // 32\n",
        "steps = np.arange(n_steps)\n",
        "lrs = lr0 * 0.1**(steps / s)\n",
        "\n",
        "plt.figure(figsize=(11, 4))\n",
        "plt.plot(steps, lrs, \"-\", linewidth=2)\n",
        "plt.axis([0, n_steps - 1, 0, lr0 * 1.1])\n",
        "plt.xlabel(\"Batch\")\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.title(\"Exponential Scheduling (per batch)\", fontsize=14)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 792x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJqrpoNRtsUF",
        "colab_type": "text"
      },
      "source": [
        "The schedule function can optionally take the current learning rate as a second argument. For example, the following schedule function just multiplies the previous learning rate by $(0.1)^{\\frac{1}{20}}$ , which results in the same exponential decay (except the decay now starts at the beginning of epoch $0$ instead of $1$). This implementation relies on the optimizer’s initial learning rate (contrary to the previous implementation), so make sure to set it appropriately."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pi1PlihBtvdy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def exponential_decay_fn(epoch, lr):\n",
        "    return lr * 0.1**(1 / 20)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3l8RTFGtyPF",
        "colab_type": "text"
      },
      "source": [
        "When you save a model, the optimizer and its learning rate get saved along with it. This means that with this new schedule function, you could just load a trained model and continue training where it left off, no problem. However, things are not so simple if your schedule function uses the epoch argument: indeed, the epoch does not get saved, and it gets reset to 0 every time you call the `fit()` method. This could lead to a very large learning rate when you continue training a model where it left off, which would likely damage your model’s weights. One solution is to manually set the `fit()` method’s `initial_epoch` argument so the epoch starts at the right value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24lVhWJIiP23",
        "colab_type": "text"
      },
      "source": [
        "#### Piecewise constant scheduling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYLWK2TJiV-a",
        "colab_type": "text"
      },
      "source": [
        "Use a constant learning rate for a number of epochs (e.g., $\\eta_0=0.1$ for $5$ epochs), then a smaller learning rate for another number of epochs (e.g., $\\eta_1=0.001$ for $50$ epochs), and so on. Although this solution can work very well, it requires fiddling around to figure out the right sequence of learning rates, and how long to use each of them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ig7VqyUmuT45",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def piecewise_constant_fn(epoch):\n",
        "    if epoch < 5:\n",
        "        return 0.01\n",
        "    elif epoch < 15:\n",
        "        return 0.005\n",
        "    else:\n",
        "        return 0.001"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ake8NgARuURD",
        "colab_type": "text"
      },
      "source": [
        "As earlier, you can define a more general function if you want."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwsHFLM0uWsy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def piecewise_constant(boundaries, values):\n",
        "    boundaries = np.array([0] + boundaries)\n",
        "    values = np.array(values)\n",
        "    def piecewise_constant_fn(epoch):\n",
        "        return values[np.argmax(boundaries > epoch) - 1]\n",
        "    return piecewise_constant_fn\n",
        "\n",
        "piecewise_constant_fn = piecewise_constant([5, 15], [0.01, 0.005, 0.001])"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5hkSl4nua-_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 945
        },
        "outputId": "76b2beb9-a24c-4543-ee4d-73fb0e0bdc91"
      },
      "source": [
        "lr_scheduler = keras.callbacks.LearningRateScheduler(piecewise_constant_fn)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
        "n_epochs = 25\n",
        "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
        "                    validation_data=(X_valid_scaled, y_valid),\n",
        "                    callbacks=[lr_scheduler])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 55000 samples, validate on 5000 samples\n",
            "Epoch 1/25\n",
            "55000/55000 [==============================] - 8s 140us/step - loss: 0.8723 - accuracy: 0.7513 - val_loss: 0.8916 - val_accuracy: 0.7376\n",
            "Epoch 2/25\n",
            "55000/55000 [==============================] - 8s 139us/step - loss: 0.8457 - accuracy: 0.7602 - val_loss: 0.7912 - val_accuracy: 0.7562\n",
            "Epoch 3/25\n",
            "55000/55000 [==============================] - 8s 138us/step - loss: 0.8760 - accuracy: 0.7515 - val_loss: 0.9102 - val_accuracy: 0.7078\n",
            "Epoch 4/25\n",
            "55000/55000 [==============================] - 8s 138us/step - loss: 0.9444 - accuracy: 0.7077 - val_loss: 0.8747 - val_accuracy: 0.7172\n",
            "Epoch 5/25\n",
            "55000/55000 [==============================] - 8s 144us/step - loss: 0.9498 - accuracy: 0.6713 - val_loss: 1.3946 - val_accuracy: 0.6278\n",
            "Epoch 6/25\n",
            "55000/55000 [==============================] - 8s 138us/step - loss: 0.7378 - accuracy: 0.7180 - val_loss: 0.7597 - val_accuracy: 0.7216\n",
            "Epoch 7/25\n",
            "55000/55000 [==============================] - 8s 138us/step - loss: 0.6893 - accuracy: 0.7386 - val_loss: 0.7778 - val_accuracy: 0.7462\n",
            "Epoch 8/25\n",
            "55000/55000 [==============================] - 8s 137us/step - loss: 0.6453 - accuracy: 0.7624 - val_loss: 0.7352 - val_accuracy: 0.7380\n",
            "Epoch 9/25\n",
            "55000/55000 [==============================] - 8s 137us/step - loss: 0.6353 - accuracy: 0.7682 - val_loss: 0.8214 - val_accuracy: 0.7630\n",
            "Epoch 10/25\n",
            "55000/55000 [==============================] - 8s 137us/step - loss: 0.5928 - accuracy: 0.7885 - val_loss: 0.7026 - val_accuracy: 0.7992\n",
            "Epoch 11/25\n",
            "55000/55000 [==============================] - 8s 138us/step - loss: 0.5161 - accuracy: 0.8479 - val_loss: 0.5968 - val_accuracy: 0.8236\n",
            "Epoch 12/25\n",
            "55000/55000 [==============================] - 8s 138us/step - loss: 0.4771 - accuracy: 0.8575 - val_loss: 0.6783 - val_accuracy: 0.8460\n",
            "Epoch 13/25\n",
            "55000/55000 [==============================] - 8s 137us/step - loss: 0.4901 - accuracy: 0.8583 - val_loss: 0.6073 - val_accuracy: 0.8332\n",
            "Epoch 14/25\n",
            "55000/55000 [==============================] - 8s 138us/step - loss: 0.4490 - accuracy: 0.8659 - val_loss: 0.5343 - val_accuracy: 0.8532\n",
            "Epoch 15/25\n",
            "55000/55000 [==============================] - 8s 138us/step - loss: 0.4478 - accuracy: 0.8658 - val_loss: 0.6352 - val_accuracy: 0.8542\n",
            "Epoch 16/25\n",
            "55000/55000 [==============================] - 8s 136us/step - loss: 0.3249 - accuracy: 0.8964 - val_loss: 0.4707 - val_accuracy: 0.8686\n",
            "Epoch 17/25\n",
            "55000/55000 [==============================] - 8s 142us/step - loss: 0.2987 - accuracy: 0.9021 - val_loss: 0.4890 - val_accuracy: 0.8750\n",
            "Epoch 18/25\n",
            "55000/55000 [==============================] - 8s 146us/step - loss: 0.2863 - accuracy: 0.9066 - val_loss: 0.4917 - val_accuracy: 0.8740\n",
            "Epoch 19/25\n",
            "55000/55000 [==============================] - 8s 138us/step - loss: 0.2789 - accuracy: 0.9087 - val_loss: 0.4835 - val_accuracy: 0.8764\n",
            "Epoch 20/25\n",
            "55000/55000 [==============================] - 8s 137us/step - loss: 0.2703 - accuracy: 0.9117 - val_loss: 0.5697 - val_accuracy: 0.8726\n",
            "Epoch 21/25\n",
            "55000/55000 [==============================] - 8s 137us/step - loss: 0.2620 - accuracy: 0.9140 - val_loss: 0.5246 - val_accuracy: 0.8758\n",
            "Epoch 22/25\n",
            "55000/55000 [==============================] - 8s 137us/step - loss: 0.2558 - accuracy: 0.9161 - val_loss: 0.5246 - val_accuracy: 0.8788\n",
            "Epoch 23/25\n",
            "55000/55000 [==============================] - 8s 137us/step - loss: 0.2479 - accuracy: 0.9188 - val_loss: 0.5308 - val_accuracy: 0.8742\n",
            "Epoch 24/25\n",
            "55000/55000 [==============================] - 8s 137us/step - loss: 0.2410 - accuracy: 0.9210 - val_loss: 0.5702 - val_accuracy: 0.8738\n",
            "Epoch 25/25\n",
            "55000/55000 [==============================] - 8s 138us/step - loss: 0.2373 - accuracy: 0.9232 - val_loss: 0.5399 - val_accuracy: 0.8762\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3vMmo83ubX-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "122d2dc4-1129-492e-eaa7-500d046806cb"
      },
      "source": [
        "#@title\n",
        "plt.figure(figsize=(11, 4))\n",
        "plt.plot(history.epoch, [piecewise_constant_fn(epoch) for epoch in history.epoch], \"o-\")\n",
        "plt.axis([0, n_epochs - 1, 0, 0.011])\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.title(\"Piecewise Constant Scheduling\", fontsize=14)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 792x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxEvlNkWiZCX",
        "colab_type": "text"
      },
      "source": [
        "#### Performance scheduling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqQVeobNicMS",
        "colab_type": "text"
      },
      "source": [
        "Measure the validation error every $N$ steps (just like for early stopping) and reduce the learning rate by a factor of $\\lambda$ when the error stops dropping.\n",
        "\n",
        "To implement performance scheduling simply use the `ReduceLROnPlateau` callback. For example, if you pass the following callback to the `fit()` method, it will multiply the learning rate by $0.5$ whenever the best validation loss does not improve for $5$ consecutive epochs (other options are available, please check the documentation for more details):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUHKV13vuufg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 945
        },
        "outputId": "4e688cb3-f24e-47fe-9a29-ed329f6de5ad"
      },
      "source": [
        "lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "optimizer = keras.optimizers.SGD(lr=0.02, momentum=0.9)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "n_epochs = 25\n",
        "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
        "                    validation_data=(X_valid_scaled, y_valid),\n",
        "                    callbacks=[lr_scheduler])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 55000 samples, validate on 5000 samples\n",
            "Epoch 1/25\n",
            "55000/55000 [==============================] - 6s 105us/step - loss: 0.5974 - accuracy: 0.8052 - val_loss: 0.4829 - val_accuracy: 0.8450\n",
            "Epoch 2/25\n",
            "55000/55000 [==============================] - 6s 102us/step - loss: 0.5126 - accuracy: 0.8359 - val_loss: 0.5347 - val_accuracy: 0.8442\n",
            "Epoch 3/25\n",
            "55000/55000 [==============================] - 6s 101us/step - loss: 0.5098 - accuracy: 0.8442 - val_loss: 0.4879 - val_accuracy: 0.8436\n",
            "Epoch 4/25\n",
            "55000/55000 [==============================] - 6s 102us/step - loss: 0.5185 - accuracy: 0.8444 - val_loss: 0.6734 - val_accuracy: 0.8224\n",
            "Epoch 5/25\n",
            "55000/55000 [==============================] - 6s 102us/step - loss: 0.5468 - accuracy: 0.8447 - val_loss: 0.5608 - val_accuracy: 0.8478\n",
            "Epoch 6/25\n",
            "55000/55000 [==============================] - 6s 101us/step - loss: 0.5364 - accuracy: 0.8500 - val_loss: 0.8003 - val_accuracy: 0.8378\n",
            "Epoch 7/25\n",
            "55000/55000 [==============================] - 6s 101us/step - loss: 0.3164 - accuracy: 0.8903 - val_loss: 0.4487 - val_accuracy: 0.8676\n",
            "Epoch 8/25\n",
            "55000/55000 [==============================] - 6s 102us/step - loss: 0.2599 - accuracy: 0.9061 - val_loss: 0.4170 - val_accuracy: 0.8632\n",
            "Epoch 9/25\n",
            "55000/55000 [==============================] - 6s 102us/step - loss: 0.2499 - accuracy: 0.9087 - val_loss: 0.3752 - val_accuracy: 0.8874\n",
            "Epoch 10/25\n",
            "55000/55000 [==============================] - 6s 101us/step - loss: 0.2196 - accuracy: 0.9182 - val_loss: 0.4174 - val_accuracy: 0.8862\n",
            "Epoch 11/25\n",
            "55000/55000 [==============================] - 6s 101us/step - loss: 0.2125 - accuracy: 0.9211 - val_loss: 0.4428 - val_accuracy: 0.8646\n",
            "Epoch 12/25\n",
            "55000/55000 [==============================] - 6s 101us/step - loss: 0.2036 - accuracy: 0.9240 - val_loss: 0.4223 - val_accuracy: 0.8822\n",
            "Epoch 13/25\n",
            "55000/55000 [==============================] - 6s 101us/step - loss: 0.1948 - accuracy: 0.9270 - val_loss: 0.4212 - val_accuracy: 0.8864\n",
            "Epoch 14/25\n",
            "55000/55000 [==============================] - 6s 101us/step - loss: 0.1842 - accuracy: 0.9317 - val_loss: 0.4351 - val_accuracy: 0.8812\n",
            "Epoch 15/25\n",
            "55000/55000 [==============================] - 6s 101us/step - loss: 0.1258 - accuracy: 0.9510 - val_loss: 0.3947 - val_accuracy: 0.8926\n",
            "Epoch 16/25\n",
            "55000/55000 [==============================] - 6s 102us/step - loss: 0.1112 - accuracy: 0.9571 - val_loss: 0.4306 - val_accuracy: 0.8944\n",
            "Epoch 17/25\n",
            "55000/55000 [==============================] - 6s 102us/step - loss: 0.1040 - accuracy: 0.9592 - val_loss: 0.4267 - val_accuracy: 0.8922\n",
            "Epoch 18/25\n",
            "55000/55000 [==============================] - 6s 101us/step - loss: 0.0979 - accuracy: 0.9616 - val_loss: 0.4412 - val_accuracy: 0.8934\n",
            "Epoch 19/25\n",
            "55000/55000 [==============================] - 6s 102us/step - loss: 0.0905 - accuracy: 0.9650 - val_loss: 0.4852 - val_accuracy: 0.8926\n",
            "Epoch 20/25\n",
            "55000/55000 [==============================] - 6s 101us/step - loss: 0.0709 - accuracy: 0.9732 - val_loss: 0.4537 - val_accuracy: 0.8990\n",
            "Epoch 21/25\n",
            "55000/55000 [==============================] - 6s 101us/step - loss: 0.0643 - accuracy: 0.9765 - val_loss: 0.4784 - val_accuracy: 0.8978\n",
            "Epoch 22/25\n",
            "55000/55000 [==============================] - 5s 100us/step - loss: 0.0602 - accuracy: 0.9782 - val_loss: 0.4928 - val_accuracy: 0.8942\n",
            "Epoch 23/25\n",
            "55000/55000 [==============================] - 6s 100us/step - loss: 0.0573 - accuracy: 0.9797 - val_loss: 0.5118 - val_accuracy: 0.8952\n",
            "Epoch 24/25\n",
            "55000/55000 [==============================] - 6s 101us/step - loss: 0.0538 - accuracy: 0.9805 - val_loss: 0.5123 - val_accuracy: 0.8980\n",
            "Epoch 25/25\n",
            "55000/55000 [==============================] - 6s 101us/step - loss: 0.0456 - accuracy: 0.9854 - val_loss: 0.5196 - val_accuracy: 0.8974\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aRRMoqUuw1J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "ba426647-e5ed-433a-8575-55c6a755ea4a"
      },
      "source": [
        "#@title\n",
        "plt.plot(history.epoch, history.history[\"lr\"], \"bo-\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Learning Rate\", color='b')\n",
        "plt.tick_params('y', colors='b')\n",
        "plt.gca().set_xlim(0, n_epochs - 1)\n",
        "plt.grid(True)\n",
        "\n",
        "ax2 = plt.gca().twinx()\n",
        "ax2.plot(history.epoch, history.history[\"val_loss\"], \"r^-\")\n",
        "ax2.set_ylabel('Validation Loss', color='r')\n",
        "ax2.tick_params('y', colors='r')\n",
        "\n",
        "plt.title(\"Reduce LR on Plateau\", fontsize=14)\n",
        "plt.show()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KrUbIJWhaZy",
        "colab_type": "text"
      },
      "source": [
        "#### TensorFlow implementatiom"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOjZypzjv2Tu",
        "colab_type": "text"
      },
      "source": [
        "Lastly, tf.keras offers an alternative way to implement learning rate scheduling: just define the learning rate using one of the schedules available in `keras.optimizers.schedules`, then pass this learning rate to any optimizer. This approach updates the learning rate at each step rather than at each epoch. For example, here is how to implement the same exponential schedule as earlier:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5o4hUq_wCsf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 945
        },
        "outputId": "6c813523-38a7-45d2-e721-cd306d26bdda"
      },
      "source": [
        "import tensorflow as tf\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "s = 20 * len(X_train) // 32 # number of steps in 20 epochs (batch size = 32)\n",
        "learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(0.01, s, 0.1)\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "n_epochs = 25\n",
        "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
        "                    validation_data=(X_valid_scaled, y_valid))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 55000 samples, validate on 5000 samples\n",
            "Epoch 1/25\n",
            "55000/55000 [==============================] - 5s 95us/step - loss: 0.4879 - accuracy: 0.8289 - val_loss: 0.4086 - val_accuracy: 0.8594\n",
            "Epoch 2/25\n",
            "55000/55000 [==============================] - 5s 97us/step - loss: 0.3790 - accuracy: 0.8668 - val_loss: 0.3767 - val_accuracy: 0.8658\n",
            "Epoch 3/25\n",
            "55000/55000 [==============================] - 5s 98us/step - loss: 0.3467 - accuracy: 0.8765 - val_loss: 0.3582 - val_accuracy: 0.8722\n",
            "Epoch 4/25\n",
            "55000/55000 [==============================] - 5s 94us/step - loss: 0.3232 - accuracy: 0.8851 - val_loss: 0.3518 - val_accuracy: 0.8752\n",
            "Epoch 5/25\n",
            "55000/55000 [==============================] - 5s 94us/step - loss: 0.3067 - accuracy: 0.8903 - val_loss: 0.3403 - val_accuracy: 0.8814\n",
            "Epoch 6/25\n",
            "55000/55000 [==============================] - 5s 94us/step - loss: 0.2939 - accuracy: 0.8950 - val_loss: 0.3399 - val_accuracy: 0.8806\n",
            "Epoch 7/25\n",
            "55000/55000 [==============================] - 5s 93us/step - loss: 0.2825 - accuracy: 0.8988 - val_loss: 0.3325 - val_accuracy: 0.8830\n",
            "Epoch 8/25\n",
            "55000/55000 [==============================] - 5s 94us/step - loss: 0.2727 - accuracy: 0.9032 - val_loss: 0.3303 - val_accuracy: 0.8842\n",
            "Epoch 9/25\n",
            "55000/55000 [==============================] - 5s 93us/step - loss: 0.2646 - accuracy: 0.9053 - val_loss: 0.3308 - val_accuracy: 0.8822\n",
            "Epoch 10/25\n",
            "55000/55000 [==============================] - 5s 93us/step - loss: 0.2582 - accuracy: 0.9078 - val_loss: 0.3262 - val_accuracy: 0.8838\n",
            "Epoch 11/25\n",
            "55000/55000 [==============================] - 5s 93us/step - loss: 0.2521 - accuracy: 0.9107 - val_loss: 0.3270 - val_accuracy: 0.8840\n",
            "Epoch 12/25\n",
            "55000/55000 [==============================] - 5s 93us/step - loss: 0.2470 - accuracy: 0.9122 - val_loss: 0.3241 - val_accuracy: 0.8872\n",
            "Epoch 13/25\n",
            "55000/55000 [==============================] - 5s 93us/step - loss: 0.2421 - accuracy: 0.9138 - val_loss: 0.3227 - val_accuracy: 0.8864\n",
            "Epoch 14/25\n",
            "55000/55000 [==============================] - 5s 94us/step - loss: 0.2382 - accuracy: 0.9153 - val_loss: 0.3191 - val_accuracy: 0.8844\n",
            "Epoch 15/25\n",
            "55000/55000 [==============================] - 5s 94us/step - loss: 0.2347 - accuracy: 0.9178 - val_loss: 0.3198 - val_accuracy: 0.8852\n",
            "Epoch 16/25\n",
            "55000/55000 [==============================] - 5s 92us/step - loss: 0.2316 - accuracy: 0.9179 - val_loss: 0.3184 - val_accuracy: 0.8860\n",
            "Epoch 17/25\n",
            "55000/55000 [==============================] - 5s 93us/step - loss: 0.2288 - accuracy: 0.9202 - val_loss: 0.3232 - val_accuracy: 0.8868\n",
            "Epoch 18/25\n",
            "55000/55000 [==============================] - 5s 92us/step - loss: 0.2262 - accuracy: 0.9213 - val_loss: 0.3185 - val_accuracy: 0.8874\n",
            "Epoch 19/25\n",
            "55000/55000 [==============================] - 5s 93us/step - loss: 0.2239 - accuracy: 0.9213 - val_loss: 0.3179 - val_accuracy: 0.8868\n",
            "Epoch 20/25\n",
            "55000/55000 [==============================] - 5s 94us/step - loss: 0.2221 - accuracy: 0.9224 - val_loss: 0.3172 - val_accuracy: 0.8872\n",
            "Epoch 21/25\n",
            "55000/55000 [==============================] - 5s 99us/step - loss: 0.2202 - accuracy: 0.9226 - val_loss: 0.3189 - val_accuracy: 0.8858\n",
            "Epoch 22/25\n",
            "55000/55000 [==============================] - 6s 103us/step - loss: 0.2186 - accuracy: 0.9231 - val_loss: 0.3177 - val_accuracy: 0.8862\n",
            "Epoch 23/25\n",
            "55000/55000 [==============================] - 5s 96us/step - loss: 0.2174 - accuracy: 0.9248 - val_loss: 0.3165 - val_accuracy: 0.8884\n",
            "Epoch 24/25\n",
            "55000/55000 [==============================] - 5s 94us/step - loss: 0.2162 - accuracy: 0.9251 - val_loss: 0.3172 - val_accuracy: 0.8880\n",
            "Epoch 25/25\n",
            "55000/55000 [==============================] - 5s 92us/step - loss: 0.2151 - accuracy: 0.9254 - val_loss: 0.3156 - val_accuracy: 0.8888\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYv3emPHrwRr",
        "colab_type": "text"
      },
      "source": [
        "For piecewise constant scheduling, try this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfGUvVRBrYSr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = tf.keras.optimizers.schedules.PiecewiseConstantDecay(\n",
        "    boundaries=[5. * n_steps_per_epoch, 15. * n_steps_per_epoch],\n",
        "    values=[0.01, 0.005, 0.001])"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iz8E6Pa9wJFp",
        "colab_type": "text"
      },
      "source": [
        "This is nice and simple, plus when you save the model, the learning rate and its schedule (including its state) get saved as well. However, this approach is not part of the Keras API, it is specific to tf.keras.\n",
        "\n",
        "\n",
        "To sum up, exponential decay or performance scheduling can considerably speed up convergence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzRkdLPJyPYb",
        "colab_type": "text"
      },
      "source": [
        "# Resources"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igySK6jtyRks",
        "colab_type": "text"
      },
      "source": [
        "- https://github.com/ageron/handson-ml2\n",
        "\n",
        "\n",
        "- https://ruder.io/optimizing-gradient-descent/index.html#visualizationofalgorithms\n",
        "\n",
        "\n",
        "\n",
        "- https://stackoverflow.com/questions/36162180/gradient-descent-vs-adagrad-vs-momentum-in-tensorflow"
      ]
    }
  ]
}