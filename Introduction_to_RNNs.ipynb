{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Introduction to RNNs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMoDZfsjYjt86nOqxDecdrm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victorviro/Deep_learning_python/blob/master/Introduction_to_RNNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8J3vS0xGBPW",
        "colab_type": "text"
      },
      "source": [
        "# Recurrent neural networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVstB5jNGBSe",
        "colab_type": "text"
      },
      "source": [
        "In this notebook, we will look at the fundamental concepts underlying Recurrent Neural Networks (RNN).\n",
        "\n",
        "Up to now, we have studied feedforward neural networks, where the activations flow only in one direction, from the input layer to the output layer. Despite their power, these neural networks have limitations.\n",
        "Most notably, they rely on the assumption of independence among the training examples (and test examples). After each example (data point) is processed, the entire state of the network is lost. If each example is generated independently, this presents no problem. But if data points are related in time or space, this is unacceptable. Frames from video, snippets of audio, and words pulled from sentences, represent data where the independence assumption fails. Additionally, standard networks generally rely on examples being vectors of fixed length. Thus\n",
        "it is desirable to extend these powerful learning tools to model data with temporal or sequential structure and varying length inputs and outputs.\n",
        "\n",
        "\n",
        "What differentiates Recurrent Neural Networks from Feedforward Neural Networks (also known as Multi-Layer Perceptrons, MLPs) is how information gets passed through the network. While Feedforward Networks pass information through the network without cycles, the RNN has cycles and\n",
        "transmits information back into itself. This enables them to extend the functionality of Feedforward Networks to also take into account previous inputs and not only the current input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Y7YkiRuyXuU7"
      },
      "source": [
        "## Input and Output Sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "I9OklUj1XuVD"
      },
      "source": [
        "Standard feed-forward neural network propagate the data in one direction, from input to output. This type of network cannot handle sequential data.\n",
        "\n",
        "![](https://i.ibb.co/fNkfK3g/vanila-neural-networks.png)\n",
        "\n",
        "Recurrent neural networks are particularly well-suited for handling cases where we have a sequence of inputs rather than a single input.\n",
        "\n",
        "- An RNN can simultaneously take a sequence of inputs and produce a sequence of outputs (see Figure 4-4, top-left network). For example, this type of network called *sequence-to-sequence network* or also known as *many to one* model is useful for predicting time series such as stock prices: we feed it the prices over the last $N$ days, and it must output the prices shifted by one day into the future (i.e., from $N-1$ days ago to tomorrow).\n",
        "\n",
        "- Alternatively, we could feed the network a sequence of inputs, and ignore all outputs except for the last one (see the top-right network). In other words, this is a *sequence-to-vector network* or also called *many to one* model. For example, we could feed the network an input of variable size like a sequence of words corresponding to a movie review, and the network would output a sentiment score (e.g., from -1 (hate) to +1 (love)). Another example could be input a video which have a variable number of frames and output what kind of activity or action is going on in that video.\n",
        "\n",
        "- Conversely, we could feed the network a single input at the first time step (and zeros for all other time steps), and let it output a sequence (see the bottom-left network). This is a *vector-to-sequence network* or also called *one to many* model. For example, the input could be some object of fixed length like an image, and the output could be a sequence of variable length such as a caption for that image (image captioning), where different captions might have different number of words (the output needs to be variable in length).\n",
        "\n",
        "- Lastly, we could have a sequence-to-vector network, called an *encoder*, followed by a vector-to-sequence network, called a *decoder* (see the bottom-right network). For example, this can be used for translating a sentence from one language to another. We would feed the network a sentence in one language (English) which could have a variable length, the encoder would convert this sentence into a single vector representation, and then the decoder would decode this vector into a sentence in another language (french), which also could have a variable length. Note that the length of the English sentence might be different from the french sentence. This two-step model, called an *Encoder–Decoder*, works much better than trying to translate on the fly with a single sequence-to-sequence RNN (like the one represented on the top left), since the last words of a sentence can affect the first words of the translation, so we need to wait until we have heard the whole sentence before translating it.\n",
        "\n",
        "![texto alternativo](https://i.ibb.co/b5NpXXV/inputs-outputs-rnn.png)\n",
        "\n",
        "Recurrent neural networks can handle variable size sequence data that allow us to capture all of these different types of setups in our models. Furthermore, they can also be useful for some problems that have a fixed size input and a fixed size output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9_X_CrLGBaz",
        "colab_type": "text"
      },
      "source": [
        "## Recurrent neurons"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kj6TKuv9GBdk",
        "colab_type": "text"
      },
      "source": [
        " A recurrent neural network looks like a feedforward neural network, except it also has connections pointing backward. Let’s look at the simplest possible RNN, composed of just one neuron receiving inputs, producing an output, and sending that output back to itself, as shown in Figure 4-1 (left). At each time step $t$ (also called a *frame*), this recurrent neuron receives the inputs $x_{(t)}$ as well as its own output from the previous time step, $y_{(t-1)}$. Since there is no previous output at the first time step, it is generally set to 0. We can represent this tiny network against the time axis, as shown in Figure 4-1 (right). This is called unrolling or unfolding the network through time (it’s the same recurrent neuron represented once per time step).\n",
        "\n",
        "![texto alternativo](https://i.ibb.co/g7ByFbG/recurrent-neuron.png)\n",
        "\n",
        "\n",
        "We can easily create a layer of recurrent neurons. At each time step $t$, every neuron receives both the input vector $\\boldsymbol{x}_{(t)}$ and the output vector from the previous time step $\\boldsymbol{y}_{(t-1)}$, as shown in Figure 4-2. Note that both the inputs and outputs are vectors now (when there was just a single neuron, the output was a scalar).\n",
        "\n",
        "![texto alternativo](https://i.ibb.co/BNC0jRK/recurrent-layer.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhx3o-YHGBgU",
        "colab_type": "text"
      },
      "source": [
        "### Memory cells\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hb_zbYjfbXea",
        "colab_type": "text"
      },
      "source": [
        "Since the output of a recurrent neuron at time step $t$ is a function of all the inputs from previous time steps, we could say it has a form of *memory*. A part of a neural network that preserves some state across time steps is called a *memory cell* (or simply a *cell*). A single recurrent neuron, or a layer of recurrent neurons, is a very basic cell, capable of learning only short patterns (typically about 10 steps long, but this varies depending on the task). Later, we will look at some more complex and powerful types of cells capable of learning longer patterns (roughly 10 times longer, but again, this depends on the task).\n",
        "\n",
        "In general a cell’s state at time step $t$, denoted $\\boldsymbol{h}_{(t)}$\n",
        " (the “h” stands for “hidden”), is a function parametrized by $\\boldsymbol{W}$ of some inputs at that time step, $\\boldsymbol{x}_{(t)}$, \n",
        "and its state at the previous time step, $\\boldsymbol{h}_{(t-1)}$. This is,  $\\boldsymbol{h}_{(t)}=f_{\\boldsymbol{W}}(\\boldsymbol{h}_{(t-1)},\\boldsymbol{x}_{(t)})$. Its output at time step $t$, denoted $\\boldsymbol{y}_{(t)}$, is also a function of the previous state and the current inputs. In the case of the basic cells we have discussed so far, the output is simply equal to the state, but in more complex cells this is not always the case, as shown in Figure 4-3.\n",
        "\n",
        "**Note**: The same function and the same set of parameters are used at every time step.\n",
        "\n",
        "![texto alternativo](https://i.ibb.co/WgpyWBm/hidden-cells.png)\n",
        "\n",
        "The network passes the information about its hidden state from one time step of the network to the next. We call this networks with loops in them recurrent because the information is being passed from one-time step to the next internally within the network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jt0NGeF_Gr0t",
        "colab_type": "text"
      },
      "source": [
        "Let's consider the standard recurrent neural network with one hidden layer shown in the previous figure.\n",
        "\n",
        "Each recurrent neuron has two sets of weights: one for the inputs $\\boldsymbol{x}_{(t)}$\n",
        " and the other for the hidden state of the previous time step, $\\boldsymbol{h}_{(t-1)}$.\n",
        "Let’s call these weight vectors $\\boldsymbol{w}_{xh}$ and $\\boldsymbol{w}_{hh}$. If we consider the whole recurrent layer instead of just one recurrent neuron, we can place all the weight vectors in two weight matrices, $\\boldsymbol{W}_{xh}$ and $\\boldsymbol{W}_{hh}$. The hidden stage vector of the whole recurrent layer at time step $t$ is updated as shown in the next equation.\n",
        "\n",
        "$$\\boldsymbol{h}_{(t)} = \\phi_{h}(\\boldsymbol{W}_{xh}^T\\boldsymbol{x}_{(t)}+\\boldsymbol{W}_{hh}^T\\boldsymbol{h}_{(t-1)}+\\boldsymbol{b}_{h})$$\n",
        "\n",
        "where $\\boldsymbol{b}_{h}$\n",
        "is the bias parameter vector and $ \\phi_{h}()$ is the activation function used in the hidden layer.\n",
        "\n",
        "Just like for feedforward neural networks, we can compute a recurrent layer’s hidden state in one shot for a whole mini-batch by placing all the inputs at time step $t$ in an input matrix $\\boldsymbol{X}_{(t)}$\n",
        " and the hidden states at the previous time step in a hidden-state-to-hidden-state matrix $\\boldsymbol{H}_{(t-1)}$.\n",
        "\n",
        "$$\\boldsymbol{H}_{(t)} = \\phi_{h}(\\boldsymbol{X}_{(t)}\\boldsymbol{W}_{xh}+\\boldsymbol{H}_{(t-1)}\\boldsymbol{W}_{hh}+\\boldsymbol{b}_h)\n",
        "$$\n",
        "\n",
        "- $\\boldsymbol{H}_{(t)}$ is an $m$ × $n$ matrix containing the layer’s hidden states at time step $t$ for each instance in the mini-batch ($m$ is the number of instances in the mini-batch and $n$ is the number of neurons or hidden units).\n",
        "\n",
        "- $\\boldsymbol{X}_{(t)}$  is an $m$ × $p$ matrix containing the inputs for all instances ($p$ is the number of input features).\n",
        "\n",
        "- $\\boldsymbol{W}_{xh} $ is an $p$ × $n$ matrix containing the connection weights for the inputs of the current time step.\n",
        "\n",
        "- $\\boldsymbol{W}_{hh} $ is an $n$ × $n$ matrix containing the connection weights for the hidden states of the current time step.\n",
        "\n",
        "- $\\boldsymbol{b}_h$ is a vector of size $n$ containing each neuron’s bias term.\n",
        "\n",
        "\n",
        "Notice that $\\boldsymbol{H}_{(t)}$ \n",
        "is a function of $\\boldsymbol{X}_{(t)}$ and \n",
        "$\\boldsymbol{H}_{(t-1)}$,\n",
        "which is a function of $\\boldsymbol{X}_{(t-1)}$ and \n",
        "$\\boldsymbol{H}_{(t-2)}$, which is a function of \n",
        "$\\boldsymbol{X}_{(t-2)}$ and \n",
        "$\\boldsymbol{H}_{(t-3)}$, and so on. This makes \n",
        "$\\boldsymbol{H}_{(t)}$ a function of all the inputs since time \n",
        "$t = 0$ (that is, $\\boldsymbol{X}_{(0)},\\boldsymbol{X}_{(1)},...,\\boldsymbol{X}_{(t)}$). \n",
        "The RNN includes traces of all hidden states that preceded $\\boldsymbol{H}_{(t-1)}$ as well as $\\boldsymbol{H}_{(t-1)}$ itself. At the first time step, $t = 0$, there are no previous hidden states, so they are typically assumed to be all zeros.\n",
        "\n",
        "**Note**: The same function and the same set of parameters are used at every time step.\n",
        "\n",
        "Additionally, if we require an output $\\boldsymbol{y}_{(t)}$\n",
        " at the end of each time step we can pass the hidden state and just multiply it by another weight matrix which contains the connection weights for the outputs of the current time step, denoted by $\\boldsymbol{W}_{hy}$, and possibly apply an activation function $ \\phi_{o}()$ to obtain the desired shape of the result.\n",
        "\n",
        "\n",
        "$$\\boldsymbol{y}_{(t)} = \\phi_{o}(\\boldsymbol{W}_{hy}\\boldsymbol{h}_{(t)}+\\boldsymbol{b}_o)$$\n",
        "\n",
        "or for a whole mini-batch\n",
        "\n",
        "$$\\boldsymbol{Y}_{(t)} = \\phi_{o}(\\boldsymbol{H}_{(t)}\\boldsymbol{W}_{hy}+\\boldsymbol{b}_o)$$\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ja1gU1nHXkD7",
        "colab_type": "text"
      },
      "source": [
        "If we compare that notation for RNNs with similar notation for Feedforward Neural Networks we can clearly see the difference we described earlier. In the next equations, we can see the computation for the hidden variable and the output variable in a feed-forward neural network.\n",
        "\n",
        "\n",
        "\\begin{cases}\n",
        "\\boldsymbol{H} = \\phi_{h}(\\boldsymbol{X}\\boldsymbol{W}_{xh}+\\boldsymbol{b}_h)\\\\\\\\\n",
        "\\boldsymbol{Y} = \\phi_{o}(\\boldsymbol{H}\\boldsymbol{W}_{hy}+\\boldsymbol{b}_o)\n",
        "\\end{cases}\n",
        "\n",
        "\n",
        "![](https://i.ibb.co/wYdtkZW/FFNN-vs-RNN.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgZTq5NGGBmM",
        "colab_type": "text"
      },
      "source": [
        "### Basic RNNs in TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXoD6FEccNzP",
        "colab_type": "text"
      },
      "source": [
        "Let’s implement a very simple RNN model, without using any of Keras RNN operations or layers, to better understand what goes on under the hood. We will create an RNN composed of a layer of five recurrent neurons (like the RNN represented in Figure 4-2), using the tanh activation function. We will assume that the RNN runs over only two-time steps, taking input vectors of size 3 at each time step. The following code builds this RNN, unrolled through two-time steps:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqTHHGwfKSmv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "1bab741a-38f1-4fae-fc2f-ad5692389477"
      },
      "source": [
        "# %tensorflow_version only exists in Colab.\n",
        "#%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "number_inputs, hidden_units = 3, 5\n",
        "# Intizialize the weight matrices with random values from a normal distribution\n",
        "W_xh = tf.Variable(tf.random.normal(shape=[number_inputs, hidden_units], dtype=tf.float32))\n",
        "W_hh = tf.Variable(tf.random.normal(shape=[hidden_units,hidden_units], dtype=tf.float32))\n",
        "b = tf.Variable(tf.zeros([1, hidden_units], dtype=tf.float32))\n",
        "\n",
        "# Each mini-batch contains four instances, each with an input sequence composed of exactly three inputs.\n",
        "X0_batch = tf.constant([[2,0,1], [3,4,5], [6,7,8], [3,4,6]], dtype=tf.float32) # t = 0\n",
        "X1_batch = tf.constant([[5,6,9], [0,0,0], [3,4,6], [2,0,1]], dtype=tf.float32) # t = 1\n",
        "\n",
        "# The outputs of the network at both time steps for all neurons and all instances in the mini-batch:\n",
        "H_0 = tf.tanh(tf.matmul(X0_batch,W_xh) + b)\n",
        "H_1 = tf.tanh(tf.matmul(H_0,W_hh) + tf.matmul(X1_batch,W_xh) + b)\n",
        "print(H_0)\n",
        "print(H_1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[-0.21947616  0.546716   -0.38057125 -0.99852973 -0.9998861 ]\n",
            " [ 0.99323684 -0.9655363  -0.92103803 -0.9998911  -1.        ]\n",
            " [ 0.99919486 -0.99443185 -0.6669558  -1.         -1.        ]\n",
            " [ 0.9988184  -0.9819186  -0.99816346 -0.9999261  -1.        ]], shape=(4, 5), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.9999997  -0.9992626  -1.         -0.9999962  -1.        ]\n",
            " [-0.5321363   0.6728677  -0.99823815  0.8079903  -0.7237798 ]\n",
            " [ 0.9956927  -0.94421226 -0.9999926  -0.9993712  -1.        ]\n",
            " [-0.6828183   0.90710294 -0.9994755  -0.9858882  -0.99998224]], shape=(4, 5), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvwMNTiMc6JL",
        "colab_type": "text"
      },
      "source": [
        "This network looks much like a two-layer feedforward neural network, with a few twists: first, the same weights and bias terms are shared by both layers, and second, we feed inputs at each layer, and we get outputs from each layer.\n",
        "\n",
        "Of course, if we want to be able to run an RNN over 100 time steps, the graph is going to be pretty big. Now let’s look at how to create the same model using Keras RNN layers.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urEHRLIy5buN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "7e5afcc5-65cf-49e5-f198-05daffafd088"
      },
      "source": [
        "import tensorflow.keras as keras\n",
        "\n",
        "X_batch = np.array([[[2,0,1], [3,4,5], [6,7,8], [3,4,6]],\n",
        "                    [[5,6,9], [0,0,0], [3,4,6], [2,0,1]]]).astype(np.float32)\n",
        "\n",
        "simple_rnn = keras.layers.SimpleRNN(number_neurons, return_sequences=True)\n",
        "\n",
        "whole_sequence_output = simple_rnn(X_batch)\n",
        "H_O,H_1 = whole_sequence_output\n",
        "print(H_O)\n",
        "print(H_1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[-0.8183296  -0.30870414  0.21450713  0.6722447   0.1228546 ]\n",
            "  [-0.9999569   0.944683    0.99453515  0.99952203  0.99321294]\n",
            "  [-1.          0.99924815  0.9999043   0.9999984   0.9999831 ]\n",
            "  [-0.99999845  0.9842991   0.98354846  0.999255    0.9990642 ]]\n",
            "\n",
            " [[-1.          0.9976738   0.9999288   1.          0.99994206]\n",
            "  [-0.86338943  0.1102461  -0.7549897  -0.90183294  0.32073975]\n",
            "  [-0.9999594   0.99558353  0.9996615   0.9998455   0.9956671 ]\n",
            "  [-0.9853368  -0.20650566 -0.645611   -0.58214396  0.42599127]]], shape=(2, 4, 5), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSxaMq43Y9Kk",
        "colab_type": "text"
      },
      "source": [
        "The `simple_rnn` function returns two objects. The first is a Python list containing the output tensors for each time step. The second is a tensor containing the final states of the network. When we are using basic cells, the final state is simply equal to the last output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoQAyJBOv6T3",
        "colab_type": "text"
      },
      "source": [
        "## Training RNNs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzjdUwTvWV3H",
        "colab_type": "text"
      },
      "source": [
        "Regular feedforward neural networks are trained using the backpropagation algorithm to update the weights in order to minimize the error between the expected output and the predicted output for a given input. In this, a certain input is first propagated through the network to compute the output. This is called the forward pass. The output is then compared to a ground truth label using a differentiable loss function. In the backward pass the gradients of the loss with respect to all the parameters (weights) in the network are computed by application of the chain rule (see notebook [Introduction to neural networks](https://github.com/victorviro/Deep_learning_python/blob/master/Introduction_artificial_neural_networks.ipynb)). Finally, all parameters are updated using a gradient-based optimization procedure such as gradient descent. See notebook [Gradient Descent](https://github.com/victorviro/ML_algorithms_python/blob/master/Introduction_gradient_descent_algorithm.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvAA0rnTWZSg",
        "colab_type": "text"
      },
      "source": [
        "### Backpropagation through time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2n1p8mFv-mu",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "As we saw, in recurrent neural networks a new input is applied for every time step, and the output at a certain time step is dependent on all previous inputs. This means that the loss at time step $N$ needs to be backpropagated up until the applied inputs at time step 1. To train these networks, the trick is to unroll it through time (like we just did) and then simply use regular backpropagation (see Figure 15-5). This strategy is called *backpropagation through time* (BPTT).\n",
        "\n",
        "Just like in regular backpropagation, there is a first forward pass through the unrolled network (represented by the dashed arrows). Then the output sequence is evaluated using a cost function $C(\\boldsymbol{Y}_{(0)}, \\boldsymbol{Y}_{(1)},...,\\boldsymbol{Y}_{(T)})$\n",
        " (where $T$ is the max time step). This basically sums up every loss term of each update step so far. This loss term can have different definitions based on the specific problem (e.g. Mean Squared Error, Hinge Loss, Cross-Entropy Loss, etc.). Note that this cost function may ignore some outputs, as shown in Figure 15-5 (for example, in a sequence-to-vector RNN, all outputs are ignored except for the very last one). The gradients of that cost function are then propagated backward through the unrolled network (represented by the solid arrows) (hence the name backpropagation through time). Finally, the model parameters are updated using the gradients computed during BPTT. Note that the gradients flow backward through all the outputs used by the cost function, not just through the final output (for example, in Figure 15-5 the cost function is computed using the last three outputs of the network, $\\boldsymbol{Y}_{(2)}, \\boldsymbol{Y}_{(3)}$\n",
        "and $\\boldsymbol{Y}_{(4)}$,\n",
        "so gradients flow through these three outputs, but not through \n",
        "$\\boldsymbol{Y}_{(0)}$ and $\\boldsymbol{Y}_{(1)}$). Moreover, since the same parameters $\\boldsymbol{W}$ and $\\boldsymbol{b}$ are used at each time step, backpropagation will do the right thing and sum over all time steps.\n",
        "\n",
        "![texto alternativo](https://i.ibb.co/kKM7VpZ/BPTT.png)\n",
        "\n",
        "The next figure shows the fact that the same weight matrices are shared across times teps.\n",
        "\n",
        "![](https://i.ibb.co/gwJmKqb/BPTT-2.png)\n",
        "\n",
        "Fortunately, `tf.keras` takes care of all of this complexity for us."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hdf4t2VwWdNo",
        "colab_type": "text"
      },
      "source": [
        "### Truncated backpropagation through time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDEXmJXpA4FS",
        "colab_type": "text"
      },
      "source": [
        "Backpropagation through time can be sometimes inefficient. Imagine we want to train a language model, which tries to predict the next word in a sentence, and we use very long sequences to train the model. In this case, BPTT requires processing the full sequence both forward and backward. This requires maintaining the full unfolded network, or equivalently storing the full history of inputs and activations. This is impractical when very long sequences are processed with large networks: processing the whole sequence at every gradient step slows down learning.  In addition to speed, the accumulation of gradients over so many times teps can result in a shrinking of values to zero, or a growth of values that eventually overflow, or explode.\n",
        "\n",
        "Practically, this is alleviated by limiting gradient flows after a fixed\n",
        "number of times teps, or equivalently, splitting the input sequence into subsequences of fixed length, and only backpropagating through those subsequences. This algorithm is referred to as *truncated backpropagation through time* (TBPTT).\n",
        "\n",
        "The TBPTT training algorithm has two parameters:\n",
        "\n",
        "- $k_1$: Defines the number of times teps shown to the network on the forward pass.\n",
        "- $k_2$: Defines the number of times teps to look at when estimating the gradient on the backward pass.\n",
        "\n",
        "As such, we can use the notation $\\text{TBPTT}(k_1, k_2)$ when considering how to configure the training algorithm. For $k_1 = k_2 = T$, where $T$ is the length of the original input sequence, it is the classical non-truncated BPTT. Note that, in order to remain as data efficient as possible, $k_1$ should preferably be less than or equal to $k_2$, since otherwise some data points would be skipped during training.\n",
        "\n",
        "\n",
        "Modern recurrent neural networks (like LSTMs, which we will see in the next notebook) can use their internal state to remember over very long input sequences (over thousands of timesteps). This means that the configuration of TBPTT does not necessarily define the memory of the network that we are optimizing with the choice of the number of time steps. We can choose when the internal state of the network is reset separately from the regime used to update network weights.\n",
        "\n",
        "Instead, the choice of TBPTT parameters influences how the network estimates the error gradient used to update the weights. More generally, the configuration defines the number of timesteps from which the network may be considered to model your sequence problem. In other words, the TBPTT defines the scope of the input sequence for the model during training.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ql4UBxKjWK-d",
        "colab_type": "text"
      },
      "source": [
        "#### Keras Implementation of TBPTT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqHJrldfWBaQ",
        "colab_type": "text"
      },
      "source": [
        "Keras provides an implementation of TBPTT for training recurrent neural networks. The implementation is more restricted than the general version. \n",
        "\n",
        "Specifically, the $k_1$ and $k_2$ values are equal to each other and fixed. This means that when we train the model, we will step forward for some number of steps (like 100), compute the loss only over this subsequence of the data, backpropagate through this subsequence and then make a gradient step. This scheme is repeated for each mini-batch of data during the training process.\n",
        "\n",
        "In Keras, this is realized by the fixed-sized three-dimensional input required to train recurrent neural networks. The RNN expects input data to have the dimensions: [*samples, timesteps, features*]. It is the second dimension of this input format, that defines the number of timesteps used for forward and backward passes on our sequence prediction problem.\n",
        "\n",
        "Therefore, when preparing our input data for sequence prediction problems in Keras, the choice of timesteps will influence both the internal state accumulated during the forward pass and the gradient estimate used to update weights on the backward pass. We will see how we can prepare the date later.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tz_JwfZUlmqe"
      },
      "source": [
        "### Stateless and stateful modes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpJ4Uk7YsdSD",
        "colab_type": "text"
      },
      "source": [
        "In the implementation of RNNs in Keras, by default, the internal state of the network is reset after each batch (usually all zeros). This is known as a *stateless model*. This means that, at each batch, the model starts with a hidden state full of zeros, then it updates this state at each time step, and after the last time step, it throws it away, as it is not needed anymore. In a *stateful mode*, the model preserves this final state after processing one training batch and use it as the initial state for the next training batch. This mode allows us to have more explicit control over when the internal state is reset by calling the reset operation manually. This way the model can learn long-term patterns despite only backpropagating through short sequences.\n",
        "\n",
        "Note that a stateful RNN only makes sense if each input sequence in a batch starts exactly where the corresponding sequence in the previous batch left off. So batching is usually much harder when preparing a dataset for a stateful RNN than it is for a stateless RNN. Moreover, we must obviously not shuffle the sequences.\n",
        "\n",
        "Most of the problems can be solved with stateless model so we go for the stateful mode when we really need it. Suppose we have a big sequence (e.g. all text of Wikipedia) and we split it into smaller subsequences to construct our dataset. Then, the model may find dependencies between the subsequences only if we go for the stateful model. In the next notebooks, we will prepare a dataset to train a language model where we will use the stateful mode.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNA_EcJacGts",
        "colab_type": "text"
      },
      "source": [
        "### Prepare Sequence Data for BPTT or TBPTT in Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwz1EQNhcKrz",
        "colab_type": "text"
      },
      "source": [
        "The way that we break up our sequence data will define the number of time steps used in the forward and backward passes of BPTT. As such, we must put careful thought into how we will prepare our training data.\n",
        "\n",
        "This section lists some techniques we may consider.\n",
        "\n",
        "- **Use data as-is**: We may use our input sequences as-is if the number of timesteps in each sequence is modest, such as tens or a few hundred timesteps (practical limits have been suggested for TBPTT of about 200-to-400 timesteps). If our sequence data is less than or equal to this range, we may reshape the sequence observations as timesteps for the input data and use classical BPTT. For example, if we had a collection of 100 univariate sequences of 25 timesteps, this could be reshaped as 100 samples, 25 timesteps, and 1 feature or [100, 25, 1].\n",
        "\n",
        "- **Naive Data Split**: If we have long input sequences, such as thousands of timesteps, we may need to break the long input sequences into multiple contiguous subsequences. This will require the use of a stateful model in Keras so that the internal state is preserved across the input of the sub-sequences and only reset at the end of a true fuller input sequence. A split that divides the full sequence into fixed-sized subsequences is preferred. The choice of the subsequence length is arbitrary, hence the name “naive data split”.\n",
        "For example, if we had 100 input sequences of 50000 timesteps, then each input sequence could be divided into 100 subsequences of 500 timesteps. One input sequence would become 100 samples, therefore the 100 original samples would become 10,000. The dimensionality of the input for Keras would be 10,000 samples, 500 timesteps, and 1 feature or [10000, 500, 1]. If we use a stateful model, Care would be needed to preserve state across every 100 subsequences and reset the internal state after every 100 samples either explicitly or by using a batch size of 100.\n",
        "\n",
        "- **Domain-Specific Data Split**: It can be hard to know the correct number of timesteps required to provide a useful estimate of the error gradient. We can use the naive approach (above) to get a model quickly, but the model may be far from optimized. Alternatively, we can use domain-specific information to estimate the number of timesteps that will be relevant to the model while learning the problem. For example, if the sequence problem is a regression time series, perhaps a review of the autocorrelation and partial autocorrelation plots can inform the choice of the number of the timesteps. If the sequence problem is a natural language processing problem, perhaps the input sequence can be divided by sentence and then padded to a fixed length or split according to the average sentence length in the domain. The key idea is to consider knowledge specific to our domain that we can use to split up the sequence into meaningful chunks.\n",
        "\n",
        "- **Systematic Data Split (grid search)**: Rather than guessing at an efficient number of timesteps, we can systematically evaluate different subsequence lengths for our sequence prediction problem. We could perform a grid search over each sub-sequence length and adopt the configuration that results in the best performing model on average. There are some considerations for this approach. We can start with subsequence lengths that are a factor of the full sequence length or use padding and perhaps masking if exploring subsequence lengths that are not a factor of the full sequence length We may ake the average performance over multiple runs (e.g. 30) of each different configuration. If computation resources are not a limitation, then a systematic investigation of different numbers of timesteps is recommended.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8tN2zQwoDoF",
        "colab_type": "text"
      },
      "source": [
        "# References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGABhhcyoFDN",
        "colab_type": "text"
      },
      "source": [
        "- [A Critical Review of Recurrent Neural Networks for Sequence Learning](https://arxiv.org/abs/1506.00019)\n",
        "\n",
        "- [Recurrent Neural Networks (RNNs): A gentle Introduction and Overview](https://arxiv.org/abs/1912.05911)\n",
        "\n",
        "\n",
        "\n",
        "- [Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/)\n",
        "\n",
        "- [Handson-ml2 Github](https://github.com/ageron/handson-ml2)\n",
        "\n",
        "- [RNNs Stanford lecture](https://www.youtube.com/watch?v=6niqTuYFZLQ)\n",
        "\n",
        "- [RNNs MIT lecture](https://www.youtube.com/watch?v=SEnXr6v2ifU)\n",
        "\n",
        "- [Unbiasing Truncated Backpropagation Through Time](https://arxiv.org/abs/1705.08209)\n",
        "\n",
        "- [Stateful and Stateless LSTM for Time Series Forecasting with Python](https://machinelearningmastery.com/stateful-stateless-lstm-time-series-forecasting-python/)\n",
        "\n",
        "- [Understanding Stateful LSTM Recurrent Neural Networks in Python with Keras](https://machinelearningmastery.com/understanding-stateful-lstm-recurrent-neural-networks-python-keras/)\n",
        "\n",
        "- [Stateful LSTM in Keras](http://philipperemy.github.io/keras-stateful-lstm/)\n",
        "\n",
        "- [How to Prepare Sequence Prediction for Truncated BPTT in Keras](https://machinelearningmastery.com/truncated-backpropagation-through-time-in-keras/)\n",
        "\n",
        "\n"
      ]
    }
  ]
}