{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras_Functional_API.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNaZylqZxgcrOZSl6j3pvAw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victorviro/Deep_learning_python/blob/master/Keras_Functional_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfOdjZLQ0ZyV",
        "colab_type": "text"
      },
      "source": [
        "## The Functional API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrATliKU0GuC",
        "colab_type": "text"
      },
      "source": [
        "[Here](https://github.com/victorviro/Deep_learning_python/blob/master/Introduction_artificial_neural_networks_keras.ipynb) we used the Sequential API of Keras to build a MLP classifier. Although sequential models are extremely common, it is sometimes useful to build neural networks with more complex topologies, or with multiple inputs or outputs. For this purpose, Keras offers the Functional API.\n",
        "\n",
        "\n",
        "One example of a non-sequential neural network is a *Wide & Deep* neural network. This neural network architecture was introduced in a [paper](https://arxiv.org/abs/1606.07792) by Heng-Tze Cheng in 2016. It connects all or part of the inputs directly to the output layer, as shown in\n",
        "Figure 10-13.\n",
        "\n",
        "![texto alternativo](https://i.ibb.co/pPrpHsz/WDNN.png)\n",
        "\n",
        "This architecture makes it possible for the neural network to learn both\n",
        "deep patterns (using the deep path) and simple rules (through the short path). In contrast, a regular MLP forces all the data to flow through the full stack of layers, thus simple patterns in the data may end up being distorted by this sequence of transformations.\n",
        "\n",
        "Let’s build such a neural network to tackle the [California housing problem](https://scikit-learn.org/stable/datasets/index.html#california-housing-dataset):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_29A8Ul07HZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's load, split and scale the California housing dataset\n",
        "\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_valid = scaler.transform(X_valid)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FctP6czm1RF-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ef7a50f5-d5a4-47c0-c040-92e86c6304e2"
      },
      "source": [
        "# build the neural network\n",
        "import keras\n",
        "\n",
        "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
        "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
        "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
        "concat = keras.layers.concatenate([input_, hidden2])\n",
        "output = keras.layers.Dense(1)(concat)\n",
        "model = keras.models.Model(inputs=[input_], outputs=[output])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaLbqnu71ZoI",
        "colab_type": "text"
      },
      "source": [
        "Let’s go through each line of this code:\n",
        "\n",
        "\n",
        "- First, we need to create an `Input` object. This is needed because we may have\n",
        "multiple inputs, as we will see later.\n",
        "\n",
        "- Next, we create a `Dense` layer with 30 neurons and using the ReLU activation\n",
        "function. As soon as it is created, notice that we call it like a function, passing it the input. This is why this is called the Functional API. Note that we are just telling Keras how it should connect the layers together, no actual data is being processed yet.\n",
        "\n",
        "- We then create a second hidden layer, and again we use it as a function. Note\n",
        "however that we pass it the output of the first hidden layer.\n",
        "\n",
        "- Next, we create a `Concatenate()` layer, and once again we immediately use it like a function, to concatenate the input and the output of the second hidden layer.\n",
        "\n",
        "- Then we create the output layer, with a single neuron and no activation function, and we call it like a function, passing it the result of the concatenation.\n",
        "\n",
        "- Lastly, we create a Keras `Model`, specifying which inputs and outputs to use. Remember that in the Sequential API you instantiate the model object when calling `model = Sequential()` (and then add layers and constraints). In the Functional API, you create layers and then instantiate your model by calling `model = Model()` with your desired input and output layer(s) as we did.\n",
        "\n",
        "\n",
        "\n",
        "We compile the model, train it, evaluate it and use it to make predictions.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5ToCEUb1pqc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "1c06cf2c-89f8-4461-b910-0d3ca5f511c4"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 8)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 30)           270         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 30)           930         dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 38)           0           input_1[0][0]                    \n",
            "                                                                 dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 1)            39          concatenate_1[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 1,239\n",
            "Trainable params: 1,239\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xa6T_ew11sYd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "73258840-5fbc-4ad4-eb3b-3eac09bd0162"
      },
      "source": [
        "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
        "history = model.fit(X_train, y_train, epochs=20,\n",
        "                    validation_data=(X_valid, y_valid))\n",
        "mse_test = model.evaluate(X_test, y_test)\n",
        "X_new = X_test[:3]\n",
        "y_pred = model.predict(X_new)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 11610 samples, validate on 3870 samples\n",
            "Epoch 1/20\n",
            "11610/11610 [==============================] - 0s 42us/step - loss: 2.5161 - val_loss: 9.1327\n",
            "Epoch 2/20\n",
            "11610/11610 [==============================] - 0s 36us/step - loss: 0.6542 - val_loss: 0.5336\n",
            "Epoch 3/20\n",
            "11610/11610 [==============================] - 0s 37us/step - loss: 0.5448 - val_loss: 0.4899\n",
            "Epoch 4/20\n",
            "11610/11610 [==============================] - 0s 36us/step - loss: 0.5159 - val_loss: 0.4697\n",
            "Epoch 5/20\n",
            "11610/11610 [==============================] - 0s 36us/step - loss: 0.4935 - val_loss: 0.4632\n",
            "Epoch 6/20\n",
            "11610/11610 [==============================] - 0s 35us/step - loss: 0.4742 - val_loss: 0.4514\n",
            "Epoch 7/20\n",
            "11610/11610 [==============================] - 0s 34us/step - loss: 0.4614 - val_loss: 0.4416\n",
            "Epoch 8/20\n",
            "11610/11610 [==============================] - 0s 35us/step - loss: 0.4501 - val_loss: 0.4484\n",
            "Epoch 9/20\n",
            "11610/11610 [==============================] - 0s 36us/step - loss: 0.4411 - val_loss: 0.4472\n",
            "Epoch 10/20\n",
            "11610/11610 [==============================] - 0s 36us/step - loss: 0.4335 - val_loss: 0.4318\n",
            "Epoch 11/20\n",
            "11610/11610 [==============================] - 0s 36us/step - loss: 0.4282 - val_loss: 0.4411\n",
            "Epoch 12/20\n",
            "11610/11610 [==============================] - 0s 35us/step - loss: 0.4228 - val_loss: 0.4548\n",
            "Epoch 13/20\n",
            "11610/11610 [==============================] - 0s 35us/step - loss: 0.4178 - val_loss: 0.4300\n",
            "Epoch 14/20\n",
            "11610/11610 [==============================] - 0s 35us/step - loss: 0.4143 - val_loss: 0.4625\n",
            "Epoch 15/20\n",
            "11610/11610 [==============================] - 0s 35us/step - loss: 0.4113 - val_loss: 0.4553\n",
            "Epoch 16/20\n",
            "11610/11610 [==============================] - 0s 36us/step - loss: 0.4081 - val_loss: 0.4275\n",
            "Epoch 17/20\n",
            "11610/11610 [==============================] - 0s 36us/step - loss: 0.4048 - val_loss: 0.4441\n",
            "Epoch 18/20\n",
            "11610/11610 [==============================] - 0s 35us/step - loss: 0.4022 - val_loss: 0.4480\n",
            "Epoch 19/20\n",
            "11610/11610 [==============================] - 0s 35us/step - loss: 0.3996 - val_loss: 0.4236\n",
            "Epoch 20/20\n",
            "11610/11610 [==============================] - 0s 36us/step - loss: 0.3975 - val_loss: 0.4444\n",
            "5160/5160 [==============================] - 0s 15us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpxLN7aC1s_g",
        "colab_type": "text"
      },
      "source": [
        "But what if you want to send a subset of the features through the wide path, and a different subset (possibly overlapping) through the deep path (see Figure 10-14)? \n",
        "\n",
        "![texto alternativo](https://i.ibb.co/KzbDTjB/multiple-inputs.png)\n",
        "\n",
        "In this case, one solution is to use multiple inputs. For example, suppose we want to send 5 features through the deep path (features 0 to 4), and 6 features through the wide path (features 2 to 7):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_H4VYWbx12iE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
        "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
        "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
        "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
        "concat = keras.layers.concatenate([input_A, hidden2])\n",
        "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
        "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvIgOv4I17rt",
        "colab_type": "text"
      },
      "source": [
        "The code is self-explanatory. Note that we specified `inputs=[input_A, input_B]`\n",
        "when creating the model. Now we can compile the model as usual, but when we call\n",
        "the `fit()` method, instead of passing a single input matrix `X_train` , we must pass a pair of matrices `(X_train_A, X_train_B)` : one per input. The same is true for `X_valid`, and also for `X_test` and `X_new` when you call `evaluate()` or `predict()`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3Ygz4gK19I3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "4da9ce7a-4d2d-41bf-b4b3-6b7f56510d1c"
      },
      "source": [
        "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
        "\n",
        "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
        "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
        "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
        "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
        "\n",
        "history = model.fit([X_train_A, X_train_B], y_train, epochs=20,\n",
        "                    validation_data=([X_valid_A, X_valid_B], y_valid))\n",
        "\n",
        "mse_test = model.evaluate([X_test_A, X_test_B], y_test)\n",
        "y_pred = model.predict([X_new_A, X_new_B])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 11610 samples, validate on 3870 samples\n",
            "Epoch 1/20\n",
            "11610/11610 [==============================] - 0s 41us/step - loss: 1.8974 - val_loss: 1.7702\n",
            "Epoch 2/20\n",
            "11610/11610 [==============================] - 0s 36us/step - loss: 0.7005 - val_loss: 0.6267\n",
            "Epoch 3/20\n",
            "11610/11610 [==============================] - 0s 35us/step - loss: 0.6135 - val_loss: 0.5864\n",
            "Epoch 4/20\n",
            "11610/11610 [==============================] - 0s 35us/step - loss: 0.5733 - val_loss: 0.5431\n",
            "Epoch 5/20\n",
            "11610/11610 [==============================] - 0s 36us/step - loss: 0.5451 - val_loss: 0.5195\n",
            "Epoch 6/20\n",
            "11610/11610 [==============================] - 0s 36us/step - loss: 0.5229 - val_loss: 0.5590\n",
            "Epoch 7/20\n",
            "11610/11610 [==============================] - 0s 36us/step - loss: 0.5061 - val_loss: 0.5057\n",
            "Epoch 8/20\n",
            "11610/11610 [==============================] - 0s 35us/step - loss: 0.4924 - val_loss: 0.4643\n",
            "Epoch 9/20\n",
            "11610/11610 [==============================] - 0s 36us/step - loss: 0.4796 - val_loss: 0.4563\n",
            "Epoch 10/20\n",
            "11610/11610 [==============================] - 0s 36us/step - loss: 0.4695 - val_loss: 0.4557\n",
            "Epoch 11/20\n",
            "11610/11610 [==============================] - 0s 36us/step - loss: 0.4616 - val_loss: 0.4311\n",
            "Epoch 12/20\n",
            "11610/11610 [==============================] - 0s 36us/step - loss: 0.4538 - val_loss: 0.4236\n",
            "Epoch 13/20\n",
            "11610/11610 [==============================] - 0s 37us/step - loss: 0.4483 - val_loss: 0.4189\n",
            "Epoch 14/20\n",
            "11610/11610 [==============================] - 0s 36us/step - loss: 0.4437 - val_loss: 0.4112\n",
            "Epoch 15/20\n",
            "11610/11610 [==============================] - 0s 35us/step - loss: 0.4392 - val_loss: 0.4061\n",
            "Epoch 16/20\n",
            "11610/11610 [==============================] - 0s 36us/step - loss: 0.4351 - val_loss: 0.4039\n",
            "Epoch 17/20\n",
            "11610/11610 [==============================] - 0s 36us/step - loss: 0.4322 - val_loss: 0.4070\n",
            "Epoch 18/20\n",
            "11610/11610 [==============================] - 0s 37us/step - loss: 0.4297 - val_loss: 0.4233\n",
            "Epoch 19/20\n",
            "11610/11610 [==============================] - 0s 36us/step - loss: 0.4273 - val_loss: 0.3952\n",
            "Epoch 20/20\n",
            "11610/11610 [==============================] - 0s 35us/step - loss: 0.4252 - val_loss: 0.3931\n",
            "5160/5160 [==============================] - 0s 16us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lp4vVdsD2C_o",
        "colab_type": "text"
      },
      "source": [
        "There are also many use cases in which you may want to have multiple outputs:\n",
        "\n",
        "\n",
        "- The task may demand it, for example you may want to locate and classify the\n",
        "main object in a picture. This is both a regression task (finding the coordinates of the object’s center, as well as its width and height) and a classification task.\n",
        "\n",
        "- Similarly, you may have multiple independent tasks to perform based on the\n",
        "same data. Sure, you could train one neural network per task, but in many cases\n",
        "you will get better results on all tasks by training a single neural network with one output per task. This is because the neural network can learn features in the data that are useful across tasks.\n",
        "\n",
        "- Another use case is as a regularization technique (i.e., a training constraint whose objective is to reduce overfitting and thus improve the model’s ability to generalize). For example, you may want to add some auxiliary outputs in a neural network architecture (see Figure 10-15) to ensure that the underlying part of the network learns something useful on its own, without relying on the rest of the network.\n",
        "\n",
        "![texto alternativo](https://i.ibb.co/pLKmRgw/multiple-outputs.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOiPvQge2OGc",
        "colab_type": "text"
      },
      "source": [
        "Adding extra outputs is quite easy: just connect them to the appropriate layers and add them to your model’s list of outputs. For example, the following code builds the network represented in Figure 10-15:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eegzZDl2Ooc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
        "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
        "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
        "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
        "concat = keras.layers.concatenate([input_A, hidden2])\n",
        "output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
        "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)\n",
        "model = keras.models.Model(inputs=[input_A, input_B],\n",
        "                           outputs=[output, aux_output])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpxL1F892Stg",
        "colab_type": "text"
      },
      "source": [
        "Each output will need its own loss function, so when we compile the model we\n",
        "should pass a list of losses (if we pass a single loss, Keras will assume that the same loss must be used for all outputs). By default, Keras will compute all these losses and simply add them up to get the final loss used for training. However, we care much more about the main output than about the auxiliary output (as it is just used for regularization), so we want to give the main output’s loss a much greater weight. Fortunately, it is possible to set all the loss weights when compiling the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thED7y5_2Yfs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(lr=1e-3))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mB8Opr3A2Y-8",
        "colab_type": "text"
      },
      "source": [
        "Now when we train the model, we need to provide some labels for each output. In\n",
        "this example, the main output and the auxiliary output should try to predict the same thing, so they should use the same labels. So instead of passing `y_train` , we just need to pass `[y_train, y_train]` (and the same goes for `y_valid` and `y_test`):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HScmHAoZ2ct0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "outputId": "0ee57337-7076-4e21-d149-4a85fbff4b58"
      },
      "source": [
        "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=20,\n",
        "                    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 11610 samples, validate on 3870 samples\n",
            "Epoch 1/20\n",
            "11610/11610 [==============================] - 1s 46us/step - loss: 2.3618 - main_output_loss: 2.1316 - aux_output_loss: 4.4274 - val_loss: 2.2500 - val_main_output_loss: 1.5113 - val_aux_output_loss: 8.8912\n",
            "Epoch 2/20\n",
            "11610/11610 [==============================] - 0s 40us/step - loss: 1.0658 - main_output_loss: 0.8751 - aux_output_loss: 2.7818 - val_loss: 1.6173 - val_main_output_loss: 0.7666 - val_aux_output_loss: 9.2680\n",
            "Epoch 3/20\n",
            "11610/11610 [==============================] - 0s 39us/step - loss: 0.8144 - main_output_loss: 0.6865 - aux_output_loss: 1.9651 - val_loss: 1.4924 - val_main_output_loss: 0.6207 - val_aux_output_loss: 9.3327\n",
            "Epoch 4/20\n",
            "11610/11610 [==============================] - 0s 40us/step - loss: 0.7124 - main_output_loss: 0.6138 - aux_output_loss: 1.5978 - val_loss: 1.3784 - val_main_output_loss: 0.5686 - val_aux_output_loss: 8.6614\n",
            "Epoch 5/20\n",
            "11610/11610 [==============================] - 0s 39us/step - loss: 0.6557 - main_output_loss: 0.5716 - aux_output_loss: 1.4144 - val_loss: 1.2407 - val_main_output_loss: 0.5273 - val_aux_output_loss: 7.6572\n",
            "Epoch 6/20\n",
            "11610/11610 [==============================] - 0s 40us/step - loss: 0.6154 - main_output_loss: 0.5382 - aux_output_loss: 1.3125 - val_loss: 1.1048 - val_main_output_loss: 0.4996 - val_aux_output_loss: 6.5469\n",
            "Epoch 7/20\n",
            "11610/11610 [==============================] - 0s 38us/step - loss: 0.5865 - main_output_loss: 0.5130 - aux_output_loss: 1.2469 - val_loss: 0.9817 - val_main_output_loss: 0.4799 - val_aux_output_loss: 5.4936\n",
            "Epoch 8/20\n",
            "11610/11610 [==============================] - 0s 40us/step - loss: 0.5651 - main_output_loss: 0.4961 - aux_output_loss: 1.1914 - val_loss: 0.8873 - val_main_output_loss: 0.4612 - val_aux_output_loss: 4.7198\n",
            "Epoch 9/20\n",
            "11610/11610 [==============================] - 0s 39us/step - loss: 0.5480 - main_output_loss: 0.4814 - aux_output_loss: 1.1478 - val_loss: 0.8191 - val_main_output_loss: 0.4467 - val_aux_output_loss: 4.1684\n",
            "Epoch 10/20\n",
            "11610/11610 [==============================] - 0s 40us/step - loss: 0.5342 - main_output_loss: 0.4702 - aux_output_loss: 1.1095 - val_loss: 0.7661 - val_main_output_loss: 0.4374 - val_aux_output_loss: 3.7219\n",
            "Epoch 11/20\n",
            "11610/11610 [==============================] - 0s 39us/step - loss: 0.5231 - main_output_loss: 0.4615 - aux_output_loss: 1.0771 - val_loss: 0.7259 - val_main_output_loss: 0.4295 - val_aux_output_loss: 3.3907\n",
            "Epoch 12/20\n",
            "11610/11610 [==============================] - 0s 40us/step - loss: 0.5136 - main_output_loss: 0.4542 - aux_output_loss: 1.0489 - val_loss: 0.6914 - val_main_output_loss: 0.4243 - val_aux_output_loss: 3.0932\n",
            "Epoch 13/20\n",
            "11610/11610 [==============================] - 0s 39us/step - loss: 0.5053 - main_output_loss: 0.4480 - aux_output_loss: 1.0208 - val_loss: 0.6620 - val_main_output_loss: 0.4205 - val_aux_output_loss: 2.8333\n",
            "Epoch 14/20\n",
            "11610/11610 [==============================] - 0s 38us/step - loss: 0.4982 - main_output_loss: 0.4428 - aux_output_loss: 0.9959 - val_loss: 0.6422 - val_main_output_loss: 0.4231 - val_aux_output_loss: 2.6120\n",
            "Epoch 15/20\n",
            "11610/11610 [==============================] - 0s 39us/step - loss: 0.4916 - main_output_loss: 0.4381 - aux_output_loss: 0.9723 - val_loss: 0.6104 - val_main_output_loss: 0.4141 - val_aux_output_loss: 2.3760\n",
            "Epoch 16/20\n",
            "11610/11610 [==============================] - 0s 40us/step - loss: 0.4859 - main_output_loss: 0.4344 - aux_output_loss: 0.9510 - val_loss: 0.5932 - val_main_output_loss: 0.4151 - val_aux_output_loss: 2.1950\n",
            "Epoch 17/20\n",
            "11610/11610 [==============================] - 0s 39us/step - loss: 0.4809 - main_output_loss: 0.4310 - aux_output_loss: 0.9310 - val_loss: 0.5807 - val_main_output_loss: 0.4175 - val_aux_output_loss: 2.0474\n",
            "Epoch 18/20\n",
            "11610/11610 [==============================] - 0s 39us/step - loss: 0.4761 - main_output_loss: 0.4276 - aux_output_loss: 0.9117 - val_loss: 0.5620 - val_main_output_loss: 0.4145 - val_aux_output_loss: 1.8885\n",
            "Epoch 19/20\n",
            "11610/11610 [==============================] - 0s 40us/step - loss: 0.4716 - main_output_loss: 0.4248 - aux_output_loss: 0.8932 - val_loss: 0.5450 - val_main_output_loss: 0.4095 - val_aux_output_loss: 1.7627\n",
            "Epoch 20/20\n",
            "11610/11610 [==============================] - 0s 38us/step - loss: 0.4679 - main_output_loss: 0.4225 - aux_output_loss: 0.8764 - val_loss: 0.5361 - val_main_output_loss: 0.4117 - val_aux_output_loss: 1.6537\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWe5HxAI2f6n",
        "colab_type": "text"
      },
      "source": [
        "When we evaluate the model, Keras will return the total loss, as well as all the individ‐\n",
        "ual losses:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ab6jTV22gZx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "25aa880c-ff91-453f-da66-0950583c8a2e"
      },
      "source": [
        "total_loss, main_loss, aux_loss = model.evaluate(\n",
        "    [X_test_A, X_test_B], [y_test, y_test])\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5160/5160 [==============================] - 0s 18us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAqoDffP2kfn",
        "colab_type": "text"
      },
      "source": [
        "Similarly, the `predict()` method will return predictions for each output:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grv8dsP22k46",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOi9RyPr2oAb",
        "colab_type": "text"
      },
      "source": [
        "As you can see, you can build any sort of architecture you want quite easily with the\n",
        "Functional API. Let’s look at one last way you can build Keras models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNmrxOZC2oXy",
        "colab_type": "text"
      },
      "source": [
        "## The Subclassing API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKb8r4Gg2uvf",
        "colab_type": "text"
      },
      "source": [
        "Both the Sequential API and the Functional API are declarative: you start by declaring which layers you want to use and how they should be connected, and only then can you start feeding the model some data for training or inference. This has many advantages: the model can easily be saved, cloned, shared, its structure can be displayed and analyzed, the framework can infer shapes and check types, so errors can be caught early (i.e., before any data ever goes through the model). It’s also fairly easy to debug, since the whole model is just a static graph of layers. But the flip side is just that: it’s static. Some models involve loops, varying shapes, conditional branching, and other dynamic behaviors. For such cases, or simply if you prefer a more imperative programming style, the Subclassing API is for you.\n",
        "\n",
        "Simply subclass the `Model` class, create the layers you need in the constructor, and use them to perform the computations you want in the `call()` method. For example, creating an instance of the following `WideAndDeepModel` class gives us an equivalent model to the one we just built with the Functional API. You can then compile it, evaluate it and use it to make predictions, exactly like we just did.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feFw0IxB22_Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class WideAndDeepModel(keras.models.Model):\n",
        "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
        "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
        "        self.main_output = keras.layers.Dense(1)\n",
        "        self.aux_output = keras.layers.Dense(1)\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        input_A, input_B = inputs\n",
        "        hidden1 = self.hidden1(input_B)\n",
        "        hidden2 = self.hidden2(hidden1)\n",
        "        concat = keras.layers.concatenate([input_A, hidden2])\n",
        "        main_output = self.main_output(concat)\n",
        "        aux_output = self.aux_output(hidden2)\n",
        "        return main_output, aux_output\n",
        "\n",
        "model = WideAndDeepModel(30, activation=\"relu\")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MerPoFBP3HZ3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "6e9b6dae-4b42-44a0-b5d4-d12d4dcf3032"
      },
      "source": [
        "model.compile(loss=\"mse\", loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(lr=1e-3))\n",
        "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=10,\n",
        "                    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))\n",
        "total_loss, main_loss, aux_loss = model.evaluate([X_test_A, X_test_B], [y_test, y_test])\n",
        "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 11610 samples, validate on 3870 samples\n",
            "Epoch 1/10\n",
            "11610/11610 [==============================] - 1s 45us/step - loss: 2.1914 - output_1_loss: 1.9891 - output_2_loss: 4.0119 - val_loss: 1.4701 - val_output_1_loss: 0.8327 - val_output_2_loss: 7.2024\n",
            "Epoch 2/10\n",
            "11610/11610 [==============================] - 0s 39us/step - loss: 0.9095 - output_1_loss: 0.7235 - output_2_loss: 2.5848 - val_loss: 1.2479 - val_output_1_loss: 0.6490 - val_output_2_loss: 6.6340\n",
            "Epoch 3/10\n",
            "11610/11610 [==============================] - 0s 39us/step - loss: 0.7876 - output_1_loss: 0.6537 - output_2_loss: 1.9928 - val_loss: 1.2042 - val_output_1_loss: 0.6475 - val_output_2_loss: 6.2107\n",
            "Epoch 4/10\n",
            "11610/11610 [==============================] - 0s 40us/step - loss: 0.7246 - output_1_loss: 0.6182 - output_2_loss: 1.6810 - val_loss: 1.1382 - val_output_1_loss: 0.6017 - val_output_2_loss: 5.9626\n",
            "Epoch 5/10\n",
            "11610/11610 [==============================] - 0s 40us/step - loss: 0.6804 - output_1_loss: 0.5903 - output_2_loss: 1.4933 - val_loss: 1.0657 - val_output_1_loss: 0.5632 - val_output_2_loss: 5.5844\n",
            "Epoch 6/10\n",
            "11610/11610 [==============================] - 0s 39us/step - loss: 0.6455 - output_1_loss: 0.5644 - output_2_loss: 1.3735 - val_loss: 1.0024 - val_output_1_loss: 0.5741 - val_output_2_loss: 4.8529\n",
            "Epoch 7/10\n",
            "11610/11610 [==============================] - 0s 40us/step - loss: 0.6178 - output_1_loss: 0.5443 - output_2_loss: 1.2809 - val_loss: 0.9209 - val_output_1_loss: 0.5179 - val_output_2_loss: 4.5440\n",
            "Epoch 8/10\n",
            "11610/11610 [==============================] - 0s 39us/step - loss: 0.5945 - output_1_loss: 0.5254 - output_2_loss: 1.2155 - val_loss: 0.8548 - val_output_1_loss: 0.4987 - val_output_2_loss: 4.0567\n",
            "Epoch 9/10\n",
            "11610/11610 [==============================] - 0s 39us/step - loss: 0.5749 - output_1_loss: 0.5099 - output_2_loss: 1.1588 - val_loss: 0.7951 - val_output_1_loss: 0.4894 - val_output_2_loss: 3.5435\n",
            "Epoch 10/10\n",
            "11610/11610 [==============================] - 0s 40us/step - loss: 0.5586 - output_1_loss: 0.4971 - output_2_loss: 1.1121 - val_loss: 0.7412 - val_output_1_loss: 0.4610 - val_output_2_loss: 3.2607\n",
            "5160/5160 [==============================] - 0s 18us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpiK3X113KfY",
        "colab_type": "text"
      },
      "source": [
        "This example looks very much like the Functional API, except we do not need to create the inputs, we just use the input argument to the `call()` method, and we separate the creation of the layers in the constructor from their usage in the `call()` method. However, the big difference is that you can do pretty much anything you want in the `call()` method: for loops, if statements, low-level TensorFlow operations, your imagination is the limit. This makes it a great API for researchers experimenting with new ideas.\n",
        "\n",
        "However, this extra flexibility comes at a cost: your model’s architecture is hidden within the `call()` method, so Keras cannot easily inspect it, it cannot save or clone it, and when you call the `summary()` method, you only get a list of layers, without any information on how they are connected to each other. Moreover, Keras cannot check types and shapes ahead of time, and it is easier to make mistakes. So unless you really need that extra flexibility, you should probably stick to the Sequential API or the Functional API."
      ]
    }
  ]
}